<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Classification II: evaluation &amp; tuning |  Data Science</title>
  <meta name="description" content="This is a textbook for teaching a first introduction to data science." />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Classification II: evaluation &amp; tuning |  Data Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a textbook for teaching a first introduction to data science." />
  <meta name="github-repo" content="UBC-DSCI/introduction-to-datascience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Classification II: evaluation &amp; tuning |  Data Science" />
  
  <meta name="twitter:description" content="This is a textbook for teaching a first introduction to data science." />
  

<meta name="author" content="Tiffany Timbers, Trevor Campbell, and Melissa Lee" />


<meta name="date" content="2025-03-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification1.html"/>
<link rel="next" href="regression1.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.2/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JJ9MD0LBF5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-JJ9MD0LBF5');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="source/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://datasciencebook.ca">Data Science: A First Introduction</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome!</a></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i>Foreword</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the authors</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> R and the Tidyverse</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#overview"><i class="fa fa-check"></i><b>1.1</b> Overview</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#chapter-learning-objectives"><i class="fa fa-check"></i><b>1.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#canadian-languages-data-set"><i class="fa fa-check"></i><b>1.3</b> Canadian languages data set</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#asking-a-question"><i class="fa fa-check"></i><b>1.4</b> Asking a question</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#loading-a-tabular-data-set"><i class="fa fa-check"></i><b>1.5</b> Loading a tabular data set</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#naming-things-in-r"><i class="fa fa-check"></i><b>1.6</b> Naming things in R</a></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#creating-subsets-of-data-frames-with-filter-select"><i class="fa fa-check"></i><b>1.7</b> Creating subsets of data frames with <code>filter</code> &amp; <code>select</code></a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="intro.html"><a href="intro.html#using-filter-to-extract-rows"><i class="fa fa-check"></i><b>1.7.1</b> Using <code>filter</code> to extract rows</a></li>
<li class="chapter" data-level="1.7.2" data-path="intro.html"><a href="intro.html#using-select-to-extract-columns"><i class="fa fa-check"></i><b>1.7.2</b> Using <code>select</code> to extract columns</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#arrangesliceintro"><i class="fa fa-check"></i><b>1.8</b> Using <code>arrange</code> to order and <code>slice</code> to select rows by index number</a></li>
<li class="chapter" data-level="1.9" data-path="intro.html"><a href="intro.html#adding-and-modifying-columns-using-mutate"><i class="fa fa-check"></i><b>1.9</b> Adding and modifying columns using <code>mutate</code></a></li>
<li class="chapter" data-level="1.10" data-path="intro.html"><a href="intro.html#exploring-data-with-visualizations"><i class="fa fa-check"></i><b>1.10</b> Exploring data with visualizations</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="intro.html"><a href="intro.html#using-ggplot-to-create-a-bar-plot"><i class="fa fa-check"></i><b>1.10.1</b> Using <code>ggplot</code> to create a bar plot</a></li>
<li class="chapter" data-level="1.10.2" data-path="intro.html"><a href="intro.html#formatting-ggplot-objects"><i class="fa fa-check"></i><b>1.10.2</b> Formatting ggplot objects</a></li>
<li class="chapter" data-level="1.10.3" data-path="intro.html"><a href="intro.html#putting-it-all-together"><i class="fa fa-check"></i><b>1.10.3</b> Putting it all together</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="intro.html"><a href="intro.html#accessing-documentation"><i class="fa fa-check"></i><b>1.11</b> Accessing documentation</a></li>
<li class="chapter" data-level="1.12" data-path="intro.html"><a href="intro.html#exercises"><i class="fa fa-check"></i><b>1.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reading.html"><a href="reading.html"><i class="fa fa-check"></i><b>2</b> Reading in data locally and from the web</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reading.html"><a href="reading.html#overview-1"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="reading.html"><a href="reading.html#chapter-learning-objectives-1"><i class="fa fa-check"></i><b>2.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="2.3" data-path="reading.html"><a href="reading.html#absolute-and-relative-file-paths"><i class="fa fa-check"></i><b>2.3</b> Absolute and relative file paths</a></li>
<li class="chapter" data-level="2.4" data-path="reading.html"><a href="reading.html#reading-tabular-data-from-a-plain-text-file-into-r"><i class="fa fa-check"></i><b>2.4</b> Reading tabular data from a plain text file into R</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="reading.html"><a href="reading.html#readcsv"><i class="fa fa-check"></i><b>2.4.1</b> <code>read_csv</code> to read in comma-separated values files</a></li>
<li class="chapter" data-level="2.4.2" data-path="reading.html"><a href="reading.html#skipping-rows-when-reading-in-data"><i class="fa fa-check"></i><b>2.4.2</b> Skipping rows when reading in data</a></li>
<li class="chapter" data-level="2.4.3" data-path="reading.html"><a href="reading.html#read_tsv-to-read-in-tab-separated-values-files"><i class="fa fa-check"></i><b>2.4.3</b> <code>read_tsv</code> to read in tab-separated values files</a></li>
<li class="chapter" data-level="2.4.4" data-path="reading.html"><a href="reading.html#read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4.4</b> <code>read_delim</code> as a more flexible method to get tabular data into R</a></li>
<li class="chapter" data-level="2.4.5" data-path="reading.html"><a href="reading.html#reading-tabular-data-directly-from-a-url"><i class="fa fa-check"></i><b>2.4.5</b> Reading tabular data directly from a URL</a></li>
<li class="chapter" data-level="2.4.6" data-path="reading.html"><a href="reading.html#downloading-data-from-a-url"><i class="fa fa-check"></i><b>2.4.6</b> Downloading data from a URL</a></li>
<li class="chapter" data-level="2.4.7" data-path="reading.html"><a href="reading.html#previewing-a-data-file-before-reading-it-into-r"><i class="fa fa-check"></i><b>2.4.7</b> Previewing a data file before reading it into R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reading.html"><a href="reading.html#reading-tabular-data-from-a-microsoft-excel-file"><i class="fa fa-check"></i><b>2.5</b> Reading tabular data from a Microsoft Excel file</a></li>
<li class="chapter" data-level="2.6" data-path="reading.html"><a href="reading.html#reading-data-from-a-database"><i class="fa fa-check"></i><b>2.6</b> Reading data from a database</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="reading.html"><a href="reading.html#reading-data-from-a-sqlite-database"><i class="fa fa-check"></i><b>2.6.1</b> Reading data from a SQLite database</a></li>
<li class="chapter" data-level="2.6.2" data-path="reading.html"><a href="reading.html#reading-data-from-a-postgresql-database"><i class="fa fa-check"></i><b>2.6.2</b> Reading data from a PostgreSQL database</a></li>
<li class="chapter" data-level="2.6.3" data-path="reading.html"><a href="reading.html#why-should-we-bother-with-databases-at-all"><i class="fa fa-check"></i><b>2.6.3</b> Why should we bother with databases at all?</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="reading.html"><a href="reading.html#writing-data-from-r-to-a-.csv-file"><i class="fa fa-check"></i><b>2.7</b> Writing data from R to a <code>.csv</code> file</a></li>
<li class="chapter" data-level="2.8" data-path="reading.html"><a href="reading.html#obtaining-data-from-the-web"><i class="fa fa-check"></i><b>2.8</b> Obtaining data from the web</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="reading.html"><a href="reading.html#web-scraping"><i class="fa fa-check"></i><b>2.8.1</b> Web scraping</a></li>
<li class="chapter" data-level="2.8.2" data-path="reading.html"><a href="reading.html#using-an-api"><i class="fa fa-check"></i><b>2.8.2</b> Using an API</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="reading.html"><a href="reading.html#exercises-1"><i class="fa fa-check"></i><b>2.9</b> Exercises</a></li>
<li class="chapter" data-level="2.10" data-path="reading.html"><a href="reading.html#additional-resources"><i class="fa fa-check"></i><b>2.10</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="wrangling.html"><a href="wrangling.html"><i class="fa fa-check"></i><b>3</b> Cleaning and wrangling data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="wrangling.html"><a href="wrangling.html#overview-2"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="wrangling.html"><a href="wrangling.html#chapter-learning-objectives-2"><i class="fa fa-check"></i><b>3.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="3.3" data-path="wrangling.html"><a href="wrangling.html#data-frames-vectors-and-lists"><i class="fa fa-check"></i><b>3.3</b> Data frames, vectors, and lists</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="wrangling.html"><a href="wrangling.html#what-is-a-data-frame"><i class="fa fa-check"></i><b>3.3.1</b> What is a data frame?</a></li>
<li class="chapter" data-level="3.3.2" data-path="wrangling.html"><a href="wrangling.html#what-is-a-vector"><i class="fa fa-check"></i><b>3.3.2</b> What is a vector?</a></li>
<li class="chapter" data-level="3.3.3" data-path="wrangling.html"><a href="wrangling.html#what-is-a-list"><i class="fa fa-check"></i><b>3.3.3</b> What is a list?</a></li>
<li class="chapter" data-level="3.3.4" data-path="wrangling.html"><a href="wrangling.html#what-does-this-have-to-do-with-data-frames"><i class="fa fa-check"></i><b>3.3.4</b> What does this have to do with data frames?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="wrangling.html"><a href="wrangling.html#tidy-data"><i class="fa fa-check"></i><b>3.4</b> Tidy data</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="wrangling.html"><a href="wrangling.html#tidying-up-going-from-wide-to-long-using-pivot_longer"><i class="fa fa-check"></i><b>3.4.1</b> Tidying up: going from wide to long using <code>pivot_longer</code></a></li>
<li class="chapter" data-level="3.4.2" data-path="wrangling.html"><a href="wrangling.html#pivot-wider"><i class="fa fa-check"></i><b>3.4.2</b> Tidying up: going from long to wide using <code>pivot_wider</code></a></li>
<li class="chapter" data-level="3.4.3" data-path="wrangling.html"><a href="wrangling.html#separate"><i class="fa fa-check"></i><b>3.4.3</b> Tidying up: using <code>separate</code> to deal with multiple delimiters</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="wrangling.html"><a href="wrangling.html#using-select-to-extract-a-range-of-columns"><i class="fa fa-check"></i><b>3.5</b> Using <code>select</code> to extract a range of columns</a></li>
<li class="chapter" data-level="3.6" data-path="wrangling.html"><a href="wrangling.html#using-filter-to-extract-rows-1"><i class="fa fa-check"></i><b>3.6</b> Using <code>filter</code> to extract rows</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-that-have-a-certain-value-with"><i class="fa fa-check"></i><b>3.6.1</b> Extracting rows that have a certain value with <code>==</code></a></li>
<li class="chapter" data-level="3.6.2" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-that-do-not-have-a-certain-value-with"><i class="fa fa-check"></i><b>3.6.2</b> Extracting rows that do not have a certain value with <code>!=</code></a></li>
<li class="chapter" data-level="3.6.3" data-path="wrangling.html"><a href="wrangling.html#filter-and"><i class="fa fa-check"></i><b>3.6.3</b> Extracting rows satisfying multiple conditions using <code>,</code> or <code>&amp;</code></a></li>
<li class="chapter" data-level="3.6.4" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-satisfying-at-least-one-condition-using"><i class="fa fa-check"></i><b>3.6.4</b> Extracting rows satisfying at least one condition using <code>|</code></a></li>
<li class="chapter" data-level="3.6.5" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-with-values-in-a-vector-using-in"><i class="fa fa-check"></i><b>3.6.5</b> Extracting rows with values in a vector using <code>%in%</code></a></li>
<li class="chapter" data-level="3.6.6" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-above-or-below-a-threshold-using-and"><i class="fa fa-check"></i><b>3.6.6</b> Extracting rows above or below a threshold using <code>&gt;</code> and <code>&lt;</code></a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="wrangling.html"><a href="wrangling.html#using-mutate-to-modify-or-add-columns"><i class="fa fa-check"></i><b>3.7</b> Using <code>mutate</code> to modify or add columns</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="wrangling.html"><a href="wrangling.html#using-mutate-to-modify-columns"><i class="fa fa-check"></i><b>3.7.1</b> Using <code>mutate</code> to modify columns</a></li>
<li class="chapter" data-level="3.7.2" data-path="wrangling.html"><a href="wrangling.html#using-mutate-to-create-new-columns"><i class="fa fa-check"></i><b>3.7.2</b> Using <code>mutate</code> to create new columns</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="wrangling.html"><a href="wrangling.html#combining-functions-using-the-pipe-operator"><i class="fa fa-check"></i><b>3.8</b> Combining functions using the pipe operator, <code>|&gt;</code></a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="wrangling.html"><a href="wrangling.html#using-to-combine-filter-and-select"><i class="fa fa-check"></i><b>3.8.1</b> Using <code>|&gt;</code> to combine <code>filter</code> and <code>select</code></a></li>
<li class="chapter" data-level="3.8.2" data-path="wrangling.html"><a href="wrangling.html#using-with-more-than-two-functions"><i class="fa fa-check"></i><b>3.8.2</b> Using <code>|&gt;</code> with more than two functions</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="wrangling.html"><a href="wrangling.html#aggregating-data-with-summarize-and-map"><i class="fa fa-check"></i><b>3.9</b> Aggregating data with <code>summarize</code> and <code>map</code></a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics-on-whole-columns"><i class="fa fa-check"></i><b>3.9.1</b> Calculating summary statistics on whole columns</a></li>
<li class="chapter" data-level="3.9.2" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics-when-there-are-nas"><i class="fa fa-check"></i><b>3.9.2</b> Calculating summary statistics when there are <code>NA</code>s</a></li>
<li class="chapter" data-level="3.9.3" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics-for-groups-of-rows"><i class="fa fa-check"></i><b>3.9.3</b> Calculating summary statistics for groups of rows</a></li>
<li class="chapter" data-level="3.9.4" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics-on-many-columns"><i class="fa fa-check"></i><b>3.9.4</b> Calculating summary statistics on many columns</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="wrangling.html"><a href="wrangling.html#apply-functions-across-many-columns-with-mutate-and-across"><i class="fa fa-check"></i><b>3.10</b> Apply functions across many columns with <code>mutate</code> and <code>across</code></a></li>
<li class="chapter" data-level="3.11" data-path="wrangling.html"><a href="wrangling.html#apply-functions-across-columns-within-one-row-with-rowwise-and-mutate"><i class="fa fa-check"></i><b>3.11</b> Apply functions across columns within one row with <code>rowwise</code> and <code>mutate</code></a></li>
<li class="chapter" data-level="3.12" data-path="wrangling.html"><a href="wrangling.html#summary"><i class="fa fa-check"></i><b>3.12</b> Summary</a></li>
<li class="chapter" data-level="3.13" data-path="wrangling.html"><a href="wrangling.html#exercises-2"><i class="fa fa-check"></i><b>3.13</b> Exercises</a></li>
<li class="chapter" data-level="3.14" data-path="wrangling.html"><a href="wrangling.html#additional-resources-1"><i class="fa fa-check"></i><b>3.14</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>4</b> Effective data visualization</a>
<ul>
<li class="chapter" data-level="4.1" data-path="viz.html"><a href="viz.html#overview-3"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="viz.html"><a href="viz.html#chapter-learning-objectives-3"><i class="fa fa-check"></i><b>4.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="4.3" data-path="viz.html"><a href="viz.html#choosing-the-visualization"><i class="fa fa-check"></i><b>4.3</b> Choosing the visualization</a></li>
<li class="chapter" data-level="4.4" data-path="viz.html"><a href="viz.html#refining-the-visualization"><i class="fa fa-check"></i><b>4.4</b> Refining the visualization</a></li>
<li class="chapter" data-level="4.5" data-path="viz.html"><a href="viz.html#creating-visualizations-with-ggplot2"><i class="fa fa-check"></i><b>4.5</b> Creating visualizations with <code>ggplot2</code></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="viz.html"><a href="viz.html#scatter-plots-and-line-plots-the-mauna-loa-co_text2-data-set"><i class="fa fa-check"></i><b>4.5.1</b> Scatter plots and line plots: the Mauna Loa CO<span class="math inline">\(_{\text{2}}\)</span> data set</a></li>
<li class="chapter" data-level="4.5.2" data-path="viz.html"><a href="viz.html#scatter-plots-the-old-faithful-eruption-time-data-set"><i class="fa fa-check"></i><b>4.5.2</b> Scatter plots: the Old Faithful eruption time data set</a></li>
<li class="chapter" data-level="4.5.3" data-path="viz.html"><a href="viz.html#axis-transformation-and-colored-scatter-plots-the-canadian-languages-data-set"><i class="fa fa-check"></i><b>4.5.3</b> Axis transformation and colored scatter plots: the Canadian languages data set</a></li>
<li class="chapter" data-level="4.5.4" data-path="viz.html"><a href="viz.html#bar-plots-the-island-landmass-data-set"><i class="fa fa-check"></i><b>4.5.4</b> Bar plots: the island landmass data set</a></li>
<li class="chapter" data-level="4.5.5" data-path="viz.html"><a href="viz.html#histogramsviz"><i class="fa fa-check"></i><b>4.5.5</b> Histograms: the Michelson speed of light data set</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="viz.html"><a href="viz.html#explaining-the-visualization"><i class="fa fa-check"></i><b>4.6</b> Explaining the visualization</a></li>
<li class="chapter" data-level="4.7" data-path="viz.html"><a href="viz.html#saving-the-visualization"><i class="fa fa-check"></i><b>4.7</b> Saving the visualization</a></li>
<li class="chapter" data-level="4.8" data-path="viz.html"><a href="viz.html#exercises-3"><i class="fa fa-check"></i><b>4.8</b> Exercises</a></li>
<li class="chapter" data-level="4.9" data-path="viz.html"><a href="viz.html#additional-resources-2"><i class="fa fa-check"></i><b>4.9</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="classification1.html"><a href="classification1.html"><i class="fa fa-check"></i><b>5</b> Classification I: training &amp; predicting</a>
<ul>
<li class="chapter" data-level="5.1" data-path="classification1.html"><a href="classification1.html#overview-4"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="classification1.html"><a href="classification1.html#chapter-learning-objectives-4"><i class="fa fa-check"></i><b>5.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="5.3" data-path="classification1.html"><a href="classification1.html#the-classification-problem"><i class="fa fa-check"></i><b>5.3</b> The classification problem</a></li>
<li class="chapter" data-level="5.4" data-path="classification1.html"><a href="classification1.html#exploring-a-data-set"><i class="fa fa-check"></i><b>5.4</b> Exploring a data set</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="classification1.html"><a href="classification1.html#loading-the-cancer-data"><i class="fa fa-check"></i><b>5.4.1</b> Loading the cancer data</a></li>
<li class="chapter" data-level="5.4.2" data-path="classification1.html"><a href="classification1.html#describing-the-variables-in-the-cancer-data-set"><i class="fa fa-check"></i><b>5.4.2</b> Describing the variables in the cancer data set</a></li>
<li class="chapter" data-level="5.4.3" data-path="classification1.html"><a href="classification1.html#exploring-the-cancer-data"><i class="fa fa-check"></i><b>5.4.3</b> Exploring the cancer data</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="classification1.html"><a href="classification1.html#classification-with-k-nearest-neighbors"><i class="fa fa-check"></i><b>5.5</b> Classification with K-nearest neighbors</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="classification1.html"><a href="classification1.html#distance-between-points"><i class="fa fa-check"></i><b>5.5.1</b> Distance between points</a></li>
<li class="chapter" data-level="5.5.2" data-path="classification1.html"><a href="classification1.html#more-than-two-explanatory-variables"><i class="fa fa-check"></i><b>5.5.2</b> More than two explanatory variables</a></li>
<li class="chapter" data-level="5.5.3" data-path="classification1.html"><a href="classification1.html#summary-of-k-nearest-neighbors-algorithm"><i class="fa fa-check"></i><b>5.5.3</b> Summary of K-nearest neighbors algorithm</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="classification1.html"><a href="classification1.html#k-nearest-neighbors-with-tidymodels"><i class="fa fa-check"></i><b>5.6</b> K-nearest neighbors with <code>tidymodels</code></a></li>
<li class="chapter" data-level="5.7" data-path="classification1.html"><a href="classification1.html#data-preprocessing-with-tidymodels"><i class="fa fa-check"></i><b>5.7</b> Data preprocessing with <code>tidymodels</code></a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="classification1.html"><a href="classification1.html#centering-and-scaling"><i class="fa fa-check"></i><b>5.7.1</b> Centering and scaling</a></li>
<li class="chapter" data-level="5.7.2" data-path="classification1.html"><a href="classification1.html#balancing"><i class="fa fa-check"></i><b>5.7.2</b> Balancing</a></li>
<li class="chapter" data-level="5.7.3" data-path="classification1.html"><a href="classification1.html#missing-data"><i class="fa fa-check"></i><b>5.7.3</b> Missing data</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="classification1.html"><a href="classification1.html#puttingittogetherworkflow"><i class="fa fa-check"></i><b>5.8</b> Putting it together in a <code>workflow</code></a></li>
<li class="chapter" data-level="5.9" data-path="classification1.html"><a href="classification1.html#exercises-4"><i class="fa fa-check"></i><b>5.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification2.html"><a href="classification2.html"><i class="fa fa-check"></i><b>6</b> Classification II: evaluation &amp; tuning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="classification2.html"><a href="classification2.html#overview-5"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="classification2.html"><a href="classification2.html#chapter-learning-objectives-5"><i class="fa fa-check"></i><b>6.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="6.3" data-path="classification2.html"><a href="classification2.html#evaluating-performance"><i class="fa fa-check"></i><b>6.3</b> Evaluating performance</a></li>
<li class="chapter" data-level="6.4" data-path="classification2.html"><a href="classification2.html#randomseeds"><i class="fa fa-check"></i><b>6.4</b> Randomness and seeds</a></li>
<li class="chapter" data-level="6.5" data-path="classification2.html"><a href="classification2.html#evaluating-performance-with-tidymodels"><i class="fa fa-check"></i><b>6.5</b> Evaluating performance with <code>tidymodels</code></a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="classification2.html"><a href="classification2.html#create-the-train-test-split"><i class="fa fa-check"></i><b>6.5.1</b> Create the train / test split</a></li>
<li class="chapter" data-level="6.5.2" data-path="classification2.html"><a href="classification2.html#preprocess-the-data"><i class="fa fa-check"></i><b>6.5.2</b> Preprocess the data</a></li>
<li class="chapter" data-level="6.5.3" data-path="classification2.html"><a href="classification2.html#train-the-classifier"><i class="fa fa-check"></i><b>6.5.3</b> Train the classifier</a></li>
<li class="chapter" data-level="6.5.4" data-path="classification2.html"><a href="classification2.html#predict-the-labels-in-the-test-set"><i class="fa fa-check"></i><b>6.5.4</b> Predict the labels in the test set</a></li>
<li class="chapter" data-level="6.5.5" data-path="classification2.html"><a href="classification2.html#eval-performance-cls2"><i class="fa fa-check"></i><b>6.5.5</b> Evaluate performance</a></li>
<li class="chapter" data-level="6.5.6" data-path="classification2.html"><a href="classification2.html#critically-analyze-performance"><i class="fa fa-check"></i><b>6.5.6</b> Critically analyze performance</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="classification2.html"><a href="classification2.html#tuning-the-classifier"><i class="fa fa-check"></i><b>6.6</b> Tuning the classifier</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="classification2.html"><a href="classification2.html#cross-validation"><i class="fa fa-check"></i><b>6.6.1</b> Cross-validation</a></li>
<li class="chapter" data-level="6.6.2" data-path="classification2.html"><a href="classification2.html#parameter-value-selection"><i class="fa fa-check"></i><b>6.6.2</b> Parameter value selection</a></li>
<li class="chapter" data-level="6.6.3" data-path="classification2.html"><a href="classification2.html#underoverfitting"><i class="fa fa-check"></i><b>6.6.3</b> Under/Overfitting</a></li>
<li class="chapter" data-level="6.6.4" data-path="classification2.html"><a href="classification2.html#evaluating-on-the-test-set"><i class="fa fa-check"></i><b>6.6.4</b> Evaluating on the test set</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="classification2.html"><a href="classification2.html#summary-1"><i class="fa fa-check"></i><b>6.7</b> Summary</a></li>
<li class="chapter" data-level="6.8" data-path="classification2.html"><a href="classification2.html#predictor-variable-selection"><i class="fa fa-check"></i><b>6.8</b> Predictor variable selection</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="classification2.html"><a href="classification2.html#the-effect-of-irrelevant-predictors"><i class="fa fa-check"></i><b>6.8.1</b> The effect of irrelevant predictors</a></li>
<li class="chapter" data-level="6.8.2" data-path="classification2.html"><a href="classification2.html#finding-a-good-subset-of-predictors"><i class="fa fa-check"></i><b>6.8.2</b> Finding a good subset of predictors</a></li>
<li class="chapter" data-level="6.8.3" data-path="classification2.html"><a href="classification2.html#forward-selection-in-r"><i class="fa fa-check"></i><b>6.8.3</b> Forward selection in R</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="classification2.html"><a href="classification2.html#exercises-5"><i class="fa fa-check"></i><b>6.9</b> Exercises</a></li>
<li class="chapter" data-level="6.10" data-path="classification2.html"><a href="classification2.html#additional-resources-3"><i class="fa fa-check"></i><b>6.10</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regression1.html"><a href="regression1.html"><i class="fa fa-check"></i><b>7</b> Regression I: K-nearest neighbors</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regression1.html"><a href="regression1.html#overview-6"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="regression1.html"><a href="regression1.html#chapter-learning-objectives-6"><i class="fa fa-check"></i><b>7.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="7.3" data-path="regression1.html"><a href="regression1.html#the-regression-problem"><i class="fa fa-check"></i><b>7.3</b> The regression problem</a></li>
<li class="chapter" data-level="7.4" data-path="regression1.html"><a href="regression1.html#exploring-a-data-set-1"><i class="fa fa-check"></i><b>7.4</b> Exploring a data set</a></li>
<li class="chapter" data-level="7.5" data-path="regression1.html"><a href="regression1.html#k-nearest-neighbors-regression"><i class="fa fa-check"></i><b>7.5</b> K-nearest neighbors regression</a></li>
<li class="chapter" data-level="7.6" data-path="regression1.html"><a href="regression1.html#training-evaluating-and-tuning-the-model"><i class="fa fa-check"></i><b>7.6</b> Training, evaluating, and tuning the model</a></li>
<li class="chapter" data-level="7.7" data-path="regression1.html"><a href="regression1.html#underfitting-and-overfitting"><i class="fa fa-check"></i><b>7.7</b> Underfitting and overfitting</a></li>
<li class="chapter" data-level="7.8" data-path="regression1.html"><a href="regression1.html#evaluating-on-the-test-set-1"><i class="fa fa-check"></i><b>7.8</b> Evaluating on the test set</a></li>
<li class="chapter" data-level="7.9" data-path="regression1.html"><a href="regression1.html#multivariable-k-nn-regression"><i class="fa fa-check"></i><b>7.9</b> Multivariable K-NN regression</a></li>
<li class="chapter" data-level="7.10" data-path="regression1.html"><a href="regression1.html#strengths-and-limitations-of-k-nn-regression"><i class="fa fa-check"></i><b>7.10</b> Strengths and limitations of K-NN regression</a></li>
<li class="chapter" data-level="7.11" data-path="regression1.html"><a href="regression1.html#exercises-6"><i class="fa fa-check"></i><b>7.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression2.html"><a href="regression2.html"><i class="fa fa-check"></i><b>8</b> Regression II: linear regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="regression2.html"><a href="regression2.html#overview-7"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="regression2.html"><a href="regression2.html#chapter-learning-objectives-7"><i class="fa fa-check"></i><b>8.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="8.3" data-path="regression2.html"><a href="regression2.html#simple-linear-regression"><i class="fa fa-check"></i><b>8.3</b> Simple linear regression</a></li>
<li class="chapter" data-level="8.4" data-path="regression2.html"><a href="regression2.html#linear-regression-in-r"><i class="fa fa-check"></i><b>8.4</b> Linear regression in R</a></li>
<li class="chapter" data-level="8.5" data-path="regression2.html"><a href="regression2.html#comparing-simple-linear-and-k-nn-regression"><i class="fa fa-check"></i><b>8.5</b> Comparing simple linear and K-NN regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression2.html"><a href="regression2.html#multivariable-linear-regression"><i class="fa fa-check"></i><b>8.6</b> Multivariable linear regression</a></li>
<li class="chapter" data-level="8.7" data-path="regression2.html"><a href="regression2.html#multicollinearity-and-outliers"><i class="fa fa-check"></i><b>8.7</b> Multicollinearity and outliers</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="regression2.html"><a href="regression2.html#outliers"><i class="fa fa-check"></i><b>8.7.1</b> Outliers</a></li>
<li class="chapter" data-level="8.7.2" data-path="regression2.html"><a href="regression2.html#multicollinearity"><i class="fa fa-check"></i><b>8.7.2</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="regression2.html"><a href="regression2.html#designing-new-predictors"><i class="fa fa-check"></i><b>8.8</b> Designing new predictors</a></li>
<li class="chapter" data-level="8.9" data-path="regression2.html"><a href="regression2.html#the-other-sides-of-regression"><i class="fa fa-check"></i><b>8.9</b> The other sides of regression</a></li>
<li class="chapter" data-level="8.10" data-path="regression2.html"><a href="regression2.html#exercises-7"><i class="fa fa-check"></i><b>8.10</b> Exercises</a></li>
<li class="chapter" data-level="8.11" data-path="regression2.html"><a href="regression2.html#additional-resources-4"><i class="fa fa-check"></i><b>8.11</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>9</b> Clustering</a>
<ul>
<li class="chapter" data-level="9.1" data-path="clustering.html"><a href="clustering.html#overview-8"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="clustering.html"><a href="clustering.html#chapter-learning-objectives-8"><i class="fa fa-check"></i><b>9.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="9.3" data-path="clustering.html"><a href="clustering.html#clustering-1"><i class="fa fa-check"></i><b>9.3</b> Clustering</a></li>
<li class="chapter" data-level="9.4" data-path="clustering.html"><a href="clustering.html#an-illustrative-example"><i class="fa fa-check"></i><b>9.4</b> An illustrative example</a></li>
<li class="chapter" data-level="9.5" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>9.5</b> K-means</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="clustering.html"><a href="clustering.html#measuring-cluster-quality"><i class="fa fa-check"></i><b>9.5.1</b> Measuring cluster quality</a></li>
<li class="chapter" data-level="9.5.2" data-path="clustering.html"><a href="clustering.html#the-clustering-algorithm"><i class="fa fa-check"></i><b>9.5.2</b> The clustering algorithm</a></li>
<li class="chapter" data-level="9.5.3" data-path="clustering.html"><a href="clustering.html#random-restarts"><i class="fa fa-check"></i><b>9.5.3</b> Random restarts</a></li>
<li class="chapter" data-level="9.5.4" data-path="clustering.html"><a href="clustering.html#choosing-k"><i class="fa fa-check"></i><b>9.5.4</b> Choosing K</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="clustering.html"><a href="clustering.html#k-means-in-r"><i class="fa fa-check"></i><b>9.6</b> K-means in R</a></li>
<li class="chapter" data-level="9.7" data-path="clustering.html"><a href="clustering.html#exercises-8"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
<li class="chapter" data-level="9.8" data-path="clustering.html"><a href="clustering.html#additional-resources-5"><i class="fa fa-check"></i><b>9.8</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>10</b> Statistical inference</a>
<ul>
<li class="chapter" data-level="10.1" data-path="inference.html"><a href="inference.html#overview-9"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="inference.html"><a href="inference.html#chapter-learning-objectives-9"><i class="fa fa-check"></i><b>10.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="10.3" data-path="inference.html"><a href="inference.html#why-do-we-need-sampling"><i class="fa fa-check"></i><b>10.3</b> Why do we need sampling?</a></li>
<li class="chapter" data-level="10.4" data-path="inference.html"><a href="inference.html#sampling-distributions"><i class="fa fa-check"></i><b>10.4</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="inference.html"><a href="inference.html#sampling-distributions-for-proportions"><i class="fa fa-check"></i><b>10.4.1</b> Sampling distributions for proportions</a></li>
<li class="chapter" data-level="10.4.2" data-path="inference.html"><a href="inference.html#sampling-distributions-for-means"><i class="fa fa-check"></i><b>10.4.2</b> Sampling distributions for means</a></li>
<li class="chapter" data-level="10.4.3" data-path="inference.html"><a href="inference.html#summary-2"><i class="fa fa-check"></i><b>10.4.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="inference.html"><a href="inference.html#bootstrapping"><i class="fa fa-check"></i><b>10.5</b> Bootstrapping</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="inference.html"><a href="inference.html#overview-10"><i class="fa fa-check"></i><b>10.5.1</b> Overview</a></li>
<li class="chapter" data-level="10.5.2" data-path="inference.html"><a href="inference.html#bootstrapping-in-r"><i class="fa fa-check"></i><b>10.5.2</b> Bootstrapping in R</a></li>
<li class="chapter" data-level="10.5.3" data-path="inference.html"><a href="inference.html#using-the-bootstrap-to-calculate-a-plausible-range"><i class="fa fa-check"></i><b>10.5.3</b> Using the bootstrap to calculate a plausible range</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="inference.html"><a href="inference.html#exercises-9"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
<li class="chapter" data-level="10.7" data-path="inference.html"><a href="inference.html#additional-resources-6"><i class="fa fa-check"></i><b>10.7</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="jupyter.html"><a href="jupyter.html"><i class="fa fa-check"></i><b>11</b> Combining code and text with Jupyter</a>
<ul>
<li class="chapter" data-level="11.1" data-path="jupyter.html"><a href="jupyter.html#overview-11"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="jupyter.html"><a href="jupyter.html#chapter-learning-objectives-10"><i class="fa fa-check"></i><b>11.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="11.3" data-path="jupyter.html"><a href="jupyter.html#jupyter-1"><i class="fa fa-check"></i><b>11.3</b> Jupyter</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="jupyter.html"><a href="jupyter.html#accessing-jupyter"><i class="fa fa-check"></i><b>11.3.1</b> Accessing Jupyter</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="jupyter.html"><a href="jupyter.html#code-cells"><i class="fa fa-check"></i><b>11.4</b> Code cells</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="jupyter.html"><a href="jupyter.html#executing-code-cells"><i class="fa fa-check"></i><b>11.4.1</b> Executing code cells</a></li>
<li class="chapter" data-level="11.4.2" data-path="jupyter.html"><a href="jupyter.html#the-kernel"><i class="fa fa-check"></i><b>11.4.2</b> The Kernel</a></li>
<li class="chapter" data-level="11.4.3" data-path="jupyter.html"><a href="jupyter.html#creating-new-code-cells"><i class="fa fa-check"></i><b>11.4.3</b> Creating new code cells</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="jupyter.html"><a href="jupyter.html#markdown-cells"><i class="fa fa-check"></i><b>11.5</b> Markdown cells</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="jupyter.html"><a href="jupyter.html#editing-markdown-cells"><i class="fa fa-check"></i><b>11.5.1</b> Editing Markdown cells</a></li>
<li class="chapter" data-level="11.5.2" data-path="jupyter.html"><a href="jupyter.html#creating-new-markdown-cells"><i class="fa fa-check"></i><b>11.5.2</b> Creating new Markdown cells</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="jupyter.html"><a href="jupyter.html#saving-your-work"><i class="fa fa-check"></i><b>11.6</b> Saving your work</a></li>
<li class="chapter" data-level="11.7" data-path="jupyter.html"><a href="jupyter.html#best-practices-for-running-a-notebook"><i class="fa fa-check"></i><b>11.7</b> Best practices for running a notebook</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="jupyter.html"><a href="jupyter.html#best-practices-for-executing-code-cells"><i class="fa fa-check"></i><b>11.7.1</b> Best practices for executing code cells</a></li>
<li class="chapter" data-level="11.7.2" data-path="jupyter.html"><a href="jupyter.html#best-practices-for-including-r-packages-in-notebooks"><i class="fa fa-check"></i><b>11.7.2</b> Best practices for including R packages in notebooks</a></li>
<li class="chapter" data-level="11.7.3" data-path="jupyter.html"><a href="jupyter.html#summary-of-best-practices-for-running-a-notebook"><i class="fa fa-check"></i><b>11.7.3</b> Summary of best practices for running a notebook</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="jupyter.html"><a href="jupyter.html#exploring-data-files"><i class="fa fa-check"></i><b>11.8</b> Exploring data files</a></li>
<li class="chapter" data-level="11.9" data-path="jupyter.html"><a href="jupyter.html#exporting-to-a-different-file-format"><i class="fa fa-check"></i><b>11.9</b> Exporting to a different file format</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="jupyter.html"><a href="jupyter.html#exporting-to-html"><i class="fa fa-check"></i><b>11.9.1</b> Exporting to HTML</a></li>
<li class="chapter" data-level="11.9.2" data-path="jupyter.html"><a href="jupyter.html#exporting-to-pdf"><i class="fa fa-check"></i><b>11.9.2</b> Exporting to PDF</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="jupyter.html"><a href="jupyter.html#creating-a-new-jupyter-notebook"><i class="fa fa-check"></i><b>11.10</b> Creating a new Jupyter notebook</a></li>
<li class="chapter" data-level="11.11" data-path="jupyter.html"><a href="jupyter.html#additional-resources-7"><i class="fa fa-check"></i><b>11.11</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="version-control.html"><a href="version-control.html"><i class="fa fa-check"></i><b>12</b> Collaboration with version control</a>
<ul>
<li class="chapter" data-level="12.1" data-path="version-control.html"><a href="version-control.html#overview-12"><i class="fa fa-check"></i><b>12.1</b> Overview</a></li>
<li class="chapter" data-level="12.2" data-path="version-control.html"><a href="version-control.html#chapter-learning-objectives-11"><i class="fa fa-check"></i><b>12.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="12.3" data-path="version-control.html"><a href="version-control.html#what-is-version-control-and-why-should-i-use-it"><i class="fa fa-check"></i><b>12.3</b> What is version control, and why should I use it?</a></li>
<li class="chapter" data-level="12.4" data-path="version-control.html"><a href="version-control.html#version-control-repositories"><i class="fa fa-check"></i><b>12.4</b> Version control repositories</a></li>
<li class="chapter" data-level="12.5" data-path="version-control.html"><a href="version-control.html#version-control-workflows"><i class="fa fa-check"></i><b>12.5</b> Version control workflows</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="version-control.html"><a href="version-control.html#commit-changes"><i class="fa fa-check"></i><b>12.5.1</b> Committing changes to a local repository</a></li>
<li class="chapter" data-level="12.5.2" data-path="version-control.html"><a href="version-control.html#pushing-changes-to-a-remote-repository"><i class="fa fa-check"></i><b>12.5.2</b> Pushing changes to a remote repository</a></li>
<li class="chapter" data-level="12.5.3" data-path="version-control.html"><a href="version-control.html#pulling-changes-from-a-remote-repository"><i class="fa fa-check"></i><b>12.5.3</b> Pulling changes from a remote repository</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="version-control.html"><a href="version-control.html#working-with-remote-repositories-using-github"><i class="fa fa-check"></i><b>12.6</b> Working with remote repositories using GitHub</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="version-control.html"><a href="version-control.html#creating-a-remote-repository-on-github"><i class="fa fa-check"></i><b>12.6.1</b> Creating a remote repository on GitHub</a></li>
<li class="chapter" data-level="12.6.2" data-path="version-control.html"><a href="version-control.html#editing-files-on-github-with-the-pen-tool"><i class="fa fa-check"></i><b>12.6.2</b> Editing files on GitHub with the pen tool</a></li>
<li class="chapter" data-level="12.6.3" data-path="version-control.html"><a href="version-control.html#creating-files-on-github-with-the-add-file-menu"><i class="fa fa-check"></i><b>12.6.3</b> Creating files on GitHub with the “Add file” menu</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="version-control.html"><a href="version-control.html#local-repo-jupyter"><i class="fa fa-check"></i><b>12.7</b> Working with local repositories using Jupyter</a>
<ul>
<li class="chapter" data-level="12.7.1" data-path="version-control.html"><a href="version-control.html#generating-a-github-personal-access-token"><i class="fa fa-check"></i><b>12.7.1</b> Generating a GitHub personal access token</a></li>
<li class="chapter" data-level="12.7.2" data-path="version-control.html"><a href="version-control.html#cloning-a-repository-using-jupyter"><i class="fa fa-check"></i><b>12.7.2</b> Cloning a repository using Jupyter</a></li>
<li class="chapter" data-level="12.7.3" data-path="version-control.html"><a href="version-control.html#specifying-files-to-commit"><i class="fa fa-check"></i><b>12.7.3</b> Specifying files to commit</a></li>
<li class="chapter" data-level="12.7.4" data-path="version-control.html"><a href="version-control.html#making-the-commit"><i class="fa fa-check"></i><b>12.7.4</b> Making the commit</a></li>
<li class="chapter" data-level="12.7.5" data-path="version-control.html"><a href="version-control.html#pushing-the-commits-to-github"><i class="fa fa-check"></i><b>12.7.5</b> Pushing the commits to GitHub</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="version-control.html"><a href="version-control.html#collaboration"><i class="fa fa-check"></i><b>12.8</b> Collaboration</a>
<ul>
<li class="chapter" data-level="12.8.1" data-path="version-control.html"><a href="version-control.html#giving-collaborators-access-to-your-project"><i class="fa fa-check"></i><b>12.8.1</b> Giving collaborators access to your project</a></li>
<li class="chapter" data-level="12.8.2" data-path="version-control.html"><a href="version-control.html#pulling-changes-from-github-using-jupyter"><i class="fa fa-check"></i><b>12.8.2</b> Pulling changes from GitHub using Jupyter</a></li>
<li class="chapter" data-level="12.8.3" data-path="version-control.html"><a href="version-control.html#handling-merge-conflicts"><i class="fa fa-check"></i><b>12.8.3</b> Handling merge conflicts</a></li>
<li class="chapter" data-level="12.8.4" data-path="version-control.html"><a href="version-control.html#communicating-using-github-issues"><i class="fa fa-check"></i><b>12.8.4</b> Communicating using GitHub issues</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="version-control.html"><a href="version-control.html#exercises-10"><i class="fa fa-check"></i><b>12.9</b> Exercises</a></li>
<li class="chapter" data-level="12.10" data-path="version-control.html"><a href="version-control.html#vc-add-res"><i class="fa fa-check"></i><b>12.10</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="setup.html"><a href="setup.html"><i class="fa fa-check"></i><b>13</b> Setting up your computer</a>
<ul>
<li class="chapter" data-level="13.1" data-path="setup.html"><a href="setup.html#overview-13"><i class="fa fa-check"></i><b>13.1</b> Overview</a></li>
<li class="chapter" data-level="13.2" data-path="setup.html"><a href="setup.html#chapter-learning-objectives-12"><i class="fa fa-check"></i><b>13.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="13.3" data-path="setup.html"><a href="setup.html#obtaining-the-worksheets-for-this-book"><i class="fa fa-check"></i><b>13.3</b> Obtaining the worksheets for this book</a></li>
<li class="chapter" data-level="13.4" data-path="setup.html"><a href="setup.html#working-with-docker"><i class="fa fa-check"></i><b>13.4</b> Working with Docker</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="setup.html"><a href="setup.html#windows"><i class="fa fa-check"></i><b>13.4.1</b> Windows</a></li>
<li class="chapter" data-level="13.4.2" data-path="setup.html"><a href="setup.html#macos"><i class="fa fa-check"></i><b>13.4.2</b> MacOS</a></li>
<li class="chapter" data-level="13.4.3" data-path="setup.html"><a href="setup.html#ubuntu"><i class="fa fa-check"></i><b>13.4.3</b> Ubuntu</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="setup.html"><a href="setup.html#working-with-jupyterlab-desktop"><i class="fa fa-check"></i><b>13.5</b> Working with JupyterLab Desktop</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="setup.html"><a href="setup.html#windows-1"><i class="fa fa-check"></i><b>13.5.1</b> Windows</a></li>
<li class="chapter" data-level="13.5.2" data-path="setup.html"><a href="setup.html#macos-1"><i class="fa fa-check"></i><b>13.5.2</b> MacOS</a></li>
<li class="chapter" data-level="13.5.3" data-path="setup.html"><a href="setup.html#ubuntu-1"><i class="fa fa-check"></i><b>13.5.3</b> Ubuntu</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><p><img src="img/frontmatter/ds-a-first-intro-graphic.jpg" />
Data Science</p></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification2" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Chapter 6</span> Classification II: evaluation &amp; tuning<a href="classification2.html#classification2" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="overview-5" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Overview<a href="classification2.html#overview-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This chapter continues the introduction to predictive modeling through
classification. While the previous chapter covered training and data
preprocessing, this chapter focuses on how to evaluate the performance of
a classifier, as well as how to improve the classifier (where possible)
to maximize its accuracy.</p>
</div>
<div id="chapter-learning-objectives-5" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Chapter learning objectives<a href="classification2.html#chapter-learning-objectives-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>By the end of the chapter, readers will be able to do the following:</p>
<ul>
<li>Describe what training, validation, and test data sets are and how they are used in classification.</li>
<li>Split data into training, validation, and test data sets.</li>
<li>Describe what a random seed is and its importance in reproducible data analysis.</li>
<li>Set the random seed in R using the <code>set.seed</code> function.</li>
<li>Describe and interpret accuracy, precision, recall, and confusion matrices.</li>
<li>Evaluate classification accuracy, precision, and recall in R using a test set, a single validation set, and cross-validation.</li>
<li>Produce a confusion matrix in R.</li>
<li>Choose the number of neighbors in a K-nearest neighbors classifier by maximizing estimated cross-validation accuracy.</li>
<li>Describe underfitting and overfitting, and relate it to the number of neighbors in K-nearest neighbors classification.</li>
<li>Describe the advantages and disadvantages of the K-nearest neighbors classification algorithm.</li>
</ul>
</div>
<div id="evaluating-performance" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Evaluating performance<a href="classification2.html#evaluating-performance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sometimes our classifier might make the wrong prediction. A classifier does not
need to be right 100% of the time to be useful, though we don’t want the
classifier to make too many wrong predictions. How do we measure how “good” our
classifier is? Let’s revisit the
<a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29">breast cancer images data</a> <span class="citation">(<a href="#ref-streetbreastcancer">Street, Wolberg, and Mangasarian 1993</a>)</span>
and think about how our classifier will be used in practice. A biopsy will be
performed on a <em>new</em> patient’s tumor, the resulting image will be analyzed,
and the classifier will be asked to decide whether the tumor is benign or
malignant. The key word here is <em>new</em>: our classifier is “good” if it provides
accurate predictions on data <em>not seen during training</em>, as this implies that
it has actually learned about the relationship between the predictor variables and response variable,
as opposed to simply memorizing the labels of individual training data examples.
But then, how can we evaluate our classifier without visiting the hospital to collect more
tumor images?</p>
<p>The trick is to split the data into a <strong>training set</strong> and <strong>test set</strong> (Figure <a href="classification2.html#fig:06-training-test">6.1</a>)
and use only the <strong>training set</strong> when building the classifier.
Then, to evaluate the performance of the classifier, we first set aside the labels from the <strong>test set</strong>,
and then use the classifier to predict the labels in the <strong>test set</strong>. If our predictions match the actual
labels for the observations in the <strong>test set</strong>, then we have some
confidence that our classifier might also accurately predict the class
labels for new observations without known class labels.</p>
<blockquote>
<p><strong>Note:</strong> If there were a golden rule of machine learning, it might be this:
<em>you cannot use the test data to build the model!</em> If you do, the model gets to
“see” the test data in advance, making it look more accurate than it really
is. Imagine how bad it would be to overestimate your classifier’s accuracy
when predicting whether a patient’s tumor is malignant or benign!</p>
</blockquote>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-training-test"></span>
<img src="img/classification2/training_test.png" alt="Splitting the data into training and testing sets." width="100%" />
<p class="caption">
Figure 6.1: Splitting the data into training and testing sets.
</p>
</div>
<p>How exactly can we assess how well our predictions match the actual labels for
the observations in the test set? One way we can do this is to calculate the
prediction <strong>accuracy</strong>. This is the fraction of examples for which the
classifier made the correct prediction. To calculate this, we divide the number
of correct predictions by the number of predictions made.
The process for assessing if our predictions match the actual labels in the
test set is illustrated in Figure <a href="classification2.html#fig:06-ML-paradigm-test">6.2</a>.</p>
<p><span class="math display">\[\mathrm{accuracy} = \frac{\mathrm{number \; of  \; correct  \; predictions}}{\mathrm{total \;  number \;  of  \; predictions}}\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-ML-paradigm-test"></span>
<img src="img/classification2/ML-paradigm-test.png" alt="Process for splitting the data and finding the prediction accuracy." width="100%" />
<p class="caption">
Figure 6.2: Process for splitting the data and finding the prediction accuracy.
</p>
</div>
<p>Accuracy is a convenient, general-purpose way to summarize the performance of a classifier with
a single number. But prediction accuracy by itself does not tell the whole
story. In particular, accuracy alone only tells us how often the classifier
makes mistakes in general, but does not tell us anything about the <em>kinds</em> of
mistakes the classifier makes. A more comprehensive view of performance can be
obtained by additionally examining the <strong>confusion matrix</strong>. The confusion
matrix shows how many test set labels of each type are predicted correctly and
incorrectly, which gives us more detail about the kinds of mistakes the
classifier tends to make. Table <a href="classification2.html#tab:confusion-matrix">6.1</a> shows an example
of what a confusion matrix might look like for the tumor image data with
a test set of 65 observations.</p>
<table>
<caption><span id="tab:confusion-matrix">Table 6.1: </span> An example confusion matrix for the tumor image data.</caption>
<thead>
<tr class="header">
<th></th>
<th>Actually Malignant</th>
<th>Actually Benign</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Predicted Malignant</strong></td>
<td>1</td>
<td>4</td>
</tr>
<tr class="even">
<td><strong>Predicted Benign</strong></td>
<td>3</td>
<td>57</td>
</tr>
</tbody>
</table>
<p>In the example in Table <a href="classification2.html#tab:confusion-matrix">6.1</a>, we see that there was
1 malignant observation that was correctly classified as malignant (top left corner),
and 57 benign observations that were correctly classified as benign (bottom right corner).
However, we can also see that the classifier made some mistakes:
it classified 3 malignant observations as benign, and 4 benign observations as
malignant. The accuracy of this classifier is roughly
89%, given by the formula</p>
<p><span class="math display">\[\mathrm{accuracy} = \frac{\mathrm{number \; of  \; correct  \; predictions}}{\mathrm{total \;  number \;  of  \; predictions}} = \frac{1+57}{1+57+4+3} = 0.892.\]</span></p>
<p>But we can also see that the classifier only identified 1 out of 4 total malignant
tumors; in other words, it misclassified 75% of the malignant cases present in the
data set! In this example, misclassifying a malignant tumor is a potentially
disastrous error, since it may lead to a patient who requires treatment not receiving it.
Since we are particularly interested in identifying malignant cases, this
classifier would likely be unacceptable even with an accuracy of 89%.</p>
<p>Focusing more on one label than the other
is
common in classification problems. In such cases, we typically refer to the label we are more
interested in identifying as the <em>positive</em> label, and the other as the
<em>negative</em> label. In the tumor example, we would refer to malignant
observations as <em>positive</em>, and benign observations as <em>negative</em>. We can then
use the following terms to talk about the four kinds of prediction that the
classifier can make, corresponding to the four entries in the confusion matrix:</p>
<ul>
<li><strong>True Positive:</strong> A malignant observation that was classified as malignant (top left in Table <a href="classification2.html#tab:confusion-matrix">6.1</a>).</li>
<li><strong>False Positive:</strong> A benign observation that was classified as malignant (top right in Table <a href="classification2.html#tab:confusion-matrix">6.1</a>).</li>
<li><strong>True Negative:</strong> A benign observation that was classified as benign (bottom right in Table <a href="classification2.html#tab:confusion-matrix">6.1</a>).</li>
<li><strong>False Negative:</strong> A malignant observation that was classified as benign (bottom left in Table <a href="classification2.html#tab:confusion-matrix">6.1</a>).</li>
</ul>
<p>A perfect classifier would have zero false negatives and false positives (and
therefore, 100% accuracy). However, classifiers in practice will almost always
make some errors. So you should think about which kinds of error are most
important in your application, and use the confusion matrix to quantify and
report them. Two commonly used metrics that we can compute using the confusion
matrix are the <strong>precision</strong> and <strong>recall</strong> of the classifier. These are often
reported together with accuracy. <em>Precision</em> quantifies how many of the
positive predictions the classifier made were actually positive. Intuitively,
we would like a classifier to have a <em>high</em> precision: for a classifier with
high precision, if the classifier reports that a new observation is positive,
we can trust that the new observation is indeed positive. We can compute the
precision of a classifier using the entries in the confusion matrix, with the
formula</p>
<p><span class="math display">\[\mathrm{precision} = \frac{\mathrm{number \; of  \; correct \; positive \; predictions}}{\mathrm{total \;  number \;  of \; positive  \; predictions}}.\]</span></p>
<p><em>Recall</em> quantifies how many of the positive observations in the test set were
identified as positive. Intuitively, we would like a classifier to have a
<em>high</em> recall: for a classifier with high recall, if there is a positive
observation in the test data, we can trust that the classifier will find it.
We can also compute the recall of the classifier using the entries in the
confusion matrix, with the formula</p>
<p><span class="math display">\[\mathrm{recall} = \frac{\mathrm{number \; of  \; correct  \; positive \; predictions}}{\mathrm{total \;  number \;  of  \; positive \; test \; set \; observations}}.\]</span></p>
<p>In the example presented in Table <a href="classification2.html#tab:confusion-matrix">6.1</a>, we have that the precision and recall are</p>
<p><span class="math display">\[\mathrm{precision} = \frac{1}{1+4} = 0.20, \quad \mathrm{recall} = \frac{1}{1+3} = 0.25.\]</span></p>
<p>So even with an accuracy of 89%, the precision and recall of the classifier
were both relatively low. For this data analysis context, recall is
particularly important: if someone has a malignant tumor, we certainly want to
identify it. A recall of just 25% would likely be unacceptable!</p>
<blockquote>
<p><strong>Note:</strong> It is difficult to achieve both high precision and high recall at
the same time; models with high precision tend to have low recall and vice
versa. As an example, we can easily make a classifier that has <em>perfect
recall</em>: just <em>always</em> guess positive! This classifier will of course find
every positive observation in the test set, but it will make lots of false
positive predictions along the way and have low precision. Similarly, we can
easily make a classifier that has <em>perfect precision</em>: <em>never</em> guess
positive! This classifier will never incorrectly identify an obsevation as
positive, but it will make a lot of false negative predictions along the way.
In fact, this classifier will have 0% recall! Of course, most real
classifiers fall somewhere in between these two extremes. But these examples
serve to show that in settings where one of the classes is of interest (i.e.,
there is a <em>positive</em> label), there is a trade-off between precision and recall that one has to
make when designing a classifier.</p>
</blockquote>
</div>
<div id="randomseeds" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Randomness and seeds<a href="classification2.html#randomseeds" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Beginning in this chapter, our data analyses will often involve the use
of <em>randomness</em>. We use randomness any time we need to make a decision in our
analysis that needs to be fair, unbiased, and not influenced by human input.
For example, in this chapter, we need to split
a data set into a training set and test set to evaluate our classifier. We
certainly do not want to choose how to split
the data ourselves by hand, as we want to avoid accidentally influencing the result
of the evaluation. So instead, we let R <em>randomly</em> split the data.
In future chapters we will use randomness
in many other ways, e.g., to help us select a small subset of data from a larger data set,
to pick groupings of data, and more.</p>
<p>However, the use of randomness runs counter to one of the main
tenets of good data analysis practice: <em>reproducibility</em>. Recall that a reproducible
analysis produces the same result each time it is run; if we include randomness
in the analysis, would we not get a different result each time?
The trick is that in R—and other programming languages—randomness
is not actually random! Instead, R uses a <em>random number generator</em> that
produces a sequence of numbers that
are completely determined by a
<em>seed value</em>. Once you set the seed value
using the <code>set.seed</code> function, everything after that point may <em>look</em> random,
but is actually totally reproducible. As long as you pick the same seed
value, you get the same result!</p>
<p>Let’s use an example to investigate how seeds work in R. Say we want
to randomly pick 10 numbers from 0 to 9 in R using the <code>sample</code> function,
but we want it to be reproducible. Before using the sample function,
we call <code>set.seed</code>, and pass it any integer as an argument.
Here, we pass in the number <code>1</code>.</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="classification2.html#cb314-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb314-2"><a href="classification2.html#cb314-2" tabindex="-1"></a>random_numbers1 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb314-3"><a href="classification2.html#cb314-3" tabindex="-1"></a>random_numbers1</span></code></pre></div>
<pre><code>##  [1] 8 3 6 0 1 6 1 2 0 4</code></pre>
<p>You can see that <code>random_numbers1</code> is a list of 10 numbers
from 0 to 9 that, from all appearances, looks random. If
we run the <code>sample</code> function again, we will
get a fresh batch of 10 numbers that also look random.</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="classification2.html#cb316-1" tabindex="-1"></a>random_numbers2 <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb316-2"><a href="classification2.html#cb316-2" tabindex="-1"></a>random_numbers2</span></code></pre></div>
<pre><code>##  [1] 4 9 5 9 6 8 4 4 8 8</code></pre>
<p>If we want to force R to produce the same sequences of random numbers,
we can simply call the <code>set.seed</code> function again with the same argument
value.</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="classification2.html#cb318-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb318-2"><a href="classification2.html#cb318-2" tabindex="-1"></a>random_numbers1_again <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb318-3"><a href="classification2.html#cb318-3" tabindex="-1"></a>random_numbers1_again</span></code></pre></div>
<pre><code>##  [1] 8 3 6 0 1 6 1 2 0 4</code></pre>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="classification2.html#cb320-1" tabindex="-1"></a>random_numbers2_again <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb320-2"><a href="classification2.html#cb320-2" tabindex="-1"></a>random_numbers2_again</span></code></pre></div>
<pre><code>##  [1] 4 9 5 9 6 8 4 4 8 8</code></pre>
<p>Notice that after setting the seed, we get the same two sequences of numbers in the same order. <code>random_numbers1</code> and <code>random_numbers1_again</code> produce the same sequence of numbers, and the same can be said about <code>random_numbers2</code> and <code>random_numbers2_again</code>. And if we choose
a different value for the seed—say, 4235—we
obtain a different sequence of random numbers.</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="classification2.html#cb322-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4235</span>)</span>
<span id="cb322-2"><a href="classification2.html#cb322-2" tabindex="-1"></a>random_numbers1_different <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb322-3"><a href="classification2.html#cb322-3" tabindex="-1"></a>random_numbers1_different</span></code></pre></div>
<pre><code>##  [1] 8 3 1 4 6 8 8 4 1 7</code></pre>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="classification2.html#cb324-1" tabindex="-1"></a>random_numbers2_different <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">10</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb324-2"><a href="classification2.html#cb324-2" tabindex="-1"></a>random_numbers2_different</span></code></pre></div>
<pre><code>##  [1] 3 7 8 2 8 8 6 3 3 8</code></pre>
<p>In other words, even though the sequences of numbers that R is generating <em>look</em>
random, they are totally determined when we set a seed value!</p>
<p>So what does this mean for data analysis? Well, <code>sample</code> is certainly
not the only function that uses randomness in R. Many of the functions
that we use in <code>tidymodels</code>, <code>tidyverse</code>, and beyond use randomness—some of them
without even telling you about it. So at the beginning of every data analysis you
do, right after loading packages, you should call the <code>set.seed</code> function and
pass it an integer that you pick.
Also note that when R starts up, it creates its own seed to use. So if you do not
explicitly call the <code>set.seed</code> function in your code, your results will
likely not be reproducible.
And finally, be careful to set the seed <em>only once</em> at the beginning of a data
analysis. Each time you set the seed, you are inserting your own human input,
thereby influencing the analysis. If you use <code>set.seed</code> many times
throughout your analysis, the randomness that R uses will not look
as random as it should.</p>
<p>In summary: if you want your analysis to be reproducible, i.e., produce <em>the same result</em> each time you
run it, make sure to use <code>set.seed</code> exactly once at the beginning of the analysis.
Different argument values in <code>set.seed</code> lead to different patterns of randomness, but as long as
you pick the same argument value your result will be the same.
In the remainder of the textbook, we will set the seed once at the beginning of each chapter.</p>
</div>
<div id="evaluating-performance-with-tidymodels" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Evaluating performance with <code>tidymodels</code><a href="classification2.html#evaluating-performance-with-tidymodels" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Back to evaluating classifiers now!
In R, we can use the <code>tidymodels</code> package not only to perform K-nearest neighbors
classification, but also to assess how well our classification worked.
Let’s work through an example of how to use tools from <code>tidymodels</code> to evaluate a classifier
using the breast cancer data set from the previous chapter.
We begin the analysis by loading the packages we require,
reading in the breast cancer data,
and then making a quick scatter plot visualization of
tumor cell concavity versus smoothness colored by diagnosis in Figure <a href="classification2.html#fig:06-precode">6.3</a>.
You will also notice that we set the random seed here at the beginning of the analysis
using the <code>set.seed</code> function, as described in Section <a href="classification2.html#randomseeds">6.4</a>.</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="classification2.html#cb326-1" tabindex="-1"></a><span class="co"># load packages</span></span>
<span id="cb326-2"><a href="classification2.html#cb326-2" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb326-3"><a href="classification2.html#cb326-3" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb326-4"><a href="classification2.html#cb326-4" tabindex="-1"></a></span>
<span id="cb326-5"><a href="classification2.html#cb326-5" tabindex="-1"></a><span class="co"># set the seed</span></span>
<span id="cb326-6"><a href="classification2.html#cb326-6" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb326-7"><a href="classification2.html#cb326-7" tabindex="-1"></a></span>
<span id="cb326-8"><a href="classification2.html#cb326-8" tabindex="-1"></a><span class="co"># load data</span></span>
<span id="cb326-9"><a href="classification2.html#cb326-9" tabindex="-1"></a>cancer <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/wdbc_unscaled.csv&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb326-10"><a href="classification2.html#cb326-10" tabindex="-1"></a>  <span class="co"># convert the character Class variable to the factor datatype</span></span>
<span id="cb326-11"><a href="classification2.html#cb326-11" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Class =</span> <span class="fu">as_factor</span>(Class))  <span class="sc">|&gt;</span></span>
<span id="cb326-12"><a href="classification2.html#cb326-12" tabindex="-1"></a>  <span class="co"># rename the factor values to be more readable</span></span>
<span id="cb326-13"><a href="classification2.html#cb326-13" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Class =</span> <span class="fu">fct_recode</span>(Class, <span class="st">&quot;Malignant&quot;</span> <span class="ot">=</span> <span class="st">&quot;M&quot;</span>, <span class="st">&quot;Benign&quot;</span> <span class="ot">=</span> <span class="st">&quot;B&quot;</span>))</span>
<span id="cb326-14"><a href="classification2.html#cb326-14" tabindex="-1"></a></span>
<span id="cb326-15"><a href="classification2.html#cb326-15" tabindex="-1"></a><span class="co"># create scatter plot of tumor cell concavity versus smoothness,</span></span>
<span id="cb326-16"><a href="classification2.html#cb326-16" tabindex="-1"></a><span class="co"># labeling the points be diagnosis class</span></span>
<span id="cb326-17"><a href="classification2.html#cb326-17" tabindex="-1"></a>perim_concav <span class="ot">&lt;-</span> cancer <span class="sc">|&gt;</span></span>
<span id="cb326-18"><a href="classification2.html#cb326-18" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Smoothness, <span class="at">y =</span> Concavity, <span class="at">color =</span> Class)) <span class="sc">+</span></span>
<span id="cb326-19"><a href="classification2.html#cb326-19" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb326-20"><a href="classification2.html#cb326-20" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color =</span> <span class="st">&quot;Diagnosis&quot;</span>) <span class="sc">+</span></span>
<span id="cb326-21"><a href="classification2.html#cb326-21" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;darkorange&quot;</span>, <span class="st">&quot;steelblue&quot;</span>)) <span class="sc">+</span></span>
<span id="cb326-22"><a href="classification2.html#cb326-22" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span>
<span id="cb326-23"><a href="classification2.html#cb326-23" tabindex="-1"></a></span>
<span id="cb326-24"><a href="classification2.html#cb326-24" tabindex="-1"></a>perim_concav</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-precode"></span>
<img src="_main_files/figure-html/06-precode-1.png" alt="Scatter plot of tumor cell concavity versus smoothness colored by diagnosis label." width="432" />
<p class="caption">
Figure 6.3: Scatter plot of tumor cell concavity versus smoothness colored by diagnosis label.
</p>
</div>
<div id="create-the-train-test-split" class="section level3 hasAnchor" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Create the train / test split<a href="classification2.html#create-the-train-test-split" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Once we have decided on a predictive question to answer and done some
preliminary exploration, the very next thing to do is to split the data into
the training and test sets. Typically, the training set is between 50% and 95% of
the data, while the test set is the remaining 5% to 50%; the intuition is that
you want to trade off between training an accurate model (by using a larger
training data set) and getting an accurate evaluation of its performance (by
using a larger test data set). Here, we will use 75% of the data for training,
and 25% for testing.</p>
<p>The <code>initial_split</code> function from <code>tidymodels</code> handles the procedure of splitting
the data for us. It also applies two very important steps when splitting to ensure
that the accuracy estimates from the test data are reasonable. First, it
<strong>shuffles</strong> the data before splitting, which ensures that any ordering present
in the data does not influence the data that ends up in the training and testing sets.
Second, it <strong>stratifies</strong> the data by the class label, to ensure that roughly
the same proportion of each class ends up in both the training and testing sets. For example,
in our data set, roughly 63% of the
observations are from the benign class, and 37% are from the malignant class,
so <code>initial_split</code> ensures that roughly 63% of the training data are benign,
37% of the training data are malignant,
and the same proportions exist in the testing data.</p>
<p>Let’s use the <code>initial_split</code> function to create the training and testing sets.
We will specify that <code>prop = 0.75</code> so that 75% of our original data set ends up
in the training set. We will also set the <code>strata</code> argument to the categorical label variable
(here, <code>Class</code>) to ensure that the training and testing subsets contain the
right proportions of each category of observation.
The <code>training</code> and <code>testing</code> functions then extract the training and testing
data sets into two separate data frames.
Note that the <code>initial_split</code> function uses randomness, but since we set the
seed earlier in the chapter, the split will be reproducible.</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="classification2.html#cb327-1" tabindex="-1"></a>cancer_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(cancer, <span class="at">prop =</span> <span class="fl">0.75</span>, <span class="at">strata =</span> Class)</span>
<span id="cb327-2"><a href="classification2.html#cb327-2" tabindex="-1"></a>cancer_train <span class="ot">&lt;-</span> <span class="fu">training</span>(cancer_split)</span>
<span id="cb327-3"><a href="classification2.html#cb327-3" tabindex="-1"></a>cancer_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(cancer_split)</span></code></pre></div>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="classification2.html#cb328-1" tabindex="-1"></a><span class="fu">glimpse</span>(cancer_train)</span></code></pre></div>
<pre><code>## Rows: 426
## Columns: 12
## $ ID                &lt;dbl&gt; 8510426, 8510653, 8510824, 854941, 85713702, 857155,…
## $ Class             &lt;fct&gt; Benign, Benign, Benign, Benign, Benign, Benign, Beni…
## $ Radius            &lt;dbl&gt; 13.540, 13.080, 9.504, 13.030, 8.196, 12.050, 13.490…
## $ Texture           &lt;dbl&gt; 14.36, 15.71, 12.44, 18.42, 16.84, 14.63, 22.30, 21.…
## $ Perimeter         &lt;dbl&gt; 87.46, 85.63, 60.34, 82.61, 51.71, 78.04, 86.91, 74.…
## $ Area              &lt;dbl&gt; 566.3, 520.0, 273.9, 523.8, 201.9, 449.3, 561.0, 427…
## $ Smoothness        &lt;dbl&gt; 0.09779, 0.10750, 0.10240, 0.08983, 0.08600, 0.10310…
## $ Compactness       &lt;dbl&gt; 0.08129, 0.12700, 0.06492, 0.03766, 0.05943, 0.09092…
## $ Concavity         &lt;dbl&gt; 0.066640, 0.045680, 0.029560, 0.025620, 0.015880, 0.…
## $ Concave_Points    &lt;dbl&gt; 0.047810, 0.031100, 0.020760, 0.029230, 0.005917, 0.…
## $ Symmetry          &lt;dbl&gt; 0.1885, 0.1967, 0.1815, 0.1467, 0.1769, 0.1675, 0.18…
## $ Fractal_Dimension &lt;dbl&gt; 0.05766, 0.06811, 0.06905, 0.05863, 0.06503, 0.06043…</code></pre>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="classification2.html#cb330-1" tabindex="-1"></a><span class="fu">glimpse</span>(cancer_test)</span></code></pre></div>
<pre><code>## Rows: 143
## Columns: 12
## $ ID                &lt;dbl&gt; 842517, 84300903, 84501001, 84610002, 848406, 848620…
## $ Class             &lt;fct&gt; Malignant, Malignant, Malignant, Malignant, Malignan…
## $ Radius            &lt;dbl&gt; 20.570, 19.690, 12.460, 15.780, 14.680, 16.130, 19.8…
## $ Texture           &lt;dbl&gt; 17.77, 21.25, 24.04, 17.89, 20.13, 20.68, 22.15, 14.…
## $ Perimeter         &lt;dbl&gt; 132.90, 130.00, 83.97, 103.60, 94.74, 108.10, 130.00…
## $ Area              &lt;dbl&gt; 1326.0, 1203.0, 475.9, 781.0, 684.5, 798.8, 1260.0, …
## $ Smoothness        &lt;dbl&gt; 0.08474, 0.10960, 0.11860, 0.09710, 0.09867, 0.11700…
## $ Compactness       &lt;dbl&gt; 0.07864, 0.15990, 0.23960, 0.12920, 0.07200, 0.20220…
## $ Concavity         &lt;dbl&gt; 0.08690, 0.19740, 0.22730, 0.09954, 0.07395, 0.17220…
## $ Concave_Points    &lt;dbl&gt; 0.070170, 0.127900, 0.085430, 0.066060, 0.052590, 0.…
## $ Symmetry          &lt;dbl&gt; 0.1812, 0.2069, 0.2030, 0.1842, 0.1586, 0.2164, 0.15…
## $ Fractal_Dimension &lt;dbl&gt; 0.05667, 0.05999, 0.08243, 0.06082, 0.05922, 0.07356…</code></pre>
<p>We can see from <code>glimpse</code> in the code above that the training set contains 426
observations, while the test set contains 143 observations. This corresponds to
a train / test split of 75% / 25%, as desired. Recall from Chapter <a href="classification1.html#classification1">5</a>
that we use the <code>glimpse</code> function to view data with a large number of columns,
as it prints the data such that the columns go down the page (instead of across).</p>
<p>We can use <code>group_by</code> and <code>summarize</code> to find the percentage of malignant and benign classes
in <code>cancer_train</code> and we see about 63% of the training
data are benign and 37%
are malignant, indicating that our class proportions were roughly preserved when we split the data.</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="classification2.html#cb332-1" tabindex="-1"></a>cancer_proportions <span class="ot">&lt;-</span> cancer_train <span class="sc">|&gt;</span></span>
<span id="cb332-2"><a href="classification2.html#cb332-2" tabindex="-1"></a>                      <span class="fu">group_by</span>(Class) <span class="sc">|&gt;</span></span>
<span id="cb332-3"><a href="classification2.html#cb332-3" tabindex="-1"></a>                      <span class="fu">summarize</span>(<span class="at">n =</span> <span class="fu">n</span>()) <span class="sc">|&gt;</span></span>
<span id="cb332-4"><a href="classification2.html#cb332-4" tabindex="-1"></a>                      <span class="fu">mutate</span>(<span class="at">percent =</span> <span class="dv">100</span><span class="sc">*</span>n<span class="sc">/</span><span class="fu">nrow</span>(cancer_train))</span>
<span id="cb332-5"><a href="classification2.html#cb332-5" tabindex="-1"></a></span>
<span id="cb332-6"><a href="classification2.html#cb332-6" tabindex="-1"></a>cancer_proportions</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   Class         n percent
##   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;
## 1 Malignant   159    37.3
## 2 Benign      267    62.7</code></pre>
</div>
<div id="preprocess-the-data" class="section level3 hasAnchor" number="6.5.2">
<h3><span class="header-section-number">6.5.2</span> Preprocess the data<a href="classification2.html#preprocess-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As we mentioned in the last chapter, K-nearest neighbors is sensitive to the scale of the predictors,
so we should perform some preprocessing to standardize them. An
additional consideration we need to take when doing this is that we should
create the standardization preprocessor using <strong>only the training data</strong>. This ensures that
our test data does not influence any aspect of our model training. Once we have
created the standardization preprocessor, we can then apply it separately to both the
training and test data sets.</p>
<p>Fortunately, the <code>recipe</code> framework from <code>tidymodels</code> helps us handle
this properly. Below we construct and prepare the recipe using only the training
data (due to <code>data = cancer_train</code> in the first line).</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="classification2.html#cb334-1" tabindex="-1"></a>cancer_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Class <span class="sc">~</span> Smoothness <span class="sc">+</span> Concavity, <span class="at">data =</span> cancer_train) <span class="sc">|&gt;</span></span>
<span id="cb334-2"><a href="classification2.html#cb334-2" tabindex="-1"></a>  <span class="fu">step_scale</span>(<span class="fu">all_predictors</span>()) <span class="sc">|&gt;</span></span>
<span id="cb334-3"><a href="classification2.html#cb334-3" tabindex="-1"></a>  <span class="fu">step_center</span>(<span class="fu">all_predictors</span>())</span></code></pre></div>
</div>
<div id="train-the-classifier" class="section level3 hasAnchor" number="6.5.3">
<h3><span class="header-section-number">6.5.3</span> Train the classifier<a href="classification2.html#train-the-classifier" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we have split our original data set into training and test sets, we
can create our K-nearest neighbors classifier with only the training set using
the technique we learned in the previous chapter. For now, we will just choose
the number <span class="math inline">\(K\)</span> of neighbors to be 3, and use concavity and smoothness as the
predictors. As before we need to create a model specification, combine
the model specification and recipe into a workflow, and then finally
use <code>fit</code> with the training data <code>cancer_train</code> to build the classifier.</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="classification2.html#cb335-1" tabindex="-1"></a>knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">weight_func =</span> <span class="st">&quot;rectangular&quot;</span>, <span class="at">neighbors =</span> <span class="dv">3</span>) <span class="sc">|&gt;</span></span>
<span id="cb335-2"><a href="classification2.html#cb335-2" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb335-3"><a href="classification2.html#cb335-3" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb335-4"><a href="classification2.html#cb335-4" tabindex="-1"></a></span>
<span id="cb335-5"><a href="classification2.html#cb335-5" tabindex="-1"></a>knn_fit <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb335-6"><a href="classification2.html#cb335-6" tabindex="-1"></a>  <span class="fu">add_recipe</span>(cancer_recipe) <span class="sc">|&gt;</span></span>
<span id="cb335-7"><a href="classification2.html#cb335-7" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec) <span class="sc">|&gt;</span></span>
<span id="cb335-8"><a href="classification2.html#cb335-8" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> cancer_train)</span>
<span id="cb335-9"><a href="classification2.html#cb335-9" tabindex="-1"></a></span>
<span id="cb335-10"><a href="classification2.html#cb335-10" tabindex="-1"></a>knn_fit</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ══════════
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## ── Preprocessor ──────────
## 2 Recipe Steps
## 
## • step_scale()
## • step_center()
## 
## ── Model ──────────
## 
## Call:
## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(3,     data, 5), 
## kernel = ~&quot;rectangular&quot;)
## 
## Type of response variable: nominal
## Minimal misclassification: 0.1126761
## Best kernel: rectangular
## Best k: 3</code></pre>
</div>
<div id="predict-the-labels-in-the-test-set" class="section level3 hasAnchor" number="6.5.4">
<h3><span class="header-section-number">6.5.4</span> Predict the labels in the test set<a href="classification2.html#predict-the-labels-in-the-test-set" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we have a K-nearest neighbors classifier object, we can use it to
predict the class labels for our test set. We use the <code>bind_cols</code> to add the
column of predictions to the original test data, creating the
<code>cancer_test_predictions</code> data frame. The <code>Class</code> variable contains the actual
diagnoses, while the <code>.pred_class</code> contains the predicted diagnoses from the
classifier.</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="classification2.html#cb337-1" tabindex="-1"></a>cancer_test_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit, cancer_test) <span class="sc">|&gt;</span></span>
<span id="cb337-2"><a href="classification2.html#cb337-2" tabindex="-1"></a>  <span class="fu">bind_cols</span>(cancer_test)</span>
<span id="cb337-3"><a href="classification2.html#cb337-3" tabindex="-1"></a></span>
<span id="cb337-4"><a href="classification2.html#cb337-4" tabindex="-1"></a>cancer_test_predictions</span></code></pre></div>
<pre><code>## # A tibble: 143 × 13
##    .pred_class       ID Class     Radius Texture Perimeter  Area Smoothness
##    &lt;fct&gt;          &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;
##  1 Benign        842517 Malignant   20.6    17.8     133.  1326      0.0847
##  2 Malignant   84300903 Malignant   19.7    21.2     130   1203      0.110 
##  3 Malignant   84501001 Malignant   12.5    24.0      84.0  476.     0.119 
##  4 Malignant   84610002 Malignant   15.8    17.9     104.   781      0.0971
##  5 Benign        848406 Malignant   14.7    20.1      94.7  684.     0.0987
##  6 Malignant   84862001 Malignant   16.1    20.7     108.   799.     0.117 
##  7 Malignant     849014 Malignant   19.8    22.2     130   1260      0.0983
##  8 Malignant    8511133 Malignant   15.3    14.3     102.   704.     0.107 
##  9 Malignant     852552 Malignant   16.6    21.4     110    905.     0.112 
## 10 Malignant     853612 Malignant   11.8    18.7      77.9  441.     0.111 
## # ℹ 133 more rows
## # ℹ 5 more variables: Compactness &lt;dbl&gt;, Concavity &lt;dbl&gt;, Concave_Points &lt;dbl&gt;,
## #   Symmetry &lt;dbl&gt;, Fractal_Dimension &lt;dbl&gt;</code></pre>
</div>
<div id="eval-performance-cls2" class="section level3 hasAnchor" number="6.5.5">
<h3><span class="header-section-number">6.5.5</span> Evaluate performance<a href="classification2.html#eval-performance-cls2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Finally, we can assess our classifier’s performance. First, we will examine
accuracy. To do this we use the
<code>metrics</code> function from <code>tidymodels</code>,
specifying the <code>truth</code> and <code>estimate</code> arguments:</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="classification2.html#cb339-1" tabindex="-1"></a>cancer_test_predictions <span class="sc">|&gt;</span></span>
<span id="cb339-2"><a href="classification2.html#cb339-2" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> Class, <span class="at">estimate =</span> .pred_class) <span class="sc">|&gt;</span></span>
<span id="cb339-3"><a href="classification2.html#cb339-3" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;accuracy&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.853</code></pre>
<p>In the metrics data frame, we filtered the <code>.metric</code> column since we are
interested in the <code>accuracy</code> row. Other entries involve other metrics that
are beyond the scope of this book. Looking at the value of the <code>.estimate</code> variable
shows that the estimated accuracy of the classifier on the test data
was 85%.
To compute the precision and recall, we can use the <code>precision</code> and <code>recall</code> functions
from <code>tidymodels</code>. We first check the order of the
labels in the <code>Class</code> variable using the <code>levels</code> function:</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="classification2.html#cb341-1" tabindex="-1"></a>cancer_test_predictions <span class="sc">|&gt;</span> <span class="fu">pull</span>(Class) <span class="sc">|&gt;</span> <span class="fu">levels</span>()</span></code></pre></div>
<pre><code>## [1] &quot;Malignant&quot; &quot;Benign&quot;</code></pre>
<p>This shows that <code>"Malignant"</code> is the first level. Therefore we will set
the <code>truth</code> and <code>estimate</code> arguments to <code>Class</code> and <code>.pred_class</code> as before,
but also specify that the “positive” class corresponds to the first factor level via <code>event_level="first"</code>.
If the labels were in the other order, we would instead use <code>event_level="second"</code>.</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="classification2.html#cb343-1" tabindex="-1"></a>cancer_test_predictions <span class="sc">|&gt;</span></span>
<span id="cb343-2"><a href="classification2.html#cb343-2" tabindex="-1"></a>  <span class="fu">precision</span>(<span class="at">truth =</span> Class, <span class="at">estimate =</span> .pred_class, <span class="at">event_level =</span> <span class="st">&quot;first&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   .metric   .estimator .estimate
##   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;
## 1 precision binary         0.767</code></pre>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="classification2.html#cb345-1" tabindex="-1"></a>cancer_test_predictions <span class="sc">|&gt;</span></span>
<span id="cb345-2"><a href="classification2.html#cb345-2" tabindex="-1"></a>  <span class="fu">recall</span>(<span class="at">truth =</span> Class, <span class="at">estimate =</span> .pred_class, <span class="at">event_level =</span> <span class="st">&quot;first&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 recall  binary         0.868</code></pre>
<p>The output shows that the estimated precision and recall of the classifier on the test data was
77% and 87%, respectively.
Finally, we can look at the <em>confusion matrix</em> for the classifier using the <code>conf_mat</code> function.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="classification2.html#cb347-1" tabindex="-1"></a>confusion <span class="ot">&lt;-</span> cancer_test_predictions <span class="sc">|&gt;</span></span>
<span id="cb347-2"><a href="classification2.html#cb347-2" tabindex="-1"></a>             <span class="fu">conf_mat</span>(<span class="at">truth =</span> Class, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb347-3"><a href="classification2.html#cb347-3" tabindex="-1"></a>confusion</span></code></pre></div>
<pre><code>##            Truth
## Prediction  Malignant Benign
##   Malignant        46     14
##   Benign            7     76</code></pre>
<p>The confusion matrix shows 46 observations were correctly predicted
as malignant, and 76 were correctly predicted as benign.
It also shows that the classifier made some mistakes; in particular,
it classified 7 observations as benign when they were actually malignant,
and 14 observations as malignant when they were actually benign.
Using our formulas from earlier, we see that the accuracy, precision, and recall agree with what R reported.</p>
<p><span class="math display">\[\mathrm{accuracy} = \frac{\mathrm{number \; of  \; correct  \; predictions}}{\mathrm{total \;  number \;  of  \; predictions}} = \frac{46+76}{46+76+14+7} = 0.853\]</span></p>
<p><span class="math display">\[\mathrm{precision} = \frac{\mathrm{number \; of  \; correct \; positive \; predictions}}{\mathrm{total \;  number \;  of \; positive  \; predictions}} = \frac{46}{46 + 14} = 0.767\]</span></p>
<p><span class="math display">\[\mathrm{recall} = \frac{\mathrm{number \; of  \; correct  \; positive \; predictions}}{\mathrm{total \;  number \;  of  \; positive \; test \; set \; observations}} = \frac{46}{46+7} = 0.868\]</span></p>
</div>
<div id="critically-analyze-performance" class="section level3 hasAnchor" number="6.5.6">
<h3><span class="header-section-number">6.5.6</span> Critically analyze performance<a href="classification2.html#critically-analyze-performance" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We now know that the classifier was 85% accurate
on the test data set, and had a precision of 77% and a recall of 87%.
That sounds pretty good! Wait, <em>is</em> it good? Or do we need something higher?</p>
<p>In general, a <em>good</em> value for accuracy (as well as precision and recall, if applicable)
depends on the application; you must critically analyze your accuracy in the context of the problem
you are solving. For example, if we were building a classifier for a kind of tumor that is benign 99%
of the time, a classifier with 99% accuracy is not terribly impressive (just always guess benign!).
And beyond just accuracy, we need to consider the precision and recall: as mentioned
earlier, the <em>kind</em> of mistake the classifier makes is
important in many applications as well. In the previous example with 99% benign observations, it might be very bad for the
classifier to predict “benign” when the actual class is “malignant” (a false negative), as this
might result in a patient not receiving appropriate medical attention. In other
words, in this context, we need the classifier to have a <em>high recall</em>. On the
other hand, it might be less bad for the classifier to guess “malignant” when
the actual class is “benign” (a false positive), as the patient will then likely see a doctor who
can provide an expert diagnosis. In other words, we are fine with sacrificing
some precision in the interest of achieving high recall. This is why it is
important not only to look at accuracy, but also the confusion matrix.</p>
<p>However, there is always an easy baseline that you can compare to for any
classification problem: the <em>majority classifier</em>. The majority classifier
<em>always</em> guesses the majority class label from the training data, regardless of
the predictor variables’ values. It helps to give you a sense of
scale when considering accuracies. If the majority classifier obtains a 90%
accuracy on a problem, then you might hope for your K-nearest neighbors
classifier to do better than that. If your classifier provides a significant
improvement upon the majority classifier, this means that at least your method
is extracting some useful information from your predictor variables. Be
careful though: improving on the majority classifier does not <em>necessarily</em>
mean the classifier is working well enough for your application.</p>
<p>As an example, in the breast cancer data, recall the proportions of benign and malignant
observations in the training data are as follows:</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="classification2.html#cb349-1" tabindex="-1"></a>cancer_proportions</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   Class         n percent
##   &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;
## 1 Malignant   159    37.3
## 2 Benign      267    62.7</code></pre>
<p>Since the benign class represents the majority of the training data,
the majority classifier would <em>always</em> predict that a new observation
is benign. The estimated accuracy of the majority classifier is usually
fairly close to the majority class proportion in the training data.
In this case, we would suspect that the majority classifier will have
an accuracy of around 63%.
The K-nearest neighbors classifier we built does quite a bit better than this,
with an accuracy of 85%.
This means that from the perspective of accuracy,
the K-nearest neighbors classifier improved quite a bit on the basic
majority classifier. Hooray! But we still need to be cautious; in
this application, it is likely very important not to misdiagnose any malignant tumors to avoid missing
patients who actually need medical care. The confusion matrix above shows
that the classifier does, indeed, misdiagnose a significant number of malignant tumors as benign (7
out of 53 malignant tumors, or 13%!).
Therefore, even though the accuracy improved upon the majority classifier,
our critical analysis suggests that this classifier may not have appropriate performance
for the application.</p>
</div>
</div>
<div id="tuning-the-classifier" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Tuning the classifier<a href="classification2.html#tuning-the-classifier" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The vast majority of predictive models in statistics and machine learning have
<em>parameters</em>. A <em>parameter</em>
is a number you have to pick in advance that determines
some aspect of how the model behaves. For example, in the K-nearest neighbors
classification algorithm, <span class="math inline">\(K\)</span> is a parameter that we have to pick
that determines how many neighbors participate in the class vote.
By picking different values of <span class="math inline">\(K\)</span>, we create different classifiers
that make different predictions.</p>
<p>So then, how do we pick the <em>best</em> value of <span class="math inline">\(K\)</span>, i.e., <em>tune</em> the model?
And is it possible to make this selection in a principled way? In this book,
we will focus on maximizing the accuracy of the classifier. Ideally,
we want somehow to maximize the accuracy of our classifier on data <em>it
hasn’t seen yet</em>. But we cannot use our test data set in the process of building
our model. So we will play the same trick we did before when evaluating
our classifier: we’ll split our <em>training data itself</em> into two subsets,
use one to train the model, and then use the other to evaluate it.
In this section, we will cover the details of this procedure, as well as
how to use it to help you pick a good parameter value for your classifier.</p>
<p><strong>And remember:</strong> don’t touch the test set during the tuning process. Tuning is a part of model training!</p>
<div id="cross-validation" class="section level3 hasAnchor" number="6.6.1">
<h3><span class="header-section-number">6.6.1</span> Cross-validation<a href="classification2.html#cross-validation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The first step in choosing the parameter <span class="math inline">\(K\)</span> is to be able to evaluate the
classifier using only the training data. If this is possible, then we can compare
the classifier’s performance for different values of <span class="math inline">\(K\)</span>—and pick the best—using
only the training data. As suggested at the beginning of this section, we will
accomplish this by splitting the training data, training on one subset, and evaluating
on the other. The subset of training data used for evaluation is often called the <strong>validation set</strong>. </p>
<p>There is, however, one key difference from the train/test split
that we performed earlier. In particular, we were forced to make only a <em>single split</em>
of the data. This is because at the end of the day, we have to produce a single classifier.
If we had multiple different splits of the data into training and testing data,
we would produce multiple different classifiers.
But while we are tuning the classifier, we are free to create multiple classifiers
based on multiple splits of the training data, evaluate them, and then choose a parameter
value based on <strong><em>all</em></strong> of the different results. If we just split our overall training
data <em>once</em>, our best parameter choice will depend strongly on whatever data
was lucky enough to end up in the validation set. Perhaps using multiple
different train/validation splits, we’ll get a better estimate of accuracy,
which will lead to a better choice of the number of neighbors <span class="math inline">\(K\)</span> for the
overall set of training data.</p>
<p>Let’s investigate this idea in R! In particular, we will generate five different train/validation
splits of our overall training data, train five different K-nearest neighbors
models, and evaluate their accuracy. We will start with just a single
split.</p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="classification2.html#cb351-1" tabindex="-1"></a><span class="co"># create the 25/75 split of the training data into training and validation</span></span>
<span id="cb351-2"><a href="classification2.html#cb351-2" tabindex="-1"></a>cancer_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(cancer_train, <span class="at">prop =</span> <span class="fl">0.75</span>, <span class="at">strata =</span> Class)</span>
<span id="cb351-3"><a href="classification2.html#cb351-3" tabindex="-1"></a>cancer_subtrain <span class="ot">&lt;-</span> <span class="fu">training</span>(cancer_split)</span>
<span id="cb351-4"><a href="classification2.html#cb351-4" tabindex="-1"></a>cancer_validation <span class="ot">&lt;-</span> <span class="fu">testing</span>(cancer_split)</span>
<span id="cb351-5"><a href="classification2.html#cb351-5" tabindex="-1"></a></span>
<span id="cb351-6"><a href="classification2.html#cb351-6" tabindex="-1"></a><span class="co"># recreate the standardization recipe from before</span></span>
<span id="cb351-7"><a href="classification2.html#cb351-7" tabindex="-1"></a><span class="co"># (since it must be based on the training data)</span></span>
<span id="cb351-8"><a href="classification2.html#cb351-8" tabindex="-1"></a>cancer_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Class <span class="sc">~</span> Smoothness <span class="sc">+</span> Concavity,</span>
<span id="cb351-9"><a href="classification2.html#cb351-9" tabindex="-1"></a>                        <span class="at">data =</span> cancer_subtrain) <span class="sc">|&gt;</span></span>
<span id="cb351-10"><a href="classification2.html#cb351-10" tabindex="-1"></a>  <span class="fu">step_scale</span>(<span class="fu">all_predictors</span>()) <span class="sc">|&gt;</span></span>
<span id="cb351-11"><a href="classification2.html#cb351-11" tabindex="-1"></a>  <span class="fu">step_center</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb351-12"><a href="classification2.html#cb351-12" tabindex="-1"></a></span>
<span id="cb351-13"><a href="classification2.html#cb351-13" tabindex="-1"></a><span class="co"># fit the knn model (we can reuse the old knn_spec model from before)</span></span>
<span id="cb351-14"><a href="classification2.html#cb351-14" tabindex="-1"></a>knn_fit <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb351-15"><a href="classification2.html#cb351-15" tabindex="-1"></a>  <span class="fu">add_recipe</span>(cancer_recipe) <span class="sc">|&gt;</span></span>
<span id="cb351-16"><a href="classification2.html#cb351-16" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec) <span class="sc">|&gt;</span></span>
<span id="cb351-17"><a href="classification2.html#cb351-17" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> cancer_subtrain)</span>
<span id="cb351-18"><a href="classification2.html#cb351-18" tabindex="-1"></a></span>
<span id="cb351-19"><a href="classification2.html#cb351-19" tabindex="-1"></a><span class="co"># get predictions on the validation data</span></span>
<span id="cb351-20"><a href="classification2.html#cb351-20" tabindex="-1"></a>validation_predicted <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit, cancer_validation) <span class="sc">|&gt;</span></span>
<span id="cb351-21"><a href="classification2.html#cb351-21" tabindex="-1"></a>  <span class="fu">bind_cols</span>(cancer_validation)</span>
<span id="cb351-22"><a href="classification2.html#cb351-22" tabindex="-1"></a></span>
<span id="cb351-23"><a href="classification2.html#cb351-23" tabindex="-1"></a><span class="co"># compute the accuracy</span></span>
<span id="cb351-24"><a href="classification2.html#cb351-24" tabindex="-1"></a>acc <span class="ot">&lt;-</span> validation_predicted <span class="sc">|&gt;</span></span>
<span id="cb351-25"><a href="classification2.html#cb351-25" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> Class, <span class="at">estimate =</span> .pred_class) <span class="sc">|&gt;</span></span>
<span id="cb351-26"><a href="classification2.html#cb351-26" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;accuracy&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb351-27"><a href="classification2.html#cb351-27" tabindex="-1"></a>  <span class="fu">select</span>(.estimate) <span class="sc">|&gt;</span></span>
<span id="cb351-28"><a href="classification2.html#cb351-28" tabindex="-1"></a>  <span class="fu">pull</span>()</span>
<span id="cb351-29"><a href="classification2.html#cb351-29" tabindex="-1"></a></span>
<span id="cb351-30"><a href="classification2.html#cb351-30" tabindex="-1"></a>acc</span></code></pre></div>
<pre><code>## [1] 0.8598131</code></pre>
<p>The accuracy estimate using this split is 86%.
Now we repeat the above code 4 more times, which generates 4 more splits.
Therefore we get five different shuffles of the data, and therefore five different values for
accuracy: 86.0%, 89.7%, 88.8%, 86.0%, 86.9%. None of these values are
necessarily “more correct” than any other; they’re
just five estimates of the true, underlying accuracy of our classifier built
using our overall training data. We can combine the estimates by taking their
average (here 87%) to try to get a single assessment of our
classifier’s accuracy; this has the effect of reducing the influence of any one
(un)lucky validation set on the estimate.</p>
<p>In practice, we don’t use random splits, but rather use a more structured
splitting procedure so that each observation in the data set is used in a
validation set only a single time. The name for this strategy is
<strong>cross-validation</strong>. In <strong>cross-validation</strong>, we split our <strong>overall training
data</strong> into <span class="math inline">\(C\)</span> evenly sized chunks. Then, iteratively use <span class="math inline">\(1\)</span> chunk as the
<strong>validation set</strong> and combine the remaining <span class="math inline">\(C-1\)</span> chunks
as the <strong>training set</strong>.
This procedure is shown in Figure <a href="classification2.html#fig:06-cv-image">6.4</a>.
Here, <span class="math inline">\(C=5\)</span> different chunks of the data set are used,
resulting in 5 different choices for the <strong>validation set</strong>; we call this
<em>5-fold</em> cross-validation.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-cv-image"></span>
<img src="img/classification2/cv.png" alt="5-fold cross-validation." width="100%"  />
<p class="caption">
Figure 6.4: 5-fold cross-validation.
</p>
</div>
<p>To perform 5-fold cross-validation in R with <code>tidymodels</code>, we use another
function: <code>vfold_cv</code>. This function splits our training data into <code>v</code> folds
automatically. We set the <code>strata</code> argument to the categorical label variable
(here, <code>Class</code>) to ensure that the training and validation subsets contain the
right proportions of each category of observation.</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="classification2.html#cb353-1" tabindex="-1"></a>cancer_vfold <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(cancer_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> Class)</span>
<span id="cb353-2"><a href="classification2.html#cb353-2" tabindex="-1"></a>cancer_vfold</span></code></pre></div>
<pre><code>## #  5-fold cross-validation using stratification 
## # A tibble: 5 × 2
##   splits           id   
##   &lt;list&gt;           &lt;chr&gt;
## 1 &lt;split [340/86]&gt; Fold1
## 2 &lt;split [340/86]&gt; Fold2
## 3 &lt;split [341/85]&gt; Fold3
## 4 &lt;split [341/85]&gt; Fold4
## 5 &lt;split [342/84]&gt; Fold5</code></pre>
<p>Then, when we create our data analysis workflow, we use the <code>fit_resamples</code> function
instead of the <code>fit</code> function for training. This runs cross-validation on each
train/validation split.</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="classification2.html#cb355-1" tabindex="-1"></a><span class="co"># recreate the standardization recipe from before</span></span>
<span id="cb355-2"><a href="classification2.html#cb355-2" tabindex="-1"></a><span class="co"># (since it must be based on the training data)</span></span>
<span id="cb355-3"><a href="classification2.html#cb355-3" tabindex="-1"></a>cancer_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Class <span class="sc">~</span> Smoothness <span class="sc">+</span> Concavity,</span>
<span id="cb355-4"><a href="classification2.html#cb355-4" tabindex="-1"></a>                        <span class="at">data =</span> cancer_train) <span class="sc">|&gt;</span></span>
<span id="cb355-5"><a href="classification2.html#cb355-5" tabindex="-1"></a>  <span class="fu">step_scale</span>(<span class="fu">all_predictors</span>()) <span class="sc">|&gt;</span></span>
<span id="cb355-6"><a href="classification2.html#cb355-6" tabindex="-1"></a>  <span class="fu">step_center</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb355-7"><a href="classification2.html#cb355-7" tabindex="-1"></a></span>
<span id="cb355-8"><a href="classification2.html#cb355-8" tabindex="-1"></a><span class="co"># fit the knn model (we can reuse the old knn_spec model from before)</span></span>
<span id="cb355-9"><a href="classification2.html#cb355-9" tabindex="-1"></a>knn_fit <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb355-10"><a href="classification2.html#cb355-10" tabindex="-1"></a>  <span class="fu">add_recipe</span>(cancer_recipe) <span class="sc">|&gt;</span></span>
<span id="cb355-11"><a href="classification2.html#cb355-11" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec) <span class="sc">|&gt;</span></span>
<span id="cb355-12"><a href="classification2.html#cb355-12" tabindex="-1"></a>  <span class="fu">fit_resamples</span>(<span class="at">resamples =</span> cancer_vfold)</span>
<span id="cb355-13"><a href="classification2.html#cb355-13" tabindex="-1"></a></span>
<span id="cb355-14"><a href="classification2.html#cb355-14" tabindex="-1"></a>knn_fit</span></code></pre></div>
<pre><code>## # Resampling results
## # 5-fold cross-validation using stratification 
## # A tibble: 5 × 4
##   splits          id    .metrics         .notes          
##   &lt;list&gt;          &lt;chr&gt; &lt;list&gt;          &lt;list&gt;          
## 1 &lt;split [340/86]&gt; Fold1 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;
## 2 &lt;split [340/86]&gt; Fold2 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;
## 3 &lt;split [341/85]&gt; Fold3 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;
## 4 &lt;split [341/85]&gt; Fold4 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;
## 5 &lt;split [342/84]&gt; Fold5 &lt;tibble [2 × 4]&gt; &lt;tibble [0 × 3]&gt;</code></pre>
<p>The <code>collect_metrics</code> function is used to aggregate the <em>mean</em> and <em>standard error</em>
of the classifier’s validation accuracy across the folds. You will find results
related to the accuracy in the row with <code>accuracy</code> listed under the <code>.metric</code> column.
You should consider the mean (<code>mean</code>) to be the estimated accuracy, while the standard
error (<code>std_err</code>) is a measure of how uncertain we are in the mean value. A detailed treatment of this
is beyond the scope of this chapter; but roughly, if your estimated mean is 0.89 and standard
error is 0.02, you can expect the <em>true</em> average accuracy of the
classifier to be somewhere roughly between 87% and 91% (although it may
fall outside this range). You may ignore the other columns in the metrics data frame,
as they do not provide any additional insight.
You can also ignore the entire second row with <code>roc_auc</code> in the <code>.metric</code> column,
as it is beyond the scope of this book.</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="classification2.html#cb357-1" tabindex="-1"></a>knn_fit <span class="sc">|&gt;</span></span>
<span id="cb357-2"><a href="classification2.html#cb357-2" tabindex="-1"></a>  <span class="fu">collect_metrics</span>()</span></code></pre></div>
<pre><code>## # A tibble: 2 × 6
##   .metric  .estimator  mean     n std_err .config             
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary     0.890     5  0.0180 Preprocessor1_Model1
## 2 roc_auc  binary     0.925     5  0.0151 Preprocessor1_Model1</code></pre>
<p>We can choose any number of folds, and typically the more we use the better our
accuracy estimate will be (lower standard error). However, we are limited
by computational power: the
more folds we choose, the more computation it takes, and hence the more time
it takes to run the analysis. So when you do cross-validation, you need to
consider the size of the data, the speed of the algorithm (e.g., K-nearest
neighbors), and the speed of your computer. In practice, this is a
trial-and-error process, but typically <span class="math inline">\(C\)</span> is chosen to be either 5 or 10. Here
we will try 10-fold cross-validation to see if we get a lower standard error:</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="classification2.html#cb359-1" tabindex="-1"></a>cancer_vfold <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(cancer_train, <span class="at">v =</span> <span class="dv">10</span>, <span class="at">strata =</span> Class)</span>
<span id="cb359-2"><a href="classification2.html#cb359-2" tabindex="-1"></a></span>
<span id="cb359-3"><a href="classification2.html#cb359-3" tabindex="-1"></a>vfold_metrics <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb359-4"><a href="classification2.html#cb359-4" tabindex="-1"></a>                  <span class="fu">add_recipe</span>(cancer_recipe) <span class="sc">|&gt;</span></span>
<span id="cb359-5"><a href="classification2.html#cb359-5" tabindex="-1"></a>                  <span class="fu">add_model</span>(knn_spec) <span class="sc">|&gt;</span></span>
<span id="cb359-6"><a href="classification2.html#cb359-6" tabindex="-1"></a>                  <span class="fu">fit_resamples</span>(<span class="at">resamples =</span> cancer_vfold) <span class="sc">|&gt;</span></span>
<span id="cb359-7"><a href="classification2.html#cb359-7" tabindex="-1"></a>                  <span class="fu">collect_metrics</span>()</span>
<span id="cb359-8"><a href="classification2.html#cb359-8" tabindex="-1"></a></span>
<span id="cb359-9"><a href="classification2.html#cb359-9" tabindex="-1"></a>vfold_metrics</span></code></pre></div>
<pre><code>## # A tibble: 2 × 6
##   .metric  .estimator  mean     n std_err .config             
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary     0.890    10  0.0127 Preprocessor1_Model1
## 2 roc_auc  binary     0.913    10  0.0150 Preprocessor1_Model1</code></pre>
<p>In this case, using 10-fold instead of 5-fold cross validation did reduce the standard error, although
by only an insignificant amount. In fact, due to the randomness in how the data are split, sometimes
you might even end up with a <em>higher</em> standard error when increasing the number of folds!
We can make the reduction in standard error more dramatic by increasing the number of folds
by a large amount. In the following code we show the result when <span class="math inline">\(C = 50\)</span>;
picking such a large number of folds often takes a long time to run in practice,
so we usually stick to 5 or 10.</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="classification2.html#cb361-1" tabindex="-1"></a>cancer_vfold_50 <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(cancer_train, <span class="at">v =</span> <span class="dv">50</span>, <span class="at">strata =</span> Class)</span>
<span id="cb361-2"><a href="classification2.html#cb361-2" tabindex="-1"></a></span>
<span id="cb361-3"><a href="classification2.html#cb361-3" tabindex="-1"></a>vfold_metrics_50 <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb361-4"><a href="classification2.html#cb361-4" tabindex="-1"></a>                  <span class="fu">add_recipe</span>(cancer_recipe) <span class="sc">|&gt;</span></span>
<span id="cb361-5"><a href="classification2.html#cb361-5" tabindex="-1"></a>                  <span class="fu">add_model</span>(knn_spec) <span class="sc">|&gt;</span></span>
<span id="cb361-6"><a href="classification2.html#cb361-6" tabindex="-1"></a>                  <span class="fu">fit_resamples</span>(<span class="at">resamples =</span> cancer_vfold_50) <span class="sc">|&gt;</span></span>
<span id="cb361-7"><a href="classification2.html#cb361-7" tabindex="-1"></a>                  <span class="fu">collect_metrics</span>()</span>
<span id="cb361-8"><a href="classification2.html#cb361-8" tabindex="-1"></a></span>
<span id="cb361-9"><a href="classification2.html#cb361-9" tabindex="-1"></a>vfold_metrics_50</span></code></pre></div>
<pre><code>## # A tibble: 2 × 6
##   .metric  .estimator  mean     n std_err .config             
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary     0.884    50 0.00568 Preprocessor1_Model1
## 2 roc_auc  binary     0.926    50 0.0148  Preprocessor1_Model1</code></pre>
</div>
<div id="parameter-value-selection" class="section level3 hasAnchor" number="6.6.2">
<h3><span class="header-section-number">6.6.2</span> Parameter value selection<a href="classification2.html#parameter-value-selection" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Using 5- and 10-fold cross-validation, we have estimated that the prediction
accuracy of our classifier is somewhere around 89%.
Whether that is good or not
depends entirely on the downstream application of the data analysis. In the
present situation, we are trying to predict a tumor diagnosis, with expensive,
damaging chemo/radiation therapy or patient death as potential consequences of
misprediction. Hence, we might like to
do better than 89% for this application.</p>
<p>In order to improve our classifier, we have one choice of parameter: the number of
neighbors, <span class="math inline">\(K\)</span>. Since cross-validation helps us evaluate the accuracy of our
classifier, we can use cross-validation to calculate an accuracy for each value
of <span class="math inline">\(K\)</span> in a reasonable range, and then pick the value of <span class="math inline">\(K\)</span> that gives us the
best accuracy. The <code>tidymodels</code> package collection provides a very simple
syntax for tuning models: each parameter in the model to be tuned should be specified
as <code>tune()</code> in the model specification rather than given a particular value.</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="classification2.html#cb363-1" tabindex="-1"></a>knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">weight_func =</span> <span class="st">&quot;rectangular&quot;</span>,</span>
<span id="cb363-2"><a href="classification2.html#cb363-2" tabindex="-1"></a>                             <span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb363-3"><a href="classification2.html#cb363-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb363-4"><a href="classification2.html#cb363-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span></code></pre></div>
<p>Then instead of using <code>fit</code> or <code>fit_resamples</code>, we will use the <code>tune_grid</code> function
to fit the model for each value in a range of parameter values.
In particular, we first create a data frame with a <code>neighbors</code>
variable that contains the sequence of values of <span class="math inline">\(K\)</span> to try; below we create the <code>k_vals</code>
data frame with the <code>neighbors</code> variable containing values from 1 to 100 (stepping by 5) using
the <code>seq</code> function.
Then we pass that data frame to the <code>grid</code> argument of <code>tune_grid</code>.</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="classification2.html#cb364-1" tabindex="-1"></a>k_vals <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">neighbors =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">1</span>, <span class="at">to =</span> <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">5</span>))</span>
<span id="cb364-2"><a href="classification2.html#cb364-2" tabindex="-1"></a></span>
<span id="cb364-3"><a href="classification2.html#cb364-3" tabindex="-1"></a>knn_results <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb364-4"><a href="classification2.html#cb364-4" tabindex="-1"></a>  <span class="fu">add_recipe</span>(cancer_recipe) <span class="sc">|&gt;</span></span>
<span id="cb364-5"><a href="classification2.html#cb364-5" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec) <span class="sc">|&gt;</span></span>
<span id="cb364-6"><a href="classification2.html#cb364-6" tabindex="-1"></a>  <span class="fu">tune_grid</span>(<span class="at">resamples =</span> cancer_vfold, <span class="at">grid =</span> k_vals) <span class="sc">|&gt;</span></span>
<span id="cb364-7"><a href="classification2.html#cb364-7" tabindex="-1"></a>  <span class="fu">collect_metrics</span>()</span>
<span id="cb364-8"><a href="classification2.html#cb364-8" tabindex="-1"></a></span>
<span id="cb364-9"><a href="classification2.html#cb364-9" tabindex="-1"></a>accuracies <span class="ot">&lt;-</span> knn_results <span class="sc">|&gt;</span></span>
<span id="cb364-10"><a href="classification2.html#cb364-10" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb364-11"><a href="classification2.html#cb364-11" tabindex="-1"></a></span>
<span id="cb364-12"><a href="classification2.html#cb364-12" tabindex="-1"></a>accuracies</span></code></pre></div>
<pre><code>## # A tibble: 20 × 7
##    neighbors .metric  .estimator  mean     n std_err .config              
##        &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
##  1         1 accuracy binary     0.866    10  0.0165 Preprocessor1_Model01
##  2         6 accuracy binary     0.890    10  0.0153 Preprocessor1_Model02
##  3        11 accuracy binary     0.887    10  0.0173 Preprocessor1_Model03
##  4        16 accuracy binary     0.887    10  0.0142 Preprocessor1_Model04
##  5        21 accuracy binary     0.887    10  0.0143 Preprocessor1_Model05
##  6        26 accuracy binary     0.887    10  0.0170 Preprocessor1_Model06
##  7        31 accuracy binary     0.897    10  0.0145 Preprocessor1_Model07
##  8        36 accuracy binary     0.899    10  0.0144 Preprocessor1_Model08
##  9        41 accuracy binary     0.892    10  0.0135 Preprocessor1_Model09
## 10        46 accuracy binary     0.892    10  0.0156 Preprocessor1_Model10
## 11        51 accuracy binary     0.890    10  0.0155 Preprocessor1_Model11
## 12        56 accuracy binary     0.873    10  0.0156 Preprocessor1_Model12
## 13        61 accuracy binary     0.876    10  0.0104 Preprocessor1_Model13
## 14        66 accuracy binary     0.871    10  0.0139 Preprocessor1_Model14
## 15        71 accuracy binary     0.876    10  0.0104 Preprocessor1_Model15
## 16        76 accuracy binary     0.873    10  0.0127 Preprocessor1_Model16
## 17        81 accuracy binary     0.876    10  0.0135 Preprocessor1_Model17
## 18        86 accuracy binary     0.873    10  0.0131 Preprocessor1_Model18
## 19        91 accuracy binary     0.873    10  0.0140 Preprocessor1_Model19
## 20        96 accuracy binary     0.866    10  0.0126 Preprocessor1_Model20</code></pre>
<p>We can decide which number of neighbors is best by plotting the accuracy versus <span class="math inline">\(K\)</span>,
as shown in Figure <a href="classification2.html#fig:06-find-k">6.5</a>.</p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="classification2.html#cb366-1" tabindex="-1"></a>accuracy_vs_k <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(accuracies, <span class="fu">aes</span>(<span class="at">x =</span> neighbors, <span class="at">y =</span> mean)) <span class="sc">+</span></span>
<span id="cb366-2"><a href="classification2.html#cb366-2" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb366-3"><a href="classification2.html#cb366-3" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb366-4"><a href="classification2.html#cb366-4" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Neighbors&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Accuracy Estimate&quot;</span>) <span class="sc">+</span></span>
<span id="cb366-5"><a href="classification2.html#cb366-5" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span>
<span id="cb366-6"><a href="classification2.html#cb366-6" tabindex="-1"></a></span>
<span id="cb366-7"><a href="classification2.html#cb366-7" tabindex="-1"></a>accuracy_vs_k</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-find-k"></span>
<img src="_main_files/figure-html/06-find-k-1.png" alt="Plot of estimated accuracy versus the number of neighbors." width="384" />
<p class="caption">
Figure 6.5: Plot of estimated accuracy versus the number of neighbors.
</p>
</div>
<p>We can also obtain the number of neighbours with the highest accuracy
programmatically by accessing the <code>neighbors</code> variable in the <code>accuracies</code> data
frame where the <code>mean</code> variable is highest.
Note that it is still useful to visualize the results as
we did above since this provides additional information on how the model
performance varies.</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="classification2.html#cb367-1" tabindex="-1"></a>best_k <span class="ot">&lt;-</span> accuracies <span class="sc">|&gt;</span></span>
<span id="cb367-2"><a href="classification2.html#cb367-2" tabindex="-1"></a>        <span class="fu">arrange</span>(<span class="fu">desc</span>(mean)) <span class="sc">|&gt;</span></span>
<span id="cb367-3"><a href="classification2.html#cb367-3" tabindex="-1"></a>        <span class="fu">head</span>(<span class="dv">1</span>) <span class="sc">|&gt;</span></span>
<span id="cb367-4"><a href="classification2.html#cb367-4" tabindex="-1"></a>        <span class="fu">pull</span>(neighbors)</span>
<span id="cb367-5"><a href="classification2.html#cb367-5" tabindex="-1"></a>best_k</span></code></pre></div>
<pre><code>## [1] 36</code></pre>
<p>Setting the number of
neighbors to <span class="math inline">\(K =\)</span> 36
provides the highest cross-validation accuracy estimate (89.89%). But there is no exact or perfect answer here;
any selection from <span class="math inline">\(K = 30\)</span> and <span class="math inline">\(60\)</span> would be reasonably justified, as all
of these differ in classifier accuracy by a small amount. Remember: the
values you see on this plot are <em>estimates</em> of the true accuracy of our
classifier. Although the <span class="math inline">\(K =\)</span> 36 value is higher than the others on this plot,
that doesn’t mean the classifier is actually more accurate with this parameter
value! Generally, when selecting <span class="math inline">\(K\)</span> (and other parameters for other predictive
models), we are looking for a value where:</p>
<ul>
<li>we get roughly optimal accuracy, so that our model will likely be accurate;</li>
<li>changing the value to a nearby one (e.g., adding or subtracting a small number) doesn’t decrease accuracy too much, so that our choice is reliable in the presence of uncertainty;</li>
<li>the cost of training the model is not prohibitive (e.g., in our situation, if <span class="math inline">\(K\)</span> is too large, predicting becomes expensive!).</li>
</ul>
<p>We know that <span class="math inline">\(K =\)</span> 36
provides the highest estimated accuracy. Further, Figure <a href="classification2.html#fig:06-find-k">6.5</a> shows that the estimated accuracy
changes by only a small amount if we increase or decrease <span class="math inline">\(K\)</span> near <span class="math inline">\(K =\)</span> 36.
And finally, <span class="math inline">\(K =\)</span> 36 does not create a prohibitively expensive
computational cost of training. Considering these three points, we would indeed select
<span class="math inline">\(K =\)</span> 36 for the classifier.</p>
</div>
<div id="underoverfitting" class="section level3 hasAnchor" number="6.6.3">
<h3><span class="header-section-number">6.6.3</span> Under/Overfitting<a href="classification2.html#underoverfitting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To build a bit more intuition, what happens if we keep increasing the number of
neighbors <span class="math inline">\(K\)</span>? In fact, the accuracy actually starts to decrease!
Let’s specify a much larger range of values of <span class="math inline">\(K\)</span> to try in the <code>grid</code>
argument of <code>tune_grid</code>. Figure <a href="classification2.html#fig:06-lots-of-ks">6.6</a> shows a plot of estimated accuracy as
we vary <span class="math inline">\(K\)</span> from 1 to almost the number of observations in the training set.</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="classification2.html#cb369-1" tabindex="-1"></a>k_lots <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">neighbors =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">1</span>, <span class="at">to =</span> <span class="dv">385</span>, <span class="at">by =</span> <span class="dv">10</span>))</span>
<span id="cb369-2"><a href="classification2.html#cb369-2" tabindex="-1"></a></span>
<span id="cb369-3"><a href="classification2.html#cb369-3" tabindex="-1"></a>knn_results <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb369-4"><a href="classification2.html#cb369-4" tabindex="-1"></a>  <span class="fu">add_recipe</span>(cancer_recipe) <span class="sc">|&gt;</span></span>
<span id="cb369-5"><a href="classification2.html#cb369-5" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec) <span class="sc">|&gt;</span></span>
<span id="cb369-6"><a href="classification2.html#cb369-6" tabindex="-1"></a>  <span class="fu">tune_grid</span>(<span class="at">resamples =</span> cancer_vfold, <span class="at">grid =</span> k_lots) <span class="sc">|&gt;</span></span>
<span id="cb369-7"><a href="classification2.html#cb369-7" tabindex="-1"></a>  <span class="fu">collect_metrics</span>()</span>
<span id="cb369-8"><a href="classification2.html#cb369-8" tabindex="-1"></a></span>
<span id="cb369-9"><a href="classification2.html#cb369-9" tabindex="-1"></a>accuracies_lots <span class="ot">&lt;-</span> knn_results <span class="sc">|&gt;</span></span>
<span id="cb369-10"><a href="classification2.html#cb369-10" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;accuracy&quot;</span>)</span>
<span id="cb369-11"><a href="classification2.html#cb369-11" tabindex="-1"></a></span>
<span id="cb369-12"><a href="classification2.html#cb369-12" tabindex="-1"></a>accuracy_vs_k_lots <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(accuracies_lots, <span class="fu">aes</span>(<span class="at">x =</span> neighbors, <span class="at">y =</span> mean)) <span class="sc">+</span></span>
<span id="cb369-13"><a href="classification2.html#cb369-13" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb369-14"><a href="classification2.html#cb369-14" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb369-15"><a href="classification2.html#cb369-15" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Neighbors&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Accuracy Estimate&quot;</span>) <span class="sc">+</span></span>
<span id="cb369-16"><a href="classification2.html#cb369-16" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span>
<span id="cb369-17"><a href="classification2.html#cb369-17" tabindex="-1"></a></span>
<span id="cb369-18"><a href="classification2.html#cb369-18" tabindex="-1"></a>accuracy_vs_k_lots</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-lots-of-ks"></span>
<img src="_main_files/figure-html/06-lots-of-ks-1.png" alt="Plot of accuracy estimate versus number of neighbors for many K values." width="384" />
<p class="caption">
Figure 6.6: Plot of accuracy estimate versus number of neighbors for many K values.
</p>
</div>
<p><strong>Underfitting:</strong> What is actually happening to our classifier that causes
this? As we increase the number of neighbors, more and more of the training
observations (and those that are farther and farther away from the point) get a
“say” in what the class of a new observation is. This causes a sort of
“averaging effect” to take place, making the boundary between where our
classifier would predict a tumor to be malignant versus benign to smooth out
and become <em>simpler.</em> If you take this to the extreme, setting <span class="math inline">\(K\)</span> to the total
training data set size, then the classifier will always predict the same label
regardless of what the new observation looks like. In general, if the model
<em>isn’t influenced enough</em> by the training data, it is said to <strong>underfit</strong> the
data.</p>
<p><strong>Overfitting:</strong> In contrast, when we decrease the number of neighbors, each
individual data point has a stronger and stronger vote regarding nearby points.
Since the data themselves are noisy, this causes a more “jagged” boundary
corresponding to a <em>less simple</em> model. If you take this case to the extreme,
setting <span class="math inline">\(K = 1\)</span>, then the classifier is essentially just matching each new
observation to its closest neighbor in the training data set. This is just as
problematic as the large <span class="math inline">\(K\)</span> case, because the classifier becomes unreliable on
new data: if we had a different training set, the predictions would be
completely different. In general, if the model <em>is influenced too much</em> by the
training data, it is said to <strong>overfit</strong> the data.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-decision-grid-K"></span>
<img src="_main_files/figure-html/06-decision-grid-K-1.png" alt="Effect of K in overfitting and underfitting." width="960"  />
<p class="caption">
Figure 6.7: Effect of K in overfitting and underfitting.
</p>
</div>
<p>Both overfitting and underfitting are problematic and will lead to a model
that does not generalize well to new data. When fitting a model, we need to strike
a balance between the two. You can see these two effects in Figure
<a href="classification2.html#fig:06-decision-grid-K">6.7</a>, which shows how the classifier changes as
we set the number of neighbors <span class="math inline">\(K\)</span> to 1, 7, 20, and 300.</p>
</div>
<div id="evaluating-on-the-test-set" class="section level3 hasAnchor" number="6.6.4">
<h3><span class="header-section-number">6.6.4</span> Evaluating on the test set<a href="classification2.html#evaluating-on-the-test-set" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we have tuned the K-NN classifier and set <span class="math inline">\(K =\)</span> 36,
we are done building the model and it is time to evaluate the quality of its predictions on the held out
test data, as we did earlier in Section <a href="classification2.html#eval-performance-cls2">6.5.5</a>.
We first need to retrain the K-NN classifier
on the entire training data set using the selected number of neighbors.</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="classification2.html#cb370-1" tabindex="-1"></a>cancer_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Class <span class="sc">~</span> Smoothness <span class="sc">+</span> Concavity, <span class="at">data =</span> cancer_train) <span class="sc">|&gt;</span></span>
<span id="cb370-2"><a href="classification2.html#cb370-2" tabindex="-1"></a>  <span class="fu">step_scale</span>(<span class="fu">all_predictors</span>()) <span class="sc">|&gt;</span></span>
<span id="cb370-3"><a href="classification2.html#cb370-3" tabindex="-1"></a>  <span class="fu">step_center</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb370-4"><a href="classification2.html#cb370-4" tabindex="-1"></a></span>
<span id="cb370-5"><a href="classification2.html#cb370-5" tabindex="-1"></a>knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">weight_func =</span> <span class="st">&quot;rectangular&quot;</span>, <span class="at">neighbors =</span> best_k) <span class="sc">|&gt;</span></span>
<span id="cb370-6"><a href="classification2.html#cb370-6" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb370-7"><a href="classification2.html#cb370-7" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb370-8"><a href="classification2.html#cb370-8" tabindex="-1"></a></span>
<span id="cb370-9"><a href="classification2.html#cb370-9" tabindex="-1"></a>knn_fit <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb370-10"><a href="classification2.html#cb370-10" tabindex="-1"></a>  <span class="fu">add_recipe</span>(cancer_recipe) <span class="sc">|&gt;</span></span>
<span id="cb370-11"><a href="classification2.html#cb370-11" tabindex="-1"></a>  <span class="fu">add_model</span>(knn_spec) <span class="sc">|&gt;</span></span>
<span id="cb370-12"><a href="classification2.html#cb370-12" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> cancer_train)</span>
<span id="cb370-13"><a href="classification2.html#cb370-13" tabindex="-1"></a></span>
<span id="cb370-14"><a href="classification2.html#cb370-14" tabindex="-1"></a>knn_fit</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ══════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 2 Recipe Steps
## 
## • step_scale()
## • step_center()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## 
## Call:
## kknn::train.kknn(formula = ..y ~ ., data = data, ks = min_rows(36,     data, 5), kernel = ~&quot;rectangular&quot;)
## 
## Type of response variable: nominal
## Minimal misclassification: 0.1150235
## Best kernel: rectangular
## Best k: 36</code></pre>
<p>Then to make predictions and assess the estimated accuracy of the best model on the test data, we use the
<code>predict</code> and <code>metrics</code> functions as we did earlier in the chapter. We can then pass those predictions to
the <code>precision</code>, <code>recall</code>, and <code>conf_mat</code> functions to assess the estimated precision and recall, and print a confusion matrix.
</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="classification2.html#cb372-1" tabindex="-1"></a>cancer_test_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(knn_fit, cancer_test) <span class="sc">|&gt;</span></span>
<span id="cb372-2"><a href="classification2.html#cb372-2" tabindex="-1"></a>  <span class="fu">bind_cols</span>(cancer_test)</span>
<span id="cb372-3"><a href="classification2.html#cb372-3" tabindex="-1"></a></span>
<span id="cb372-4"><a href="classification2.html#cb372-4" tabindex="-1"></a>cancer_test_predictions <span class="sc">|&gt;</span></span>
<span id="cb372-5"><a href="classification2.html#cb372-5" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> Class, <span class="at">estimate =</span> .pred_class) <span class="sc">|&gt;</span></span>
<span id="cb372-6"><a href="classification2.html#cb372-6" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;accuracy&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.860</code></pre>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="classification2.html#cb374-1" tabindex="-1"></a>cancer_test_predictions <span class="sc">|&gt;</span></span>
<span id="cb374-2"><a href="classification2.html#cb374-2" tabindex="-1"></a>    <span class="fu">precision</span>(<span class="at">truth =</span> Class, <span class="at">estimate =</span> .pred_class, <span class="at">event_level=</span><span class="st">&quot;first&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   .metric   .estimator .estimate
##   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;
## 1 precision binary           0.8</code></pre>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="classification2.html#cb376-1" tabindex="-1"></a>cancer_test_predictions <span class="sc">|&gt;</span></span>
<span id="cb376-2"><a href="classification2.html#cb376-2" tabindex="-1"></a>    <span class="fu">recall</span>(<span class="at">truth =</span> Class, <span class="at">estimate =</span> .pred_class, <span class="at">event_level=</span><span class="st">&quot;first&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 recall  binary         0.830</code></pre>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="classification2.html#cb378-1" tabindex="-1"></a>confusion <span class="ot">&lt;-</span> cancer_test_predictions <span class="sc">|&gt;</span></span>
<span id="cb378-2"><a href="classification2.html#cb378-2" tabindex="-1"></a>             <span class="fu">conf_mat</span>(<span class="at">truth =</span> Class, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb378-3"><a href="classification2.html#cb378-3" tabindex="-1"></a>confusion</span></code></pre></div>
<pre><code>##            Truth
## Prediction  Malignant Benign
##   Malignant        44     11
##   Benign            9     79</code></pre>
<p>At first glance, this is a bit surprising: the accuracy of the classifier
has only changed a small amount despite tuning the number of neighbors! Our first model
with <span class="math inline">\(K =\)</span> 3 (before we knew how to tune) had an estimated accuracy of 85%,
while the tuned model with <span class="math inline">\(K =\)</span> 36 had an estimated accuracy
of 86%.
Upon examining Figure <a href="classification2.html#fig:06-find-k">6.5</a> again to see the
cross validation accuracy estimates for a range of neighbors, this result
becomes much less surprising. From 1 to around 96 neighbors, the cross
validation accuracy estimate varies only by around 3%, with
each estimate having a standard error around 1%.
Since the cross-validation accuracy estimates the test set accuracy,
the fact that the test set accuracy also doesn’t change much is expected.
Also note that the <span class="math inline">\(K =\)</span> 3 model had
a precision of 77% and
recall of 87%,
while the tuned model had
a precision of 80% and recall of 83%.
Given that the recall decreased—remember, in this application, recall
is critical to making sure we find all the patients with malignant tumors—the tuned model may actually be <em>less</em> preferred
in this setting. In any case, it is important to think critically about the result of tuning. Models tuned to
maximize accuracy are not necessarily better for a given application.</p>
</div>
</div>
<div id="summary-1" class="section level2 hasAnchor" number="6.7">
<h2><span class="header-section-number">6.7</span> Summary<a href="classification2.html#summary-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Classification algorithms use one or more quantitative variables to predict the
value of another categorical variable. In particular, the K-nearest neighbors algorithm
does this by first finding the <span class="math inline">\(K\)</span> points in the training data nearest
to the new observation, and then returning the majority class vote from those
training observations. We can tune and evaluate a classifier by splitting the data randomly into a
training and test data set. The training set is used to build the classifier,
and we can tune the classifier (e.g., select the number of neighbors in K-NN)
by maximizing estimated accuracy via cross-validation. After we have tuned the
model we can use the test set to estimate its accuracy.
The overall process is summarized in Figure <a href="classification2.html#fig:06-overview">6.8</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-overview"></span>
<img src="img/classification2/train-test-overview.png" alt="Overview of K-NN classification." width="100%"  />
<p class="caption">
Figure 6.8: Overview of K-NN classification.
</p>
</div>
<p>The overall workflow for performing K-nearest neighbors classification using <code>tidymodels</code> is as follows:
</p>
<ol style="list-style-type: decimal">
<li>Use the <code>initial_split</code> function to split the data into a training and test set. Set the <code>strata</code> argument to the class label variable. Put the test set aside for now.</li>
<li>Use the <code>vfold_cv</code> function to split up the training data for cross-validation.</li>
<li>Create a <code>recipe</code> that specifies the class label and predictors, as well as preprocessing steps for all variables. Pass the training data as the <code>data</code> argument of the recipe.</li>
<li>Create a <code>nearest_neighbors</code> model specification, with <code>neighbors = tune()</code>.</li>
<li>Add the recipe and model specification to a <code>workflow()</code>, and use the <code>tune_grid</code> function on the train/validation splits to estimate the classifier accuracy for a range of <span class="math inline">\(K\)</span> values.</li>
<li>Pick a value of <span class="math inline">\(K\)</span> that yields a high accuracy estimate that doesn’t change much if you change <span class="math inline">\(K\)</span> to a nearby value.</li>
<li>Make a new model specification for the best parameter value (i.e., <span class="math inline">\(K\)</span>), and retrain the classifier using the <code>fit</code> function.</li>
<li>Evaluate the estimated accuracy of the classifier on the test set using the <code>predict</code> function.</li>
</ol>
<p>In these last two chapters, we focused on the K-nearest neighbors algorithm,
but there are many other methods we could have used to predict a categorical label.
All algorithms have their strengths and weaknesses, and we summarize these for
the K-NN here.</p>
<p><strong>Strengths:</strong> K-nearest neighbors classification</p>
<ol style="list-style-type: decimal">
<li>is a simple, intuitive algorithm,</li>
<li>requires few assumptions about what the data must look like, and</li>
<li>works for binary (two-class) and multi-class (more than 2 classes) classification problems.</li>
</ol>
<p><strong>Weaknesses:</strong> K-nearest neighbors classification</p>
<ol style="list-style-type: decimal">
<li>becomes very slow as the training data gets larger,</li>
<li>may not perform well with a large number of predictors, and</li>
<li>may not perform well when classes are imbalanced.</li>
</ol>
</div>
<div id="predictor-variable-selection" class="section level2 hasAnchor" number="6.8">
<h2><span class="header-section-number">6.8</span> Predictor variable selection<a href="classification2.html#predictor-variable-selection" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote>
<p><strong>Note:</strong> This section is not required reading for the remainder of the textbook. It is included for those readers
interested in learning how irrelevant variables can influence the performance of a classifier, and how to
pick a subset of useful variables to include as predictors.</p>
</blockquote>
<p>Another potentially important part of tuning your classifier is to choose which
variables from your data will be treated as predictor variables. Technically, you can choose
anything from using a single predictor variable to using every variable in your
data; the K-nearest neighbors algorithm accepts any number of
predictors. However, it is <strong>not</strong> the case that using more predictors always
yields better predictions! In fact, sometimes including irrelevant predictors can
actually negatively affect classifier performance.</p>
<div id="the-effect-of-irrelevant-predictors" class="section level3 hasAnchor" number="6.8.1">
<h3><span class="header-section-number">6.8.1</span> The effect of irrelevant predictors<a href="classification2.html#the-effect-of-irrelevant-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s take a look at an example where K-nearest neighbors performs
worse when given more predictors to work with. In this example, we modified
the breast cancer data to have only the <code>Smoothness</code>, <code>Concavity</code>, and
<code>Perimeter</code> variables from the original data. Then, we added irrelevant
variables that we created ourselves using a random number generator.
The irrelevant variables each take a value of 0 or 1 with equal probability for each observation, regardless
of what the value <code>Class</code> variable takes. In other words, the irrelevant variables have
no meaningful relationship with the <code>Class</code> variable.</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="classification2.html#cb380-1" tabindex="-1"></a>cancer_irrelevant <span class="sc">|&gt;</span></span>
<span id="cb380-2"><a href="classification2.html#cb380-2" tabindex="-1"></a>      <span class="fu">select</span>(Class, Smoothness, Concavity, Perimeter, Irrelevant1, Irrelevant2)</span></code></pre></div>
<pre><code>## # A tibble: 569 × 6
##    Class     Smoothness Concavity Perimeter Irrelevant1 Irrelevant2
##    &lt;fct&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
##  1 Malignant     0.118     0.300      123.            1           0
##  2 Malignant     0.0847    0.0869     133.            0           0
##  3 Malignant     0.110     0.197      130             0           0
##  4 Malignant     0.142     0.241       77.6           0           1
##  5 Malignant     0.100     0.198      135.            0           0
##  6 Malignant     0.128     0.158       82.6           1           0
##  7 Malignant     0.0946    0.113      120.            0           1
##  8 Malignant     0.119     0.0937      90.2           1           0
##  9 Malignant     0.127     0.186       87.5           0           0
## 10 Malignant     0.119     0.227       84.0           1           1
## # ℹ 559 more rows</code></pre>
<p>Next, we build a sequence of K-NN classifiers that include <code>Smoothness</code>,
<code>Concavity</code>, and <code>Perimeter</code> as predictor variables, but also increasingly many irrelevant
variables. In particular, we create 6 data sets with 0, 5, 10, 15, 20, and 40 irrelevant predictors.
Then we build a model, tuned via 5-fold cross-validation, for each data set.
Figure <a href="classification2.html#fig:06-performance-irrelevant-features">6.9</a> shows
the estimated cross-validation accuracy versus the number of irrelevant predictors. As
we add more irrelevant predictor variables, the estimated accuracy of our
classifier decreases. This is because the irrelevant variables add a random
amount to the distance between each pair of observations; the more irrelevant
variables there are, the more (random) influence they have, and the more they
corrupt the set of nearest neighbors that vote on the class of the new
observation to predict.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-performance-irrelevant-features"></span>
<img src="_main_files/figure-html/06-performance-irrelevant-features-1.png" alt="Effect of inclusion of irrelevant predictors." width="65%" />
<p class="caption">
Figure 6.9: Effect of inclusion of irrelevant predictors.
</p>
</div>
<p>Although the accuracy decreases as expected, one surprising thing about
Figure <a href="classification2.html#fig:06-performance-irrelevant-features">6.9</a> is that it shows that the method
still outperforms the baseline majority classifier (with about 63% accuracy)
even with 40 irrelevant variables.
How could that be? Figure <a href="classification2.html#fig:06-neighbors-irrelevant-features">6.10</a> provides the answer:
the tuning procedure for the K-nearest neighbors classifier combats the extra randomness from the irrelevant variables
by increasing the number of neighbors. Of course, because of all the extra noise in the data from the irrelevant
variables, the number of neighbors does not increase smoothly; but the general trend is increasing.
Figure <a href="classification2.html#fig:06-fixed-irrelevant-features">6.11</a> corroborates
this evidence; if we fix the number of neighbors to <span class="math inline">\(K=3\)</span>, the accuracy falls off more quickly.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-neighbors-irrelevant-features"></span>
<img src="_main_files/figure-html/06-neighbors-irrelevant-features-1.png" alt="Tuned number of neighbors for varying number of irrelevant predictors." width="65%" />
<p class="caption">
Figure 6.10: Tuned number of neighbors for varying number of irrelevant predictors.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-fixed-irrelevant-features"></span>
<img src="_main_files/figure-html/06-fixed-irrelevant-features-1.png" alt="Accuracy versus number of irrelevant predictors for tuned and untuned number of neighbors." width="75%" />
<p class="caption">
Figure 6.11: Accuracy versus number of irrelevant predictors for tuned and untuned number of neighbors.
</p>
</div>
</div>
<div id="finding-a-good-subset-of-predictors" class="section level3 hasAnchor" number="6.8.2">
<h3><span class="header-section-number">6.8.2</span> Finding a good subset of predictors<a href="classification2.html#finding-a-good-subset-of-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>So then, if it is not ideal to use all of our variables as predictors without consideration, how
do we choose which variables we <em>should</em> use? A simple method is to rely on your scientific understanding
of the data to tell you which variables are not likely to be useful predictors. For example, in the cancer
data that we have been studying, the <code>ID</code> variable is just a unique identifier for the observation.
As it is not related to any measured property of the cells, the <code>ID</code> variable should therefore not be used
as a predictor. That is, of course, a very clear-cut case. But the decision for the remaining variables
is less obvious, as all seem like reasonable candidates. It
is not clear which subset of them will create the best classifier. One could use visualizations and
other exploratory analyses to try to help understand which variables are potentially relevant, but
this process is both time-consuming and error-prone when there are many variables to consider.
Therefore we need a more systematic and programmatic way of choosing variables.
This is a very difficult problem to solve in
general, and there are a number of methods that have been developed that apply
in particular cases of interest. Here we will discuss two basic
selection methods as an introduction to the topic. See the additional resources at the end of
this chapter to find out where you can learn more about variable selection, including more advanced methods.</p>
<p>The first idea you might think of for a systematic way to select predictors
is to try all possible subsets of predictors and then pick the set that results in the “best” classifier.
This procedure is indeed a well-known variable selection method referred to
as <em>best subset selection</em> <span class="citation">(<a href="#ref-bealesubset">Beale, Kendall, and Mann 1967</a>; <a href="#ref-hockingsubset">Hocking and Leslie 1967</a>)</span>.
In particular, you</p>
<ol style="list-style-type: decimal">
<li>create a separate model for every possible subset of predictors,</li>
<li>tune each one using cross-validation, and</li>
<li>pick the subset of predictors that gives you the highest cross-validation accuracy.</li>
</ol>
<p>Best subset selection is applicable to any classification method (K-NN or otherwise).
However, it becomes very slow when you have even a moderate
number of predictors to choose from (say, around 10). This is because the number of possible predictor subsets
grows very quickly with the number of predictors, and you have to train the model (itself
a slow process!) for each one. For example, if we have 2 predictors—let’s call
them A and B—then we have 3 variable sets to try: A alone, B alone, and finally A
and B together. If we have 3 predictors—A, B, and C—then we have 7
to try: A, B, C, AB, BC, AC, and ABC. In general, the number of models
we have to train for <span class="math inline">\(m\)</span> predictors is <span class="math inline">\(2^m-1\)</span>; in other words, when we
get to 10 predictors we have over <em>one thousand</em> models to train, and
at 20 predictors we have over <em>one million</em> models to train!
So although it is a simple method, best subset selection is usually too computationally
expensive to use in practice.</p>
<p>Another idea is to iteratively build up a model by adding one predictor variable
at a time. This method—known as <em>forward selection</em> <span class="citation">(<a href="#ref-forwardefroymson">Eforymson 1966</a>; <a href="#ref-forwarddraper">Draper and Smith 1966</a>)</span>—is also widely
applicable and fairly straightforward. It involves the following steps:</p>
<ol style="list-style-type: decimal">
<li>Start with a model having no predictors.</li>
<li>Run the following 3 steps until you run out of predictors:
<ol style="list-style-type: decimal">
<li>For each unused predictor, add it to the model to form a <em>candidate model</em>.</li>
<li>Tune all of the candidate models.</li>
<li>Update the model to be the candidate model with the highest cross-validation accuracy.</li>
</ol></li>
<li>Select the model that provides the best trade-off between accuracy and simplicity.</li>
</ol>
<p>Say you have <span class="math inline">\(m\)</span> total predictors to work with. In the first iteration, you have to make
<span class="math inline">\(m\)</span> candidate models, each with 1 predictor. Then in the second iteration, you have
to make <span class="math inline">\(m-1\)</span> candidate models, each with 2 predictors (the one you chose before and a new one).
This pattern continues for as many iterations as you want. If you run the method
all the way until you run out of predictors to choose, you will end up training
<span class="math inline">\(\frac{1}{2}m(m+1)\)</span> separate models. This is a <em>big</em> improvement from the <span class="math inline">\(2^m-1\)</span>
models that best subset selection requires you to train! For example, while best subset selection requires
training over 1000 candidate models with 10 predictors, forward selection requires training only 55 candidate models.
Therefore we will continue the rest of this section using forward selection.</p>
<blockquote>
<p><strong>Note:</strong> One word of caution before we move on. Every additional model that you train
increases the likelihood that you will get unlucky and stumble
on a model that has a high cross-validation accuracy estimate, but a low true
accuracy on the test data and other future observations.
Since forward selection involves training a lot of models, you run a fairly
high risk of this happening. To keep this risk low, only use forward selection
when you have a large amount of data and a relatively small total number of
predictors. More advanced methods do not suffer from this
problem as much; see the additional resources at the end of this chapter for
where to learn more about advanced predictor selection methods.</p>
</blockquote>
</div>
<div id="forward-selection-in-r" class="section level3 hasAnchor" number="6.8.3">
<h3><span class="header-section-number">6.8.3</span> Forward selection in R<a href="classification2.html#forward-selection-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We now turn to implementing forward selection in R.
Unfortunately there is no built-in way to do this using the <code>tidymodels</code> framework,
so we will have to code it ourselves. First we will use the <code>select</code> function to extract a smaller set of predictors
to work with in this illustrative example—<code>Smoothness</code>, <code>Concavity</code>, <code>Perimeter</code>, <code>Irrelevant1</code>, <code>Irrelevant2</code>, and <code>Irrelevant3</code>—as
well as the <code>Class</code> variable as the label. We will also extract the column names for the full set of predictors.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="classification2.html#cb382-1" tabindex="-1"></a>cancer_subset <span class="ot">&lt;-</span> cancer_irrelevant <span class="sc">|&gt;</span></span>
<span id="cb382-2"><a href="classification2.html#cb382-2" tabindex="-1"></a>  <span class="fu">select</span>(Class,</span>
<span id="cb382-3"><a href="classification2.html#cb382-3" tabindex="-1"></a>         Smoothness,</span>
<span id="cb382-4"><a href="classification2.html#cb382-4" tabindex="-1"></a>         Concavity,</span>
<span id="cb382-5"><a href="classification2.html#cb382-5" tabindex="-1"></a>         Perimeter,</span>
<span id="cb382-6"><a href="classification2.html#cb382-6" tabindex="-1"></a>         Irrelevant1,</span>
<span id="cb382-7"><a href="classification2.html#cb382-7" tabindex="-1"></a>         Irrelevant2,</span>
<span id="cb382-8"><a href="classification2.html#cb382-8" tabindex="-1"></a>         Irrelevant3)</span>
<span id="cb382-9"><a href="classification2.html#cb382-9" tabindex="-1"></a></span>
<span id="cb382-10"><a href="classification2.html#cb382-10" tabindex="-1"></a>names <span class="ot">&lt;-</span> <span class="fu">colnames</span>(cancer_subset <span class="sc">|&gt;</span> <span class="fu">select</span>(<span class="sc">-</span>Class))</span>
<span id="cb382-11"><a href="classification2.html#cb382-11" tabindex="-1"></a></span>
<span id="cb382-12"><a href="classification2.html#cb382-12" tabindex="-1"></a>cancer_subset</span></code></pre></div>
<pre><code>## # A tibble: 569 × 7
##    Class     Smoothness Concavity Perimeter Irrelevant1 Irrelevant2 Irrelevant3
##    &lt;fct&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
##  1 Malignant     0.118     0.300      123.            1           0           1
##  2 Malignant     0.0847    0.0869     133.            0           0           0
##  3 Malignant     0.110     0.197      130             0           0           0
##  4 Malignant     0.142     0.241       77.6           0           1           0
##  5 Malignant     0.100     0.198      135.            0           0           0
##  6 Malignant     0.128     0.158       82.6           1           0           1
##  7 Malignant     0.0946    0.113      120.            0           1           1
##  8 Malignant     0.119     0.0937      90.2           1           0           0
##  9 Malignant     0.127     0.186       87.5           0           0           1
## 10 Malignant     0.119     0.227       84.0           1           1           0
## # ℹ 559 more rows</code></pre>
<p>The key idea of the forward selection code is to use the <code>paste</code> function (which concatenates strings
separated by spaces) to create a model formula for each subset of predictors for which we want to build a model.
The <code>collapse</code> argument tells <code>paste</code> what to put between the items in the list;
to make a formula, we need to put a <code>+</code> symbol between each variable.
As an example, let’s make a model formula for all the predictors,
which should output something like
<code>Class ~ Smoothness + Concavity + Perimeter + Irrelevant1 + Irrelevant2 + Irrelevant3</code>:</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="classification2.html#cb384-1" tabindex="-1"></a>example_formula <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&quot;Class&quot;</span>, <span class="st">&quot;~&quot;</span>, <span class="fu">paste</span>(names, <span class="at">collapse=</span><span class="st">&quot;+&quot;</span>))</span>
<span id="cb384-2"><a href="classification2.html#cb384-2" tabindex="-1"></a>example_formula</span></code></pre></div>
<pre><code>## [1] &quot;Class ~ Smoothness+Concavity+Perimeter+Irrelevant1+Irrelevant2+Irrelevant3&quot;</code></pre>
<p>Finally, we need to write some code that performs the task of sequentially
finding the best predictor to add to the model.
If you recall the end of the wrangling chapter, we mentioned
that sometimes one needs more flexible forms of iteration than what
we have used earlier, and in these cases one typically resorts to
a <em>for loop</em>; see <a href="https://r4ds.had.co.nz/iteration.html">the chapter on iteration</a> in <em>R for Data Science</em> <span class="citation">(<a href="#ref-wickham2016r">Wickham and Grolemund 2016</a>)</span>.
Here we will use two for loops:
one over increasing predictor set sizes
(where you see <code>for (i in 1:length(names))</code> below),
and another to check which predictor to add in each round (where you see <code>for (j in 1:length(names))</code> below).
For each set of predictors to try, we construct a model formula,
pass it into a <code>recipe</code>, build a <code>workflow</code> that tunes
a K-NN classifier using 5-fold cross-validation,
and finally records the estimated accuracy.</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="classification2.html#cb386-1" tabindex="-1"></a><span class="co"># create an empty tibble to store the results</span></span>
<span id="cb386-2"><a href="classification2.html#cb386-2" tabindex="-1"></a>accuracies <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">size =</span> <span class="fu">integer</span>(),</span>
<span id="cb386-3"><a href="classification2.html#cb386-3" tabindex="-1"></a>                     <span class="at">model_string =</span> <span class="fu">character</span>(),</span>
<span id="cb386-4"><a href="classification2.html#cb386-4" tabindex="-1"></a>                     <span class="at">accuracy =</span> <span class="fu">numeric</span>())</span>
<span id="cb386-5"><a href="classification2.html#cb386-5" tabindex="-1"></a></span>
<span id="cb386-6"><a href="classification2.html#cb386-6" tabindex="-1"></a><span class="co"># create a model specification</span></span>
<span id="cb386-7"><a href="classification2.html#cb386-7" tabindex="-1"></a>knn_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">weight_func =</span> <span class="st">&quot;rectangular&quot;</span>,</span>
<span id="cb386-8"><a href="classification2.html#cb386-8" tabindex="-1"></a>                             <span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|&gt;</span></span>
<span id="cb386-9"><a href="classification2.html#cb386-9" tabindex="-1"></a>     <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb386-10"><a href="classification2.html#cb386-10" tabindex="-1"></a>     <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>)</span>
<span id="cb386-11"><a href="classification2.html#cb386-11" tabindex="-1"></a></span>
<span id="cb386-12"><a href="classification2.html#cb386-12" tabindex="-1"></a><span class="co"># create a 5-fold cross-validation object</span></span>
<span id="cb386-13"><a href="classification2.html#cb386-13" tabindex="-1"></a>cancer_vfold <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(cancer_subset, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> Class)</span>
<span id="cb386-14"><a href="classification2.html#cb386-14" tabindex="-1"></a></span>
<span id="cb386-15"><a href="classification2.html#cb386-15" tabindex="-1"></a><span class="co"># store the total number of predictors</span></span>
<span id="cb386-16"><a href="classification2.html#cb386-16" tabindex="-1"></a>n_total <span class="ot">&lt;-</span> <span class="fu">length</span>(names)</span>
<span id="cb386-17"><a href="classification2.html#cb386-17" tabindex="-1"></a></span>
<span id="cb386-18"><a href="classification2.html#cb386-18" tabindex="-1"></a><span class="co"># stores selected predictors</span></span>
<span id="cb386-19"><a href="classification2.html#cb386-19" tabindex="-1"></a>selected <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb386-20"><a href="classification2.html#cb386-20" tabindex="-1"></a></span>
<span id="cb386-21"><a href="classification2.html#cb386-21" tabindex="-1"></a><span class="co"># for every size from 1 to the total number of predictors</span></span>
<span id="cb386-22"><a href="classification2.html#cb386-22" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_total) {</span>
<span id="cb386-23"><a href="classification2.html#cb386-23" tabindex="-1"></a>    <span class="co"># for every predictor still not added yet</span></span>
<span id="cb386-24"><a href="classification2.html#cb386-24" tabindex="-1"></a>    accs <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb386-25"><a href="classification2.html#cb386-25" tabindex="-1"></a>    models <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb386-26"><a href="classification2.html#cb386-26" tabindex="-1"></a>    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(names)) {</span>
<span id="cb386-27"><a href="classification2.html#cb386-27" tabindex="-1"></a>        <span class="co"># create a model string for this combination of predictors</span></span>
<span id="cb386-28"><a href="classification2.html#cb386-28" tabindex="-1"></a>        preds_new <span class="ot">&lt;-</span> <span class="fu">c</span>(selected, names[[j]])</span>
<span id="cb386-29"><a href="classification2.html#cb386-29" tabindex="-1"></a>        model_string <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="st">&quot;Class&quot;</span>, <span class="st">&quot;~&quot;</span>, <span class="fu">paste</span>(preds_new, <span class="at">collapse=</span><span class="st">&quot;+&quot;</span>))</span>
<span id="cb386-30"><a href="classification2.html#cb386-30" tabindex="-1"></a></span>
<span id="cb386-31"><a href="classification2.html#cb386-31" tabindex="-1"></a>        <span class="co"># create a recipe from the model string</span></span>
<span id="cb386-32"><a href="classification2.html#cb386-32" tabindex="-1"></a>        cancer_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(<span class="fu">as.formula</span>(model_string),</span>
<span id="cb386-33"><a href="classification2.html#cb386-33" tabindex="-1"></a>                                <span class="at">data =</span> cancer_subset) <span class="sc">|&gt;</span></span>
<span id="cb386-34"><a href="classification2.html#cb386-34" tabindex="-1"></a>                          <span class="fu">step_scale</span>(<span class="fu">all_predictors</span>()) <span class="sc">|&gt;</span></span>
<span id="cb386-35"><a href="classification2.html#cb386-35" tabindex="-1"></a>                          <span class="fu">step_center</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb386-36"><a href="classification2.html#cb386-36" tabindex="-1"></a></span>
<span id="cb386-37"><a href="classification2.html#cb386-37" tabindex="-1"></a>        <span class="co"># tune the K-NN classifier with these predictors,</span></span>
<span id="cb386-38"><a href="classification2.html#cb386-38" tabindex="-1"></a>        <span class="co"># and collect the accuracy for the best K</span></span>
<span id="cb386-39"><a href="classification2.html#cb386-39" tabindex="-1"></a>        acc <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb386-40"><a href="classification2.html#cb386-40" tabindex="-1"></a>          <span class="fu">add_recipe</span>(cancer_recipe) <span class="sc">|&gt;</span></span>
<span id="cb386-41"><a href="classification2.html#cb386-41" tabindex="-1"></a>          <span class="fu">add_model</span>(knn_spec) <span class="sc">|&gt;</span></span>
<span id="cb386-42"><a href="classification2.html#cb386-42" tabindex="-1"></a>          <span class="fu">tune_grid</span>(<span class="at">resamples =</span> cancer_vfold, <span class="at">grid =</span> <span class="dv">10</span>) <span class="sc">|&gt;</span></span>
<span id="cb386-43"><a href="classification2.html#cb386-43" tabindex="-1"></a>          <span class="fu">collect_metrics</span>() <span class="sc">|&gt;</span></span>
<span id="cb386-44"><a href="classification2.html#cb386-44" tabindex="-1"></a>          <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;accuracy&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb386-45"><a href="classification2.html#cb386-45" tabindex="-1"></a>          <span class="fu">summarize</span>(<span class="at">mx =</span> <span class="fu">max</span>(mean))</span>
<span id="cb386-46"><a href="classification2.html#cb386-46" tabindex="-1"></a>        acc <span class="ot">&lt;-</span> acc<span class="sc">$</span>mx <span class="sc">|&gt;</span> <span class="fu">unlist</span>()</span>
<span id="cb386-47"><a href="classification2.html#cb386-47" tabindex="-1"></a></span>
<span id="cb386-48"><a href="classification2.html#cb386-48" tabindex="-1"></a>        <span class="co"># add this result to the dataframe</span></span>
<span id="cb386-49"><a href="classification2.html#cb386-49" tabindex="-1"></a>        accs[[j]] <span class="ot">&lt;-</span> acc</span>
<span id="cb386-50"><a href="classification2.html#cb386-50" tabindex="-1"></a>        models[[j]] <span class="ot">&lt;-</span> model_string</span>
<span id="cb386-51"><a href="classification2.html#cb386-51" tabindex="-1"></a>    }</span>
<span id="cb386-52"><a href="classification2.html#cb386-52" tabindex="-1"></a>    jstar <span class="ot">&lt;-</span> <span class="fu">which.max</span>(<span class="fu">unlist</span>(accs))</span>
<span id="cb386-53"><a href="classification2.html#cb386-53" tabindex="-1"></a>    accuracies <span class="ot">&lt;-</span> accuracies <span class="sc">|&gt;</span></span>
<span id="cb386-54"><a href="classification2.html#cb386-54" tabindex="-1"></a>      <span class="fu">add_row</span>(<span class="at">size =</span> i,</span>
<span id="cb386-55"><a href="classification2.html#cb386-55" tabindex="-1"></a>              <span class="at">model_string =</span> models[[jstar]],</span>
<span id="cb386-56"><a href="classification2.html#cb386-56" tabindex="-1"></a>              <span class="at">accuracy =</span> accs[[jstar]])</span>
<span id="cb386-57"><a href="classification2.html#cb386-57" tabindex="-1"></a>    selected <span class="ot">&lt;-</span> <span class="fu">c</span>(selected, names[[jstar]])</span>
<span id="cb386-58"><a href="classification2.html#cb386-58" tabindex="-1"></a>    names <span class="ot">&lt;-</span> names[<span class="sc">-</span>jstar]</span>
<span id="cb386-59"><a href="classification2.html#cb386-59" tabindex="-1"></a>}</span>
<span id="cb386-60"><a href="classification2.html#cb386-60" tabindex="-1"></a>accuracies</span></code></pre></div>
<pre><code>## # A tibble: 6 × 3
##    size model_string                                                    accuracy
##   &lt;int&gt; &lt;chr&gt;                                                              &lt;dbl&gt;
## 1     1 Class ~ Perimeter                                                  0.896
## 2     2 Class ~ Perimeter+Concavity                                        0.916
## 3     3 Class ~ Perimeter+Concavity+Smoothness                             0.931
## 4     4 Class ~ Perimeter+Concavity+Smoothness+Irrelevant1                 0.928
## 5     5 Class ~ Perimeter+Concavity+Smoothness+Irrelevant1+Irrelevant3     0.924
## 6     6 Class ~ Perimeter+Concavity+Smoothness+Irrelevant1+Irrelevant3…    0.902</code></pre>
<p>Interesting! The forward selection procedure first added the three meaningful variables <code>Perimeter</code>,
<code>Concavity</code>, and <code>Smoothness</code>, followed by the irrelevant variables. Figure <a href="classification2.html#fig:06-fwdsel-3">6.12</a>
visualizes the accuracy versus the number of predictors in the model. You can see that
as meaningful predictors are added, the estimated accuracy increases substantially; and as you add irrelevant
variables, the accuracy either exhibits small fluctuations or decreases as the model attempts to tune the number
of neighbors to account for the extra noise. In order to pick the right model from the sequence, you have
to balance high accuracy and model simplicity (i.e., having fewer predictors and a lower chance of overfitting). The
way to find that balance is to look for the <em>elbow</em>
in Figure <a href="classification2.html#fig:06-fwdsel-3">6.12</a>, i.e., the place on the plot where the accuracy stops increasing dramatically and
levels off or begins to decrease. The elbow in Figure <a href="classification2.html#fig:06-fwdsel-3">6.12</a> appears to occur at the model with
3 predictors; after that point the accuracy levels off. So here the right trade-off of accuracy and number of predictors
occurs with 3 variables: <code>Class ~ Perimeter + Concavity + Smoothness</code>. In other words, we have successfully removed irrelevant
predictors from the model! It is always worth remembering, however, that what cross-validation gives you
is an <em>estimate</em> of the true accuracy; you have to use your judgement when looking at this plot to decide
where the elbow occurs, and whether adding a variable provides a meaningful increase in accuracy.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:06-fwdsel-3"></span>
<img src="_main_files/figure-html/06-fwdsel-3-1.png" alt="Estimated accuracy versus the number of predictors for the sequence of models built using forward selection." width="65%" />
<p class="caption">
Figure 6.12: Estimated accuracy versus the number of predictors for the sequence of models built using forward selection.
</p>
</div>
<blockquote>
<p><strong>Note:</strong> Since the choice of which variables to include as predictors is
part of tuning your classifier, you <em>cannot use your test data</em> for this
process!</p>
</blockquote>
</div>
</div>
<div id="exercises-5" class="section level2 hasAnchor" number="6.9">
<h2><span class="header-section-number">6.9</span> Exercises<a href="classification2.html#exercises-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Practice exercises for the material covered in this chapter
can be found in the accompanying
<a href="https://worksheets.datasciencebook.ca">worksheets repository</a>
in the “Classification II: evaluation and tuning” row.
You can launch an interactive version of the worksheet in your browser by clicking the “launch binder” button.
You can also preview a non-interactive version of the worksheet by clicking “view worksheet.”
If you instead decide to download the worksheet and run it on your own machine,
make sure to follow the instructions for computer setup
found in Chapter <a href="setup.html#setup">13</a>. This will ensure that the automated feedback
and guidance that the worksheets provide will function as intended.</p>
</div>
<div id="additional-resources-3" class="section level2 hasAnchor" number="6.10">
<h2><span class="header-section-number">6.10</span> Additional resources<a href="classification2.html#additional-resources-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>The <a href="https://tidymodels.org/packages"><code>tidymodels</code> website</a> is an excellent
reference for more details on, and advanced usage of, the functions and
packages in the past two chapters. Aside from that, it also has a <a href="https://www.tidymodels.org/start/">nice
beginner’s tutorial</a> and <a href="https://www.tidymodels.org/learn/">an extensive list
of more advanced examples</a> that you can use
to continue learning beyond the scope of this book. It’s worth noting that the
<code>tidymodels</code> package does a lot more than just classification, and so the
examples on the website similarly go beyond classification as well. In the next
two chapters, you’ll learn about another kind of predictive modeling setting,
so it might be worth visiting the website only after reading through those
chapters.</li>
<li><em>An Introduction to Statistical Learning</em> <span class="citation">(<a href="#ref-james2013introduction">James et al. 2013</a>)</span> provides
a great next stop in the process of
learning about classification. Chapter 4 discusses additional basic techniques
for classification that we do not cover, such as logistic regression, linear
discriminant analysis, and naive Bayes. Chapter 5 goes into much more detail
about cross-validation. Chapters 8 and 9 cover decision trees and support
vector machines, two very popular but more advanced classification methods.
Finally, Chapter 6 covers a number of methods for selecting predictor
variables. Note that while this book is still a very accessible introductory
text, it requires a bit more mathematical background than we require.</li>
</ul>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bealesubset" class="csl-entry">
Beale, Evelyn Martin Lansdowne, Maurice George Kendall, and David Mann. 1967. <span>“The Discarding of Variables in Multivariate Analysis.”</span> <em>Biometrika</em> 54 (3-4): 357–66.
</div>
<div id="ref-forwarddraper" class="csl-entry">
Draper, Norman, and Harry Smith. 1966. <em>Applied Regression Analysis</em>. Wiley.
</div>
<div id="ref-forwardefroymson" class="csl-entry">
Eforymson, M. 1966. <span>“Stepwise Regression—a Backward and Forward Look.”</span> In <em>Eastern Regional Meetings of the Institute of Mathematical Statistics</em>.
</div>
<div id="ref-hockingsubset" class="csl-entry">
Hocking, Ronald, and R. N. Leslie. 1967. <span>“Selection of the Best Subset in Regression Analysis.”</span> <em>Technometrics</em> 9 (4): 531–40.
</div>
<div id="ref-james2013introduction" class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. 1st ed. Springer. <a href="https://www.statlearning.com/">https://www.statlearning.com/</a>.
</div>
<div id="ref-streetbreastcancer" class="csl-entry">
Street, William Nick, William Wolberg, and Olvi Mangasarian. 1993. <span>“Nuclear Feature Extraction for Breast Tumor Diagnosis.”</span> In <em>International Symposium on Electronic Imaging: Science and Technology</em>.
</div>
<div id="ref-wickham2016r" class="csl-entry">
Wickham, Hadley, and Garrett Grolemund. 2016. <em>R for Data Science: Import, Tidy, Transform, Visualize, and Model Data</em>. O’Reilly. <a href="https://r4ds.had.co.nz/">https://r4ds.had.co.nz/</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
