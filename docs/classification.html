<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Classification | Introduction to Data Science</title>
  <meta name="description" content="This is an open source textbook for teaching introductory data science." />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Classification | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open source textbook for teaching introductory data science." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Classification | Introduction to Data Science" />
  
  <meta name="twitter:description" content="This is an open source textbook for teaching introductory data science." />
  

<meta name="author" content="Tiffany-Anne Timbers" />
<meta name="author" content="Melissa Lee" />
<meta name="author" content="Trevor Campbell" />


<meta name="date" content="2019-08-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="GitHub.html">
<link rel="next" href="classification-continued.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction to Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction to Data Science</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#chapter-learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#jupyter-notebooks"><i class="fa fa-check"></i><b>1.2</b> Jupyter notebooks</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#loading-a-tabular-dataset"><i class="fa fa-check"></i><b>1.3</b> Loading a tabular dataset</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#assigning-value-to-an-object"><i class="fa fa-check"></i><b>1.4</b> Assigning value to an object</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#subsetting-data-frames-with-select-filter"><i class="fa fa-check"></i><b>1.5</b> Subsetting data frames with <code>select</code> &amp; <code>filter</code></a><ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#using-select-to-subset-multiple-columns"><i class="fa fa-check"></i><b>1.5.1</b> Using <code>select</code> to subset multiple columns</a></li>
<li class="chapter" data-level="1.5.2" data-path="index.html"><a href="index.html#using-select-to-subset-a-range-of-columns"><i class="fa fa-check"></i><b>1.5.2</b> Using <code>select</code> to subset a range of columns</a></li>
<li class="chapter" data-level="1.5.3" data-path="index.html"><a href="index.html#using-filter-to-subset-a-single-column"><i class="fa fa-check"></i><b>1.5.3</b> Using <code>filter</code> to subset a single column</a></li>
<li class="chapter" data-level="1.5.4" data-path="index.html"><a href="index.html#using-filter-to-get-rows-with-values-above-a-threshold"><i class="fa fa-check"></i><b>1.5.4</b> Using <code>filter</code> to get rows with values above a threshold</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#combining-functions-using-the-pipe-operator"><i class="fa fa-check"></i><b>1.6</b> Combining functions using the pipe operator: %&gt;%</a><ul>
<li class="chapter" data-level="1.6.1" data-path="index.html"><a href="index.html#using-to-combine-filter-and-select"><i class="fa fa-check"></i><b>1.6.1</b> Using %&gt;% to combine <code>filter</code> and <code>select</code></a></li>
<li class="chapter" data-level="1.6.2" data-path="index.html"><a href="index.html#using-with-more-than-two-functions"><i class="fa fa-check"></i><b>1.6.2</b> Using %&gt;% with more than two functions</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#creating-visualizations-in-r"><i class="fa fa-check"></i><b>1.7</b> Creating Visualizations in R</a><ul>
<li class="chapter" data-level="1.7.1" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot"><i class="fa fa-check"></i><b>1.7.1</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.7.2" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-scatter-plot-1"><i class="fa fa-check"></i><b>1.7.2</b> Using <code>ggplot</code> to create a scatter plot</a></li>
<li class="chapter" data-level="1.7.3" data-path="index.html"><a href="index.html#formatting-ggplot-objects"><i class="fa fa-check"></i><b>1.7.3</b> Formatting ggplot objects</a></li>
<li class="chapter" data-level="1.7.4" data-path="index.html"><a href="index.html#coloring-points-by-group"><i class="fa fa-check"></i><b>1.7.4</b> Coloring points by group</a></li>
<li class="chapter" data-level="1.7.5" data-path="index.html"><a href="index.html#whats-next"><i class="fa fa-check"></i><b>1.7.5</b> What’s next?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reading.html"><a href="reading.html"><i class="fa fa-check"></i><b>2</b> Reading in data locally and from the web</a><ul>
<li class="chapter" data-level="2.1" data-path="reading.html"><a href="reading.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="reading.html"><a href="reading.html#chapter-learning-objectives-1"><i class="fa fa-check"></i><b>2.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="2.3" data-path="reading.html"><a href="reading.html#absolute-and-relative-file-paths"><i class="fa fa-check"></i><b>2.3</b> Absolute and relative file paths</a></li>
<li class="chapter" data-level="2.4" data-path="reading.html"><a href="reading.html#reading-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4</b> Reading tabular data into R</a><ul>
<li class="chapter" data-level="2.4.1" data-path="reading.html"><a href="reading.html#read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4.1</b> <code>read_delim</code> as a more flexible method to get tabular data into R</a></li>
<li class="chapter" data-level="2.4.2" data-path="reading.html"><a href="reading.html#reading-tabular-data-directly-from-a-url"><i class="fa fa-check"></i><b>2.4.2</b> Reading tabular data directly from a URL</a></li>
<li class="chapter" data-level="2.4.3" data-path="reading.html"><a href="reading.html#previewing-a-data-file-before-reading-it-into-r"><i class="fa fa-check"></i><b>2.4.3</b> Previewing a data file before reading it into R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reading.html"><a href="reading.html#scraping-data-off-the-web-using-r"><i class="fa fa-check"></i><b>2.5</b> Scraping data off the web using R</a><ul>
<li class="chapter" data-level="2.5.1" data-path="reading.html"><a href="reading.html#html-and-css-selectors"><i class="fa fa-check"></i><b>2.5.1</b> HTML and CSS selectors</a></li>
<li class="chapter" data-level="2.5.2" data-path="reading.html"><a href="reading.html#are-you-allowed-to-scrape-that-website"><i class="fa fa-check"></i><b>2.5.2</b> Are you allowed to scrape that website?</a></li>
<li class="chapter" data-level="2.5.3" data-path="reading.html"><a href="reading.html#using-rvest"><i class="fa fa-check"></i><b>2.5.3</b> Using <code>rvest</code></a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="reading.html"><a href="reading.html#additional-readingsresources"><i class="fa fa-check"></i><b>2.6</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="wrangling.html"><a href="wrangling.html"><i class="fa fa-check"></i><b>3</b> Cleaning and wrangling data</a><ul>
<li class="chapter" data-level="3.1" data-path="wrangling.html"><a href="wrangling.html#overview-1"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="wrangling.html"><a href="wrangling.html#chapter-learning-objectives-2"><i class="fa fa-check"></i><b>3.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="3.3" data-path="wrangling.html"><a href="wrangling.html#vectors-and-data-frames"><i class="fa fa-check"></i><b>3.3</b> Vectors and Data frames</a><ul>
<li class="chapter" data-level="3.3.1" data-path="wrangling.html"><a href="wrangling.html#what-is-a-data-frame"><i class="fa fa-check"></i><b>3.3.1</b> What is a data frame?</a></li>
<li class="chapter" data-level="3.3.2" data-path="wrangling.html"><a href="wrangling.html#what-is-a-vector"><i class="fa fa-check"></i><b>3.3.2</b> What is a vector?</a></li>
<li class="chapter" data-level="3.3.3" data-path="wrangling.html"><a href="wrangling.html#how-are-vectors-different-from-a-list"><i class="fa fa-check"></i><b>3.3.3</b> How are vectors different from a list?</a></li>
<li class="chapter" data-level="3.3.4" data-path="wrangling.html"><a href="wrangling.html#what-does-this-have-to-do-with-data-frames"><i class="fa fa-check"></i><b>3.3.4</b> What does this have to do with data frames?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="wrangling.html"><a href="wrangling.html#the-dplyr-functions"><i class="fa fa-check"></i><b>3.4</b> The <code>dplyr</code> functions</a></li>
<li class="chapter" data-level="3.5" data-path="wrangling.html"><a href="wrangling.html#tidy-data"><i class="fa fa-check"></i><b>3.5</b> Tidy Data</a><ul>
<li class="chapter" data-level="3.5.1" data-path="wrangling.html"><a href="wrangling.html#what-is-tidy-data"><i class="fa fa-check"></i><b>3.5.1</b> What is tidy data?</a></li>
<li class="chapter" data-level="3.5.2" data-path="wrangling.html"><a href="wrangling.html#why-is-tidy-data-important-in-r"><i class="fa fa-check"></i><b>3.5.2</b> Why is tidy data important in R?</a></li>
<li class="chapter" data-level="3.5.3" data-path="wrangling.html"><a href="wrangling.html#going-from-wide-to-long-or-tidy-using-gather"><i class="fa fa-check"></i><b>3.5.3</b> Going from wide to long (or tidy!) using <code>gather</code></a></li>
<li class="chapter" data-level="3.5.4" data-path="wrangling.html"><a href="wrangling.html#using-separate-to-deal-with-multiple-delimiters"><i class="fa fa-check"></i><b>3.5.4</b> Using separate to deal with multiple delimiters</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="wrangling.html"><a href="wrangling.html#using-purrrs-map-functions-to-iterate"><i class="fa fa-check"></i><b>3.6</b> Using <code>purrr</code>’s <code>map*</code> functions to iterate</a><ul>
<li class="chapter" data-level="3.6.1" data-path="wrangling.html"><a href="wrangling.html#a-bit-more-about-the-map-functions"><i class="fa fa-check"></i><b>3.6.1</b> A bit more about the <code>map*</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="wrangling.html"><a href="wrangling.html#additional-readingsresources-1"><i class="fa fa-check"></i><b>3.7</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>4</b> Effective data visualization</a><ul>
<li class="chapter" data-level="4.1" data-path="viz.html"><a href="viz.html#overview-2"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="viz.html"><a href="viz.html#chapter-learning-objectives-3"><i class="fa fa-check"></i><b>4.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="4.3" data-path="viz.html"><a href="viz.html#ggplot2-for-data-visualization-in-r"><i class="fa fa-check"></i><b>4.3</b> <code>ggplot2</code> for data visualization in R</a></li>
<li class="chapter" data-level="4.4" data-path="viz.html"><a href="viz.html#making-effective-vizualizations"><i class="fa fa-check"></i><b>4.4</b> Making effective vizualizations</a><ul>
<li class="chapter" data-level="4.4.1" data-path="viz.html"><a href="viz.html#some-guiding-principles-for-making-effectice-visualizations"><i class="fa fa-check"></i><b>4.4.1</b> Some guiding principles for making effectice visualizations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="GitHub.html"><a href="GitHub.html"><i class="fa fa-check"></i><b>5</b> Version control with GitHub</a><ul>
<li class="chapter" data-level="5.1" data-path="GitHub.html"><a href="GitHub.html#overview-3"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="GitHub.html"><a href="GitHub.html#videos-to-learn-about-version-control-with-github-and-git"><i class="fa fa-check"></i><b>5.2</b> Videos to learn about version control with GitHub and Git</a><ul>
<li class="chapter" data-level="5.2.1" data-path="GitHub.html"><a href="GitHub.html#creating-a-github-repository"><i class="fa fa-check"></i><b>5.2.1</b> Creating a GitHub repository</a></li>
<li class="chapter" data-level="5.2.2" data-path="GitHub.html"><a href="GitHub.html#exploring-a-github-repository"><i class="fa fa-check"></i><b>5.2.2</b> Exploring a GitHub repository</a></li>
<li class="chapter" data-level="5.2.3" data-path="GitHub.html"><a href="GitHub.html#directly-editing-files-on-github"><i class="fa fa-check"></i><b>5.2.3</b> Directly editing files on GitHub</a></li>
<li class="chapter" data-level="5.2.4" data-path="GitHub.html"><a href="GitHub.html#logging-changes-and-pushing-them-to-github"><i class="fa fa-check"></i><b>5.2.4</b> Logging changes and pushing them to GitHub</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="GitHub.html"><a href="GitHub.html#git-command-cheatsheet"><i class="fa fa-check"></i><b>5.3</b> Git command cheatsheet</a><ul>
<li class="chapter" data-level="5.3.1" data-path="GitHub.html"><a href="GitHub.html#getting-a-repository-from-github-onto-the-server-for-the-first-time"><i class="fa fa-check"></i><b>5.3.1</b> Getting a repository from GitHub onto the server for the first time</a></li>
<li class="chapter" data-level="5.3.2" data-path="GitHub.html"><a href="GitHub.html#logging-changes"><i class="fa fa-check"></i><b>5.3.2</b> Logging changes</a></li>
<li class="chapter" data-level="5.3.3" data-path="GitHub.html"><a href="GitHub.html#sending-your-changes-back-to-github"><i class="fa fa-check"></i><b>5.3.3</b> Sending your changes back to GitHub</a></li>
<li class="chapter" data-level="5.3.4" data-path="GitHub.html"><a href="GitHub.html#getting-changes"><i class="fa fa-check"></i><b>5.3.4</b> Getting changes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="GitHub.html"><a href="GitHub.html#terminal-cheatsheet"><i class="fa fa-check"></i><b>5.4</b> Terminal cheatsheet</a><ul>
<li class="chapter" data-level="5.4.1" data-path="GitHub.html"><a href="GitHub.html#see-where-you-are"><i class="fa fa-check"></i><b>5.4.1</b> See where you are:</a></li>
<li class="chapter" data-level="5.4.2" data-path="GitHub.html"><a href="GitHub.html#see-what-is-inside-the-directory-where-you-are"><i class="fa fa-check"></i><b>5.4.2</b> See what is inside the directory where you are:</a></li>
<li class="chapter" data-level="5.4.3" data-path="GitHub.html"><a href="GitHub.html#move-to-a-different-directory"><i class="fa fa-check"></i><b>5.4.3</b> Move to a different directory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>6</b> Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="classification.html"><a href="classification.html#overview-4"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="classification.html"><a href="classification.html#learning-objectives"><i class="fa fa-check"></i><b>6.2</b> Learning objectives</a></li>
<li class="chapter" data-level="6.3" data-path="classification.html"><a href="classification.html#classification-1"><i class="fa fa-check"></i><b>6.3</b> Classification</a></li>
<li class="chapter" data-level="6.4" data-path="classification.html"><a href="classification.html#wisconsin-breast-cancer-example"><i class="fa fa-check"></i><b>6.4</b> Wisconsin Breast Cancer Example:</a><ul>
<li class="chapter" data-level="6.4.1" data-path="classification.html"><a href="classification.html#data-exploration"><i class="fa fa-check"></i><b>6.4.1</b> Data Exploration</a></li>
<li class="chapter" data-level="6.4.2" data-path="classification.html"><a href="classification.html#k-nearest-neighbour-classifier"><i class="fa fa-check"></i><b>6.4.2</b> K-Nearest Neighbour Classifier</a></li>
<li class="chapter" data-level="6.4.3" data-path="classification.html"><a href="classification.html#k-nearest-neighbours-in-r"><i class="fa fa-check"></i><b>6.4.3</b> K-Nearest Neighbours in R</a></li>
<li class="chapter" data-level="6.4.4" data-path="classification.html"><a href="classification.html#more-than-two-explanatory-variablespredictors"><i class="fa fa-check"></i><b>6.4.4</b> More than two explanatory variables/predictors</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="classification.html"><a href="classification.html#additional-readingsresources-2"><i class="fa fa-check"></i><b>6.5</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification-continued.html"><a href="classification-continued.html"><i class="fa fa-check"></i><b>7</b> Classification continued</a><ul>
<li class="chapter" data-level="7.1" data-path="classification-continued.html"><a href="classification-continued.html#overview-5"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="classification-continued.html"><a href="classification-continued.html#learning-objectives-1"><i class="fa fa-check"></i><b>7.2</b> Learning objectives</a></li>
<li class="chapter" data-level="7.3" data-path="classification-continued.html"><a href="classification-continued.html#assessing-how-good-your-classifier-is"><i class="fa fa-check"></i><b>7.3</b> Assessing how good your classifier is</a><ul>
<li class="chapter" data-level="7.3.1" data-path="classification-continued.html"><a href="classification-continued.html#assessing-your-classifier-in-r"><i class="fa fa-check"></i><b>7.3.1</b> Assessing your classifier in R</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="classification-continued.html"><a href="classification-continued.html#cross-validation-for-assessing-classifier-quality"><i class="fa fa-check"></i><b>7.4</b> Cross-validation for assessing classifier quality</a></li>
<li class="chapter" data-level="7.5" data-path="classification-continued.html"><a href="classification-continued.html#choosing-the-number-of-neighbours-for-k-nn-classification"><i class="fa fa-check"></i><b>7.5</b> Choosing the number of neighbours for k-nn classification</a></li>
<li class="chapter" data-level="7.6" data-path="classification-continued.html"><a href="classification-continued.html#other-ways-to-increase-accuracy"><i class="fa fa-check"></i><b>7.6</b> Other ways to increase accuracy</a></li>
<li class="chapter" data-level="7.7" data-path="classification-continued.html"><a href="classification-continued.html#test-data-set"><i class="fa fa-check"></i><b>7.7</b> Test data set</a></li>
<li class="chapter" data-level="7.8" data-path="classification-continued.html"><a href="classification-continued.html#scaling-your-data"><i class="fa fa-check"></i><b>7.8</b> Scaling your data</a></li>
<li class="chapter" data-level="7.9" data-path="classification-continued.html"><a href="classification-continued.html#strengths-and-limitations-of-k-nn-classification"><i class="fa fa-check"></i><b>7.9</b> Strengths and limitations of k-nn classification</a><ul>
<li class="chapter" data-level="7.9.1" data-path="classification-continued.html"><a href="classification-continued.html#strengths-of-k-nn-classification"><i class="fa fa-check"></i><b>7.9.1</b> Strengths of k-nn classification</a></li>
<li class="chapter" data-level="7.9.2" data-path="classification-continued.html"><a href="classification-continued.html#limitations-of-k-nn-classification"><i class="fa fa-check"></i><b>7.9.2</b> Limitations of k-nn classification</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="classification-continued.html"><a href="classification-continued.html#additional-readingsresources-3"><i class="fa fa-check"></i><b>7.10</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression1.html"><a href="regression1.html"><i class="fa fa-check"></i><b>8</b> Introduction to regression through K-nearest neighbours</a><ul>
<li class="chapter" data-level="8.1" data-path="regression1.html"><a href="regression1.html#overview-6"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="regression1.html"><a href="regression1.html#learning-objectives-2"><i class="fa fa-check"></i><b>8.2</b> Learning objectives</a></li>
<li class="chapter" data-level="8.3" data-path="regression1.html"><a href="regression1.html#regression"><i class="fa fa-check"></i><b>8.3</b> Regression</a></li>
<li class="chapter" data-level="8.4" data-path="regression1.html"><a href="regression1.html#sacremento-real-estate-example"><i class="fa fa-check"></i><b>8.4</b> Sacremento real estate example</a></li>
<li class="chapter" data-level="8.5" data-path="regression1.html"><a href="regression1.html#k-nearest-neighbours-regression"><i class="fa fa-check"></i><b>8.5</b> K-nearest neighbours regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression1.html"><a href="regression1.html#assessing-a-knn-regression-model"><i class="fa fa-check"></i><b>8.6</b> Assessing a knn regression model</a></li>
<li class="chapter" data-level="8.7" data-path="regression1.html"><a href="regression1.html#how-do-different-ks-affect-k-nn-regression-predictions"><i class="fa fa-check"></i><b>8.7</b> How do different k’s affect k-nn regression predictions</a></li>
<li class="chapter" data-level="8.8" data-path="regression1.html"><a href="regression1.html#assessing-model-goodness-with-the-test-set"><i class="fa fa-check"></i><b>8.8</b> Assessing model goodness with the test set</a></li>
<li class="chapter" data-level="8.9" data-path="regression1.html"><a href="regression1.html#strengths-and-limitations-of-k-nn-regression"><i class="fa fa-check"></i><b>8.9</b> Strengths and limitations of k-nn regression</a><ul>
<li class="chapter" data-level="8.9.1" data-path="regression1.html"><a href="regression1.html#strengths-of-k-nn-regression"><i class="fa fa-check"></i><b>8.9.1</b> Strengths of k-nn regression</a></li>
<li class="chapter" data-level="8.9.2" data-path="regression1.html"><a href="regression1.html#limitations-of-k-nn-regression"><i class="fa fa-check"></i><b>8.9.2</b> Limitations of k-nn regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression2.html"><a href="regression2.html"><i class="fa fa-check"></i><b>9</b> Regression, continued</a><ul>
<li class="chapter" data-level="9.1" data-path="regression2.html"><a href="regression2.html#overview-7"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="regression2.html"><a href="regression2.html#learning-objectives-3"><i class="fa fa-check"></i><b>9.2</b> Learning objectives</a></li>
<li class="chapter" data-level="9.3" data-path="regression2.html"><a href="regression2.html#rmse-versus-rmpse"><i class="fa fa-check"></i><b>9.3</b> <span class="math inline">\(RMSE\)</span> versus <span class="math inline">\(RMPSE\)</span></a></li>
<li class="chapter" data-level="9.4" data-path="regression2.html"><a href="regression2.html#linear-regression"><i class="fa fa-check"></i><b>9.4</b> Linear regression</a></li>
<li class="chapter" data-level="9.5" data-path="regression2.html"><a href="regression2.html#linear-regression-in-r-using-caret"><i class="fa fa-check"></i><b>9.5</b> Linear regression in R using <code>caret</code></a></li>
<li class="chapter" data-level="9.6" data-path="regression2.html"><a href="regression2.html#comparing-linear-and-k-nn-regression"><i class="fa fa-check"></i><b>9.6</b> Comparing linear and k-nn regression</a></li>
<li class="chapter" data-level="9.7" data-path="regression2.html"><a href="regression2.html#additional-readingsresources-4"><i class="fa fa-check"></i><b>9.7</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression3.html"><a href="regression3.html"><i class="fa fa-check"></i><b>10</b> Regression, continued some more…</a><ul>
<li class="chapter" data-level="10.1" data-path="regression3.html"><a href="regression3.html#overview-8"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="regression3.html"><a href="regression3.html#learning-objectives-4"><i class="fa fa-check"></i><b>10.2</b> Learning objectives</a></li>
<li class="chapter" data-level="10.3" data-path="regression3.html"><a href="regression3.html#multivariate-k-nn-regression"><i class="fa fa-check"></i><b>10.3</b> Multivariate k-nn regression</a></li>
<li class="chapter" data-level="10.4" data-path="regression3.html"><a href="regression3.html#multivariate-linear-regression"><i class="fa fa-check"></i><b>10.4</b> Multivariate linear regression</a></li>
<li class="chapter" data-level="10.5" data-path="regression3.html"><a href="regression3.html#the-other-side-of-regression"><i class="fa fa-check"></i><b>10.5</b> The other side of regression</a></li>
<li class="chapter" data-level="10.6" data-path="regression3.html"><a href="regression3.html#additional-readingsresources-5"><i class="fa fa-check"></i><b>10.6</b> Additional readings/resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>11</b> Clustering</a><ul>
<li class="chapter" data-level="11.1" data-path="clustering.html"><a href="clustering.html#overview-9"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="clustering.html"><a href="clustering.html#learning-objectives-5"><i class="fa fa-check"></i><b>11.2</b> Learning objectives</a></li>
<li class="chapter" data-level="11.3" data-path="clustering.html"><a href="clustering.html#clustering-1"><i class="fa fa-check"></i><b>11.3</b> Clustering</a><ul>
<li class="chapter" data-level="11.3.1" data-path="clustering.html"><a href="clustering.html#a-toy-example"><i class="fa fa-check"></i><b>11.3.1</b> A toy example</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="clustering.html"><a href="clustering.html#k-means-clustering-algorithm"><i class="fa fa-check"></i><b>11.4</b> K-means clustering algorithm</a></li>
<li class="chapter" data-level="11.5" data-path="clustering.html"><a href="clustering.html#k-means-clustering-in-r"><i class="fa fa-check"></i><b>11.5</b> K-means clustering in R</a></li>
<li class="chapter" data-level="11.6" data-path="clustering.html"><a href="clustering.html#choosing-k-for-k-means-clustering"><i class="fa fa-check"></i><b>11.6</b> Choosing K for K-means clustering</a></li>
<li class="chapter" data-level="11.7" data-path="clustering.html"><a href="clustering.html#additional-readings"><i class="fa fa-check"></i><b>11.7</b> Additional readings:</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classification" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Classification</h1>
<div id="overview-4" class="section level2">
<h2><span class="header-section-number">6.1</span> Overview</h2>
<p>This chapter serves as an introduction to classification using K-nearest neighbours (k-nn) in the case where we have two quantitative variables that we want to use to predict the class of a third, categorical variable.</p>
</div>
<div id="learning-objectives" class="section level2">
<h2><span class="header-section-number">6.2</span> Learning objectives</h2>
<ul>
<li>Recognize situations where a simple classifier would be appropriate for making predictions.</li>
<li>Explain the k-nearest neighbour classification algorithm.</li>
<li>Interpret the output of a classifier.</li>
<li>Compute, by hand, the straight-line (Euclidean) distance between points on a graph when there are two explanatory variables/predictors.</li>
<li>Describe what a training data set is and how it is used in classification.</li>
<li>In a dataset with two explanatory variables/predictors, perform k-nearest neighbour classification in R using <code>caret::train(method = "knn", ...)</code> to predict the class of a single new observation.</li>
</ul>
</div>
<div id="classification-1" class="section level2">
<h2><span class="header-section-number">6.3</span> Classification</h2>
<p>In many situations, we want to learn how to make predictions based on our experience from past examples. For instance, a doctor wants to diagnose a patient as either diseased or healthy based on some observed characteristics, an email provider would like to assign a given email as “spam” or “non-spam”, or an online store wants to predict if an order is fraudulent (or not). These are all examples of classification tasks.</p>
<p><strong>Classification</strong> is the problem of predicting a qualitative or categorical class/label for an observation (set of data collected from an object, such as a person or an email). It involves assigning an observation to a class (e.g. disease or healthy) on the basis of how similar they are to other observations that have already been classified. These already classified observations that we use as a basis to predict classes for new, unclassfied observations is called a <strong>training set</strong>. We call them a “training set” because we use these observations to train, or teach, our classifier so that we can use it to make predictions on new data that we have not seen previously.</p>
<p>There are many possible classifier methods that we could use to predict a qualitative or categorical class/label for an observation. These classification methods can perform binary classification, where only two classes are involved (e.g. disease or healthy patient), as well as multiclass classification, which involves assigning an object to one of several classes (e.g., private, public, or not for-profit organization). Here we will focus on a simple, and widely used method of classification called <strong>K-nearest neighbors</strong>, but other examples include decision trees, support vector machines and logistic regression.</p>
</div>
<div id="wisconsin-breast-cancer-example" class="section level2">
<h2><span class="header-section-number">6.4</span> Wisconsin Breast Cancer Example:</h2>
<p>Let’s start by looking at some Breast Cancer <a href="http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29">data</a>, which was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg. Each row in the data set represents an observation which includes the tumour diagnosis (benign/non-cancerous or malignant/cancerous) and several other measurements about the tumour cells (e.g., cell nuclei texture, perimeter, etc.). Diagnosis of the tumour was determined by Physicians. The question here is whether we can use some, or all, of the measurements available to us about the tumour cells to do a good job of predicting whether a future tumour, that we don’t have a diagnosis from a Physician for, is benign or malignant.</p>
<p>Answering this question is important because traditional, non-data driven methods for tumour diagnosis are quite subjective and dependent upon how skilled and experienced the diagnosing Physician is. Furthermore, benign tumours are not normally dangerous, the cells stay in the same place and the tumour stops growing before it gets very large, whereas in malignant tumours, the cells invade the surrounding tissue and spread into nearby organs where they can cause serious damage (<a href="https://www.worldwidecancerresearch.org/who-we-are/cancer-basics/">Learn more here</a>). Thus it is important to quickly and accurately diagnose the tumour type to guide patient treatment protocols.</p>
<!--http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names-->
<div id="data-exploration" class="section level3">
<h3><span class="header-section-number">6.4.1</span> Data Exploration</h3>
<p>As usual, we start by loading the necessary libraries for our analysis. We have learned about the <code>tidyverse</code> before. Today we’ll also be loading a new library, <code>forcats</code> that allows us to easily manipulate factors in R. Factors are a special categorical type of variable in R that are very helpful when doing statistical inference and machine learning with categorical variables.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" title="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb91-2" title="2"><span class="kw">library</span>(forcats)</a></code></pre></div>
<p>The data file we need to read in is a plain vanilla csv with headers, and thus we can use the <code>read_csv</code> function with no additional arguments:</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" title="1">cancer &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/clean-wdbc.data.csv&quot;</span>)</a>
<a class="sourceLine" id="cb92-2" title="2"><span class="kw">head</span>(cancer)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 12
##       ID Class Radius Texture Perimeter   Area Smoothness Compactness
##    &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;
## 1 8.42e5 M      1.89  -1.36       2.30   2.00       1.31        2.61 
## 2 8.43e5 M      1.80  -0.369      1.53   1.89      -0.375      -0.430
## 3 8.43e7 M      1.51  -0.0240     1.35   1.46       0.527       1.08 
## 4 8.43e7 M     -0.281  0.134     -0.250 -0.550      3.39        3.89 
## 5 8.44e7 M      1.30  -1.47       1.34   1.22       0.220      -0.313
## 6 8.44e5 M     -0.165 -0.314     -0.115 -0.244      2.05        1.72 
## # ... with 4 more variables: Concavity &lt;dbl&gt;, Concave_points &lt;dbl&gt;,
## #   Symmetry &lt;dbl&gt;, Fractal_dimension &lt;dbl&gt;</code></pre>
<div id="variable-descriptions" class="section level4">
<h4><span class="header-section-number">6.4.1.1</span> Variable descriptions</h4>
<p>Breast tumours can be diagnosed by performing a biopsy, a process where tissue is removed from the body to discover the presence of a disease. Traditionally these procedures were quite invasive, but now fine needle asipiration is a type of biopsy that uses a thin needle to examine a small amount of tissue from the tumour. With this method, 10 different variables are typically measured of cell nuclei from a digital image of a fine needle aspirate (FNA) of a breast mass.</p>
<div class="figure">
<img src="https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/3721bb14b16e866115c906336e9d70db096c05b9/1-Figure1-1.png" title="A magnified image of a malignant breast Fine Needle Aspiration." alt="Source: https://www.semanticscholar.org/paper/Breast-Cancer-Diagnosis-and-Prognosis-Via-Linear-P-Mangasarian-Street/3721bb14b16e866115c906336e9d70db096c05b9/figure/0" />
<p class="caption">Source: <a href="https://www.semanticscholar.org/paper/Breast-Cancer-Diagnosis-and-Prognosis-Via-Linear-P-Mangasarian-Street/3721bb14b16e866115c906336e9d70db096c05b9/figure/0" class="uri">https://www.semanticscholar.org/paper/Breast-Cancer-Diagnosis-and-Prognosis-Via-Linear-P-Mangasarian-Street/3721bb14b16e866115c906336e9d70db096c05b9/figure/0</a></p>
</div>
<p>A magnified image of a malignant breast Fine Needle Aspiration image. White lines denote the boundary of the cell nuclei.</p>
<ol style="list-style-type: decimal">
<li>ID number</li>
<li>Class - diagnosis (M = malignant, B = benign)</li>
<li>radius (mean of distances from center to points on the perimeter)</li>
<li>texture (standard deviation of gray-scale values)</li>
<li>perimeter</li>
<li>area</li>
<li>smoothness (local variation in radius lengths)</li>
<li>compactness (<span class="math inline">\(perimeter^2 / area - 1.0\)</span>)</li>
<li>concavity (severity of concave portions of the contour)</li>
<li>concave points (number of concave portions of the contour)</li>
<li>symmetry</li>
<li>fractal dimension (<span class="math inline">\(&quot;coastline\: approximation&quot; - 1\)</span>)</li>
</ol>
<p>The “worst” (mean of the three largest values) values of these variable were computed for each image. As part of the data preparation, the data have been scaled (we will discuss what this means and why we do it in the next chapter).</p>
<p>Below we use <code>glimpse</code> to preview the data frame. This function is similar to head, but can be easier to read when we have a lot of columns:</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" title="1"><span class="kw">glimpse</span>(cancer)</a></code></pre></div>
<pre><code>## Observations: 569
## Variables: 12
## $ ID                &lt;dbl&gt; 842302, 842517, 84300903, 84348301, 84358402...
## $ Class             &lt;chr&gt; &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;,...
## $ Radius            &lt;dbl&gt; 1.8850310, 1.8043398, 1.5105411, -0.2812170,...
## $ Texture           &lt;dbl&gt; -1.35809849, -0.36887865, -0.02395331, 0.133...
## $ Perimeter         &lt;dbl&gt; 2.30157548, 1.53377643, 1.34629062, -0.24971...
## $ Area              &lt;dbl&gt; 1.999478159, 1.888827020, 1.455004298, -0.54...
## $ Smoothness        &lt;dbl&gt; 1.306536657, -0.375281748, 0.526943750, 3.39...
## $ Compactness       &lt;dbl&gt; 2.61436466, -0.43006581, 1.08198014, 3.88997...
## $ Concavity         &lt;dbl&gt; 2.10767182, -0.14661996, 0.85422232, 1.98783...
## $ Concave_points    &lt;dbl&gt; 2.29405760, 1.08612862, 1.95328166, 2.173873...
## $ Symmetry          &lt;dbl&gt; 2.7482041, -0.2436753, 1.1512420, 6.0407261,...
## $ Fractal_dimension &lt;dbl&gt; 1.93531174, 0.28094279, 0.20121416, 4.930671...</code></pre>
<p>We can see from the summary of the data above that <code>Class</code> is of type character. We are going to be working with <code>Class</code> as a categorical statistical variable so we will convert it to factor using the function <code>as.factor</code>.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" title="1">cancer &lt;-<span class="st"> </span>cancer <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb96-2" title="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Class =</span> <span class="kw">as.factor</span>(Class)) </a></code></pre></div>
<p>Factors have what are called “levels”, which you can think of as categories. We can ask for the levels from the <code>Class</code> column by using the <code>levels</code> function. This function should return the name of each category in that column. Given that we only have 2 different values in our <code>Class</code> column, “B” and “M”, we only expect to get two names back. If we had 4 difference values in the column, we would expect to get 4 back. <em>Note the use of <code>unlist</code> to between <code>select</code> and <code>levels</code>. This is because <code>select</code> outputs a data frame (even though we only select a single column), and levels expects a vector.</em></p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" title="1">cancer <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb97-2" title="2"><span class="st">  </span><span class="kw">select</span>(Class) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb97-3" title="3"><span class="st">  </span><span class="kw">unlist</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="co"># turns a data frame into a vector</span></a>
<a class="sourceLine" id="cb97-4" title="4"><span class="st">  </span><span class="kw">levels</span>()</a></code></pre></div>
<pre><code>## [1] &quot;B&quot; &quot;M&quot;</code></pre>
<p>Before we start doing any modelling, Let’s explore out dataset. Below we use the <code>tidyverse</code>’s <code>group_by</code> + <code>summarize</code> function to see that we have 357 (63%) benign and 212 (37%) malignant tumour observations.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb99-1" title="1">num_obs &lt;-<span class="st"> </span><span class="kw">nrow</span>(cancer)</a>
<a class="sourceLine" id="cb99-2" title="2">cancer <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb99-3" title="3"><span class="st">  </span><span class="kw">group_by</span>(Class) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb99-4" title="4"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">n =</span> <span class="kw">n</span>(),</a>
<a class="sourceLine" id="cb99-5" title="5">            <span class="dt">percentage =</span> <span class="kw">n</span>() <span class="op">/</span><span class="st"> </span>num_obs <span class="op">*</span><span class="st"> </span><span class="dv">100</span>)</a></code></pre></div>
<pre><code>## # A tibble: 2 x 3
##   Class     n percentage
##   &lt;fct&gt; &lt;int&gt;      &lt;dbl&gt;
## 1 B       357       62.7
## 2 M       212       37.3</code></pre>
<p>Next, let’s draw a scatter plot to visualize the relationship between the perimeter and concavity variables. To avoid <code>ggplot's</code> default pallete, we define our own here and specify to use it in the <code>scale_color_manual</code> function. In that function we also make the category labels of “B” and “M” something more readable, “Benign” and “Malignant”, respectively.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb101-1" title="1"><span class="co"># colour palette</span></a>
<a class="sourceLine" id="cb101-2" title="2">cbPalette &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;#56B4E9&quot;</span>, <span class="st">&quot;#E69F00&quot;</span>,<span class="st">&quot;#009E73&quot;</span>, <span class="st">&quot;#F0E442&quot;</span>, <span class="st">&quot;#0072B2&quot;</span>, <span class="st">&quot;#D55E00&quot;</span>, <span class="st">&quot;#CC79A7&quot;</span>, <span class="st">&quot;#999999&quot;</span>) </a>
<a class="sourceLine" id="cb101-3" title="3"></a>
<a class="sourceLine" id="cb101-4" title="4">perim_concav &lt;-<span class="st"> </span>cancer <span class="op">%&gt;%</span><span class="st">  </span></a>
<a class="sourceLine" id="cb101-5" title="5"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Perimeter, <span class="dt">y =</span> Concavity, <span class="dt">color =</span> Class)) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb101-6" title="6"><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha =</span> <span class="fl">0.5</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb101-7" title="7"><span class="st">    </span><span class="kw">labs</span>(<span class="dt">color =</span> <span class="st">&quot;Diagnosis&quot;</span>) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb101-8" title="8"><span class="st">    </span><span class="kw">scale_color_manual</span>(<span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Benign&quot;</span>, <span class="st">&quot;Malignant&quot;</span>), <span class="dt">values =</span> cbPalette)</a>
<a class="sourceLine" id="cb101-9" title="9">perim_concav</a></code></pre></div>
<p><img src="_main_files/figure-html/05-scatter-1.png" width="480" /></p>
<p>In this visualization, we can see that the observations that are labelled as benign, typically fall in the the lower, left-hand side of the plot area. Whereas, the observations that are labelled as malignant typically fall in upper right-hand side of the plot. Suppose we have a new observation that is not in the current data set that we plotted and we do not have a Physician’s diagnosis for the tumour class. But what is we knew this new observation had a perimeter value of 1 and concavity value of 1. Could we use this information to classify that observation as benign or malignant? What about a new observation with perimeter value of -1 and concavity value of -0.5? What about 0 and 1? It seems like we can do this, at least visually. Now we will explore how we can use the K-Nearest Neighbour classification method to do this using R.</p>
</div>
</div>
<div id="k-nearest-neighbour-classifier" class="section level3">
<h3><span class="header-section-number">6.4.2</span> K-Nearest Neighbour Classifier</h3>
<p>To classify a new observation as benign or malignant, we find some observations in the training set that are “nearest” to our new observation, and then use their diagnoses (benign or malignant) to make a prediction for the new observation’s diagnosis.</p>
<p>Let’s walk through an example; suppose we have a new observation, with perimeter of 2 and concavity of 4 (labelled in red on the scatterplot), whose diagnosis “Class” is unknown.</p>
<p><img src="_main_files/figure-html/05-knn-1-1.png" width="480" /></p>
<p>We see that the nearest point to this new observation is located at the coordinates (2.3, 3.2). The idea here is that if a point is close to one another in the scatterplot then the perimeter and concavity values are similar so we may expect that they would have the same diagnosis.</p>
<p><img src="_main_files/figure-html/05-knn-2-1.png" width="480" /></p>
<p>Suppose we have another new observation with perimeter 0.38 and concavity of 1.8. Looking at the scatterplot below, how would you classify this red observation? The nearest neighbour to this new point is a <strong>benign</strong> observation at (0.2, 1.8). Does this seem like the right prediction to make? Probably not if you consider the other nearby points…</p>
<p><img src="_main_files/figure-html/05-knn-4-1.png" width="480" /></p>
<p>So instead of just using the one nearest neighbour, we can consider several neighbouring points, say <span class="math inline">\(k = 3\)</span>, that are closest to the new red observation to predict its diagnosis class. Among those 3 closest points, we look at their class and use the majority class as our prediction for the new observation.</p>
<p>We see that the diagnoses of 2 of the 3 nearest neighbours to our new observation are malignant so we take majority vote and classify our new red observation as malignant. <!-- For our red observation at (0.38, 1.8), the nearest points are: (0.2, 1.8), (0.5, 1.7), and (0.4, 2). --></p>
<p><img src="_main_files/figure-html/05-knn-5-1.png" width="480" /></p>
<p>Here we chose the <span class="math inline">\(k=3\)</span> nearest observations, but there is nothing special about <span class="math inline">\(k=3\)</span>. We could have used <span class="math inline">\(k=4, 5\)</span> or more, though we may want to choose an odd number to avoid ties. We will discuss more about choosing <span class="math inline">\(k\)</span> in the next section.</p>
<div id="distance-between-points-when-there-are-two-explanatory-variablespredictors" class="section level4">
<h4><span class="header-section-number">6.4.2.1</span> Distance Between Points When There are two explanatory variables/predictors</h4>
<p>How do we decide which points are “nearest” to our new observation? We can compute the distance between any pair of points using the following formula:</p>
<p><span class="math display">\[Distance = \sqrt{(x_a -x_b)^2 + (y_a - y_b)^2}\]</span></p>
<p>Suppose we want to classify a new observation with perimeter of -1 and concavity of 4.2. Let’s calculate the distances between our new point and each of the observations in the training set to find the <span class="math inline">\(k=5\)</span> observations in the training data that are nearest to our new point.</p>
<p><img src="_main_files/figure-html/05-multiknn-1-1.png" width="480" /></p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb102-1" title="1">new_obs_Perimeter &lt;-<span class="st"> </span><span class="dv">-1</span></a>
<a class="sourceLine" id="cb102-2" title="2">new_obs_Concavity &lt;-<span class="st"> </span><span class="fl">4.2</span></a>
<a class="sourceLine" id="cb102-3" title="3">cancer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(ID, Perimeter, Concavity, Class) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb102-4" title="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">dist_from_new =</span> <span class="kw">sqrt</span>((Perimeter <span class="op">-</span><span class="st"> </span>new_obs_Perimeter)<span class="op">^</span><span class="dv">2</span>  <span class="op">+</span><span class="st"> </span>(Concavity <span class="op">-</span><span class="st"> </span>new_obs_Concavity)<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb102-5" title="5"><span class="st">  </span><span class="kw">arrange</span>(dist_from_new) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb102-6" title="6"><span class="st">  </span><span class="kw">head</span>(<span class="dt">n =</span> <span class="dv">5</span>)</a></code></pre></div>
<pre><code>## # A tibble: 5 x 5
##         ID Perimeter Concavity Class dist_from_new
##      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;         &lt;dbl&gt;
## 1   859471    -1.24       4.70 B             0.553
## 2 84501001    -0.286      3.99 M             0.744
## 3  8710441    -1.08       2.63 B             1.57 
## 4  9013838    -0.461      2.72 M             1.57 
## 5   925622     0.638      4.30 M             1.64</code></pre>
<p>From this, we see that 3 of the 5 nearest neighbours to our new observation are malignant so classify our new observation as malignant. We circle those 5 in the plot below:</p>
<p><img src="_main_files/figure-html/05-multiknn-3-1.png" width="672" /></p>
<p>It can be difficult sometimes to read code as math, so here we mathematically show the calculation of distance for each of the 5 closest points.</p>
<table>
<thead>
<tr class="header">
<th>ID</th>
<th>Perimeter</th>
<th>Concavity</th>
<th>Distance</th>
<th>Class</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>8.5947110^{5}</td>
<td>-1.24</td>
<td>4.7</td>
<td><span class="math inline">\(\sqrt{-1 - (-1.24))^2 + (4.2 - 4.7)^2}=\)</span> 0.55</td>
<td>B</td>
</tr>
<tr class="even">
<td>8.450100110^{7}</td>
<td>-0.29</td>
<td>3.99</td>
<td><span class="math inline">\(\sqrt{(-1 - (-0.29))^2 + (4.2 - 3.99)^2} =\)</span> 0.74</td>
<td>M</td>
</tr>
<tr class="odd">
<td>8.71044110^{6}</td>
<td>-1.08</td>
<td>2.63</td>
<td><span class="math inline">\(\sqrt{(-1 - (-1.08))^2 + (4.2 - 2.63)^2} =\)</span> 1.57</td>
<td>B</td>
</tr>
<tr class="even">
<td>9.01383810^{6}</td>
<td>-0.46</td>
<td>2.72</td>
<td><span class="math inline">\(\sqrt{(-1 - (-0.46))^2 + (4.2 - 2.72)^2} =\)</span> 1.57</td>
<td>M</td>
</tr>
<tr class="odd">
<td>9.2562210^{5}</td>
<td>0.64</td>
<td>4.3</td>
<td><span class="math inline">\(\sqrt{(-1 - 0.64)^2 + (4.2 - 4.3)^2} =\)</span> 1.64</td>
<td>M</td>
</tr>
</tbody>
</table>
<hr />
<div id="summary" class="section level5">
<h5><span class="header-section-number">6.4.2.1.1</span> Summary:</h5>
<p>In order to classify a new observation using a k-nearest neighbor classifier, we have to do the follow steps:</p>
<ul>
<li><strong>Step 1</strong>: Compute the distance between the new observation and each observation in our training set.</li>
<li><strong>Step 2</strong>: Sort the data table in ascending order according to the distances.</li>
<li><strong>Step 3</strong>: Choose the top <span class="math inline">\(k\)</span> rows of the sorted table.</li>
<li><strong>Step 4</strong>: Classify the new observation based on majority vote.</li>
</ul>
</div>
</div>
</div>
<div id="k-nearest-neighbours-in-r" class="section level3">
<h3><span class="header-section-number">6.4.3</span> K-Nearest Neighbours in R</h3>
<p>We will use the k-nearest neighbour (k-nn) algorithm in R by making use of the <code>caret</code> (Classification And REgression Training) package. <code>caret</code> contains a set of tools to help the process of making predictive models. Why do we now switch the using <code>caret</code> to perform k-nn as opposed to just writing the code to do it ourselves as we did above? Well, first, our code would have to get a bit more complicated to predict the classes for multiple new observations. Second, our code would also have to get a bit more complicated as we add more variables to our model. Thus for those two reasons, it makes sense to use the <code>caret</code> package to keep our code simple, readable and accurate (the less we type, the less mistakes we are likely to make).</p>
<p>We start off by loading the <code>caret</code> library:</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb104-1" title="1"><span class="kw">library</span>(caret)</a></code></pre></div>
<pre><code>## Loading required package: lattice</code></pre>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
<p>Let’s again suppose we have a new observation with perimeter -1 and concavity 4.2, but its diagnosis is unknown (as in our example above). Suppose we again want to use the perimeter and concavity explanatory variables/predictors to predict the diagnosis class of this observation. Let’s pick out our 2 desired variables and store it as a new dataset named <code>cancer_train</code></p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb108-1" title="1">cancer_train &lt;-<span class="st"> </span>cancer <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb108-2" title="2"><span class="st">  </span><span class="kw">select</span>(<span class="st">&quot;Perimeter&quot;</span>, <span class="st">&quot;Concavity&quot;</span>)</a>
<a class="sourceLine" id="cb108-3" title="3"><span class="kw">head</span>(cancer_train)</a></code></pre></div>
<pre><code>## # A tibble: 6 x 2
##   Perimeter Concavity
##       &lt;dbl&gt;     &lt;dbl&gt;
## 1     2.30      2.11 
## 2     1.53     -0.147
## 3     1.35      0.854
## 4    -0.250     1.99 
## 5     1.34      0.613
## 6    -0.115     1.26</code></pre>
<p>Next, we store the diagnosis class labels (column <code>Class</code>) as a vector.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb110-1" title="1">cancer_labels &lt;-<span class="st"> </span>cancer <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb110-2" title="2"><span class="st">  </span><span class="kw">select</span>(Class) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb110-3" title="3"><span class="st">  </span><span class="kw">unlist</span>()</a>
<a class="sourceLine" id="cb110-4" title="4"><span class="kw">head</span>(cancer_labels)</a></code></pre></div>
<pre><code>## Class1 Class2 Class3 Class4 Class5 Class6 
##      M      M      M      M      M      M 
## Levels: B M</code></pre>
<p>We will use the function <code>train()</code>, where the argument <code>x</code> is a data frame object containing the explanatory variables/predictors, and <code>y</code> is a numeric or factor vector containing the outcomes/labels/classes. <code>x</code> and <code>y</code> should come from your original data frame and be in the same order. The argument <code>tuneGrid</code> should be a dataframe with possible “tuning values”. For now, just know that this is where we will specify our <span class="math inline">\(k\)</span> (the number of nearest neighbours) and we will use <span class="math inline">\(k =5\)</span> (we will discuss how to choose <span class="math inline">\(k\)</span> in a later section). We will use “knn” as our <code>method</code>. <em>Note - the <code>caret</code> package expects <code>data.frames</code> and not <code>tibbles</code> (which are special kind data frames). This is a bit annoying, and I expect this to change in the future, but for now we have to change <code>tibbles</code> to <code>data.frames</code> when using <code>caret</code>.</em></p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb112-1" title="1">k &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">k =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb112-2" title="2">model_knn &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> <span class="kw">data.frame</span>(cancer_train), <span class="dt">y =</span> cancer_labels, <span class="dt">method=</span><span class="st">&#39;knn&#39;</span>, <span class="dt">tuneGrid =</span> k)</a></code></pre></div>
<p>Now we can create a <code>data.frame</code> with our new observation and predict the label of the new observation using the <code>predict</code> function:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb113-1" title="1">new_obs &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Perimeter =</span> <span class="dv">-1</span>, <span class="dt">Concavity =</span> <span class="fl">4.2</span>)</a>
<a class="sourceLine" id="cb113-2" title="2"><span class="kw">predict</span>(<span class="dt">object =</span> model_knn, new_obs)</a></code></pre></div>
<pre><code>## [1] M
## Levels: B M</code></pre>
<p>Our model classifies this new observation as malignant. How do we know how well our model did? In later sections, we will discuss ways to evaluate our model.</p>
</div>
<div id="more-than-two-explanatory-variablespredictors" class="section level3">
<h3><span class="header-section-number">6.4.4</span> More than two explanatory variables/predictors</h3>
<p>So far we have seen how to build a classifier based on only explanatory variables/predictors, but we can use the k-nearest neighbours classifier in higher dimensional space. Let’s make a scatterplot with 3 variables instead of 2:</p>
<pre><code>## 
## Attaching package: &#39;plotly&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     last_plot</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     layout</code></pre>
<div id="htmlwidget-eecb38147af03ce15239" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-eecb38147af03ce15239">{"x":{"visdat":{"410465a72970":["function () ","plotlyVisDat"]},"cur_data":"410465a72970","attrs":{"410465a72970":{"x":{},"y":{},"z":{},"opacity":0.4,"color":{},"size":150,"colors":["#E69F00","#56B4E9"],"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Perimeter"},"yaxis":{"title":"Concavity"},"zaxis":{"title":"Symmetry"}},"hovermode":"closest","showlegend":true},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[-0.22501906532072,-0.332451412882306,-1.25381027174843,-0.678556178018386,-1.4880187413633,-0.517258858410686,-0.245850822465626,-0.722600464553329,-0.332749009412948,-0.702066303939065,-0.757419258638386,-0.506545383307591,-1.40945325727394,-1.11304711275499,-1.34517240665537,-1.24012083133892,-1.19726693092654,-0.870803536812803,-1.24279920011469,-0.642546997810762,-1.3302925801233,-0.522317999431592,-0.473214571875742,-0.457739552282383,-0.676473002303895,-0.31548841063574,-0.579754129845403,-0.470238606569327,0.0636495694015471,-0.129788175515436,-0.0821727306127943,-0.287811933286079,-0.747598573127216,-1.14429474847235,-0.723195657614613,-1.69187236485274,-0.674985019650687,-1.0428143315236,-0.983295025395294,-0.647308542301027,-0.645820559647819,-0.692543214958537,-1.05888454417824,-0.543447353107139,-0.00777359795241612,-1.03091047029794,-1.27315404624013,-0.586896446580799,-1.30708005073326,-0.699983128224575,-0.132764140821852,-0.454465990445327,-0.20716327348223,-0.0405092163229823,-0.472619378814459,0.209471869415888,-0.627964767809328,-0.813367406398991,-0.914550226817105,-1.21214675745862,-0.732123553533858,-0.300310987573023,-0.877053063956274,-0.624988802502913,-0.00479763264600116,0.0398418469502257,-0.29971579451174,-0.489284784530384,-1.4636158258507,-1.0779307221393,-0.922882929675067,-0.285431161040947,-0.614870520461102,0.388029787800796,-0.689864846182763,-0.868720361098312,-0.546125721882913,-0.592253184132347,-0.147643967353927,-0.999960431111219,-0.0791967653063793,-0.603859448827366,-1.04906385866707,-1.01364987152073,-1.45528312299273,-1.01751862641907,-0.567850268619743,-0.611894555154687,-0.837472725380953,-0.948476231310237,-0.679746564140951,-0.824080881502085,-0.613382537807894,-0.542256966984573,-1.33951807257319,-0.489582381061025,-0.449704445955062,-0.333641799004873,-1.19577894827333,-0.231566188994833,0.191616077577397,-0.655938841689631,-0.626774381686762,-0.948178634779596,-0.224721468790079,-0.183355551030909,-1.05114703438156,-0.25061236695589,0.0934092224656983,-1.00561476519341,0.206495904109473,-0.493748732490006,-0.816640968236048,-0.857709289464576,-1.2356568833793,-0.267575369202457,-0.141692036741097,-0.391375525949326,-0.696709566387518,-0.598205114745177,-0.275610475529777,-0.999365238049936,-0.564874303313328,-0.0672929040807186,-0.871398729874086,-0.785095735988047,-0.718434113124348,-0.86247083395484,-0.285728757571589,-0.535412246779818,-0.915145419878388,-0.381554840438156,-0.862768430485482,-1.16572169867854,-0.827354443339142,-0.889552118243218,-0.2485291912414,-0.264599403896041,-0.671413861282989,-0.450597235546987,-0.645820559647819,-0.448216463301855,-0.591062798009781,-0.862768430485482,-0.832413584360047,-0.165499759192418,0.0547216734823014,-0.549101687189328,-0.681829739855442,-0.557136793516648,-0.389589946765477,-1.03686240091077,-0.0434851816293977,-1.1059047960196,-0.569338251272951,-1.08626342499726,-0.731230763941933,-0.76991831292533,-0.454168393914685,-1.37969360420979,-0.350604801251439,-0.395839473908949,-0.783905349865481,-0.105980453064115,-0.452978007792119,-0.774679857415594,-1.50617212973243,-0.677960984957102,-0.763668785781858,-1.14994908255454,-0.758907241291594,-1.06334849213786,-0.430360671463364,-0.48065448514178,-0.552375249026384,-0.263706614304117,-0.729742781288726,-0.239601295322155,-0.903241558652728,-0.749384152311066,-0.676473002303895,-0.591657991071064,-1.04995664825899,0.12316887552985,-1.07168119499582,-0.818426547419896,-0.687484073937631,-1.08239467009892,-0.616656099644951,0.206495904109473,-0.82110491619567,-0.719326902716273,-0.703851883122914,-0.822592898848877,-0.542852160045856,-0.388101964112269,-0.313107638390608,-1.24964392031945,-0.936572370084577,-0.608323396786989,-0.426194320034383,-0.578563743722837,0.295774863301927,-0.401791404521779,-0.399113035746005,-0.0821727306127943,-0.241089277975362,0.173760285738906,-0.915145419878388,-0.302096566756872,-0.276800861652344,-0.664569141078234,-0.819319337011821,-0.592253184132347,-0.358044714517476,-0.317571586350231,-0.583622884743743,-0.226209451443286,-0.819319337011821,-1.0127570819288,-1.28714108318028,-0.56338632066012,-0.322630727371136,-0.295549443082759,-0.492260749836799,-0.78777410476382,-0.632726312299593,-0.583920481274384,-0.325904289208193,-0.522913192492874,-0.688972056590838,-0.729147588227443,0.25708731431853,-0.465179465548421,-0.543447353107139,-0.660402789649253,-0.813367406398991,-1.20976598521349,0.087457291852868,-0.65980759658797,-1.14667552071748,-0.569635847803592,-0.833306373951972,-0.619929661482007,0.203519938803058,-0.753848100270688,-0.174427655111663,-1.05561098234118,-1.11126153357114,-0.769323119864047,-0.701471110877782,-0.979426270496955,-0.547316108005478,-0.525293964738006,-0.147643967353927,-0.36072308329325,-0.180379585724493,-0.189307481643739,-0.31935716553408,-0.509521348614006,-0.278586440836192,-1.12822453581771,-0.677960984957102,-0.0405092163229823,0.0249620204181501,-0.706827848429329,-0.660402789649253,-0.123836244902606,-0.465477062079062,-0.314595621043816,-0.631535926177026,-0.475297747590232,-0.482142467794987,-1.16750727786239,-0.204187308175814,-0.731528360472575,-0.361913469415816,0.230303626560794,-0.189307481643739,-1.0758475464248,-0.569040654742309,-1.08269226662956,-0.595824342500045,0.14102466736834,-0.660105193118612,-0.788071701294462,-0.417861617176421,0.144000632674755,-0.180379585724493,-0.750574538433631,-0.548506494128045,-0.0851486959192092,-0.36667501390608,-0.341676905332193,0.155904493900416,-0.280967213081325,-0.0375332510165674,-0.615763310053027,-0.432146250647213,0.590395428637024,-0.71486295475665,-0.356259135333627,-0.100028522451285,-0.356259135333627,-0.429765478402081,0.0725774653207924,-0.612787344746611,-1.13715243173696,-1.12465337745001,-0.658617210465404,-0.927942070695973,0.0755534306272073,-0.774084664354311,-0.165499759192418,0.0368658816438108,-0.836579935789029,-0.236625330015739,-0.405660159420119,-1.17316161194458,-0.919014174776728,-0.233054171648041,-0.980319060088879,-1.30827043685583,-0.159547828579587,-0.596419535561328,-0.379174068193024,-0.605347431480573,-0.557731986577932,-0.602966659235441,-0.168475724498833,-0.91752619212352,-0.629155153931894,-1.49069711013907,-1.570452980351,-0.847591007422765,0.185664146964567,0.00413026327324455,-0.439883760443892,-0.24079168144472,-0.288109529816721,-1.07554994989416,-1.07674033601673,-1.13566444908375,-0.69522158373431,-0.987461376824276,-0.876755467425633,-0.570231040864875,-1.32136468420405,-0.548208897597403,-1.1216774121436,-1.17197122582201,-1.21303954705054,-0.0405092163229823,-0.743432221698235,-0.210139238788645,-0.954428161923068,-1.43147540054141],"y":[-0.159082553609287,-0.398747849778323,-0.879660233071109,-1.07302219402029,-0.974903221768684,0.15727563733384,-0.210850257581799,-1.03994838314896,-0.801385547342302,-0.86355472516855,-0.869642223691244,-1.29583901986864,-0.74482453744641,-1.20076379687838,-0.873237203133779,-0.635057831800992,-0.853536715788685,-0.612529293961102,4.69653634677537,-0.806658183858021,-0.617322599884483,-0.488382670545542,-0.895382276499798,-0.474961413960076,-0.463457479743962,1.02390534828107,-0.21804021646687,-0.137992007546412,-0.0565058068489398,-0.864225787997823,-0.657586369640881,-0.642727121278401,-1.06597603431292,-1.20646783092721,-0.383409270823504,-1.30468266929728,-0.755849141070186,-0.0373325831554169,-0.92184132519686,0.0724341224900012,-0.376219311938433,0.190828778797505,-0.681552899257785,-0.242486076676112,1.94661673853186,-0.683949552219475,-0.127446734514974,-0.584248789013156,-0.564596234727295,-0.297129764202652,-0.077596352911815,0.280942930157062,-0.915705893614932,-0.365194708314658,-0.829426386994079,-0.485506686991514,-0.803302869711655,-0.634099170616315,-0.889150978799403,-1.30468266929728,-0.935214648723092,-0.302881731310708,-0.837095676471489,-0.853153251314814,-0.106356188452099,0.182680158727758,-0.555009622880534,-0.915849692792634,1.27459524807388,2.63349747735232,-0.963591019789506,0.137623083047979,-0.373343328384405,-0.402582494517027,-0.890732769754119,-1.2158147774778,-0.36711203068401,-0.495572629430613,-0.933201460235272,-0.802823539119316,-0.986023691510927,-0.709354073613393,-1.11592228203454,-1.30468266929728,-1.30468266929728,0.366263775593239,-1.26644646794647,-1.17248329193044,-0.514745853124136,-1.27151299230748,-0.575620838351071,-0.882727948862073,-0.622595236400202,-1.05610182411075,-1.30468266929728,-0.45914350441292,-0.644644443647753,-0.0243906571622891,-1.00687457227763,0.210960663675704,0.11509454520809,-0.599587367967974,0.0403189728033505,-0.38197127904649,-0.46154015737461,-0.0694477328420679,-0.989666604012697,-0.448598231381482,-0.522415142601545,-1.17818732597926,0.326000005836841,0.569979277336919,-0.782691654241118,-1.19357383799331,-0.961434032123984,-1.00601177721142,0.163986265626573,-0.569868871243014,-1.00543658050062,2.25961961532862,-0.653272394309838,-0.738593239746015,-0.20318096810439,2.399104817699,-0.765435752916947,-0.439970280719397,-0.91618522420727,-0.386285254377533,-0.60821531863006,-0.349856129359839,-0.0900589483126048,-1.11937346229938,-0.693536164066236,-1.11088931081499,-0.961817496597855,-1.28093183844693,-0.796592241418922,-0.606777326853045,-0.981853515357586,0.298198831481233,-1.27794081555074,-0.171065818417739,-0.736196586784325,-0.563637573542619,-0.943794666325943,-0.240568754306759,-0.439970280719397,-0.23050281186766,-0.673883609780375,-1.05384897032676,-1.12579649223671,-1.16644372646698,-0.554530292288196,-1.10537700900311,-0.39203722148559,-0.90094251137092,-0.717023363090802,-0.957695253503747,-1.25099764295541,-1.23412520610511,-1.23858298061386,-1.21725276925481,-0.925292505461694,-1.07719237017363,-0.456746851451229,-0.905687884235067,-1.30468266929728,-1.21178840050216,-1.10739019749093,0.904552030788892,-1.19745641579125,-0.394913205039618,-0.446201578419792,-0.745303868038748,-0.815765465112445,-1.05030192394346,-1.2676208278977,0.343735237753349,-1.24069203522014,-1.27823320721206,-1.13121292793013,-0.609653310407074,-0.798988894380612,0.49520370493218,0.776091432042289,-0.202701637512052,-0.783650315425794,-0.96138609906475,-1.08869630438974,-0.273642565178086,-0.83383622844359,-1.15503565836933,-1.1586785708711,-0.729006627899254,-0.160041214793963,-0.0713650552114202,-1.05135645124661,-0.852146657070904,-0.756328471662524,-1.28751784078565,-0.723733991383535,-0.703122775912998,-0.507555894239065,-0.650875741348148,-0.148057949985512,-0.651834402532824,-0.659503692010233,-0.291377797094595,1.58568080250129,-0.924381777336251,-0.0732823775807723,-0.227626828313631,-0.560282259396253,0.0911280155911861,0.232051209738579,0.0690788083436348,0.16973823273463,-0.781732993056441,0.143375050156036,-0.891739363998029,-1.30468266929728,-0.536315729779349,-0.899168988179269,0.343255907161011,-0.393475213262604,-0.308154367826427,-0.610132640999412,-0.578976152497437,-0.535836399187011,-0.437094297165368,-1.06880408480771,-0.627867872915921,-0.197429000996333,-0.423673040579902,-0.644644443647753,-0.43661496657303,-0.793236927272555,-0.40929312280976,0.187952795243476,-0.746741859815762,-1.01032575254247,-0.854830908387997,-1.13298645112178,-0.077596352911815,0.238282507438974,-0.201263645735037,0.449667298660063,-1.20474224079479,-1.24548534114352,0.104069941584314,-0.381012617861814,-1.08514925800644,-1.1384028868152,-0.152851255908892,-0.71989934664483,-0.963063756137934,-0.769270397655652,-1.07685683875899,-1.00462171849364,0.986038231486365,-1.13610209997198,-1.11362149519132,-0.533439746225321,-0.317261649080851,0.506707639148294,0.237803176846636,-0.43661496657303,-0.646561766017105,-0.400185841555337,-0.969007455482926,0.0964006521069048,-0.638413145947358,-1.09080535899603,-0.960043973406204,-0.599108037375636,-0.413127767548465,-0.405458478071056,1.83780869407112,0.854222318593395,-0.997479692667807,0.222464597891817,-0.69257750288156,-1.03990045008973,0.205688027159985,-1.30468266929728,0.308264773920332,0.361470469669858,-0.100604221344043,-0.641289129501387,-0.0603404515876445,-0.528167109709602,-0.502762588315684,-0.418879734656522,-0.469688777444357,0.61455702242436,1.04211991078992,-0.136554015769398,-0.590480086713551,-0.71510604072145,-0.802344208526978,-1.22444272813988,-0.93569397931543,-0.489820662322556,0.412279512457694,-0.332600228035669,-0.415045089917817,-0.399227180370661,-0.298567755979666,0.0916073461835241,0.389750974617804,-0.70264344532066,-0.371426006015053,-0.0152833759078657,-0.776939687133061,-0.110190833190804,-0.52624978734025,-0.70743675124404,-0.622595236400202,-0.825543809196141,-1.18326823025804,-0.377177973123109,-0.900415247719348,-0.4639368103363,-0.0325392772320362,-0.446201578419792,-0.557406275842224,-0.527208448524926,-0.649917080163472,0.017311104371123,-0.726609974937563,-0.287063821763552,-0.636016492985668,-1.30468266929728,0.321686030505798,-0.443325594865763,0.63181292374853,-0.532481085040645,-0.795633580234245,-0.644644443647753,-0.80186487793464,-1.09454413761627,-0.450036223158496,-0.85650856546118,-1.00778530040308,-1.30468266929728,-0.555009622880534,-0.889917907747144,-0.921553726841457,-0.135595354584722,-0.346021484621135,-1.2565099447673,-1.30468266929728,0.450625959844739,0.435287380889921,-0.669090303856995,-1.30468266929728,-1.30468266929728],"z":[0.123238094688002,0.457824280674147,-0.728582774948222,-1.47695670785443,0.330131968148034,-0.248524334185492,-0.0480958942710862,-0.756060867517132,-0.896684047134497,-0.187102715502045,0.65502000381574,-0.746362717198693,0.516013182584781,1.06072595880377,0.11515630275597,0.616227402541983,-0.036781385566241,-0.809400694268546,2.14530243608253,-0.836878786837457,-1.04538901868389,-0.45703456603193,-0.308329594482532,-0.196800865820485,-0.224278958389395,1.01223520721158,0.773014166023413,0.11515630275597,0.404484453922732,-0.612204971126954,-1.41230237239817,-0.360053062847541,-1.08903069511687,-1.56262370233397,-0.20811537452533,0.05050196729971,-0.334191328665037,-0.450569132486304,-0.120832021659379,-0.153159189387509,0.132936245006441,-0.11598294650016,-0.594425028876482,-1.09064705350328,-0.812633411041359,-0.836878786837457,0.0408038169812712,-0.7479790755851,-2.01843676730061,0.186276071757855,-0.0190014433157698,-1.37835884628363,-0.86758959617918,-0.502292600851312,0.918486420799998,-0.287316935459248,-1.92145526411622,-0.363285779620353,-1.29107549341768,0.330131968148034,-0.511990751169751,1.04779509171252,-0.971036532909196,-0.280851501913622,-0.0788067036128098,-0.339040403824256,-0.890218613588871,0.477220581311025,0.680881737998243,0.334981043307253,-0.0674921949079647,1.53270260763447,0.343062835239286,-0.604123179194922,-0.625135838218206,-0.263071559663151,0.431962546491643,-1.0227600012742,-0.411776531212548,-1.31047179405456,-0.80293526072292,-0.119215663272972,-1.61434717069898,-0.308329594482532,-0.499059884078499,-0.463499999577556,-0.979118324841228,-1.80669381868135,-1.76143578386197,0.0521183256861163,-0.531387051806629,0.483686014856651,-0.676859306583214,-1.16661589766438,-1.60303266199414,0.199206938849107,-0.376216646711606,0.183043354985042,0.14263439532488,1.98366659744188,-0.938709365181066,-0.591192312103669,0.802108616978731,-0.052944969430306,-0.841727861996676,0.265477632691774,0.249314048827709,-0.638066705309458,0.260628557532555,-0.461883641191149,0.0860618518006526,-0.120832021659379,-0.0836557787720297,0.0165584411851737,-0.232360750321427,-1.09064705350328,-1.63374347133586,-0.599274104035702,0.000394857321108762,0.658252720588552,-0.384298438643638,-0.0286995936342086,-0.216197166457362,-0.423091039917393,0.821504917615608,-0.382682080257231,-0.259838842890337,0.0634328343909615,-0.735048208493847,1.13669480296488,-0.478047225055214,-0.71565190785697,-0.271153351595183,-0.0965866458632811,-1.10034520382172,-0.230744391935021,-0.914463989384968,0.0876782101870589,0.323666534602407,-1.45756040721755,-0.639683063695864,-0.704337399152124,-0.956489307431538,0.0876782101870589,0.591982026745886,-1.01629456772858,0.0989927188919049,0.77463052440982,0.323666534602407,-0.859507804247148,-0.125681096818598,-1.22480479957502,-0.427940115076613,-1.08903069511687,-0.348738554142695,-1.11165971252656,-1.11974150445859,0.554805783858537,-0.403694739280516,0.145867112097693,-1.02437635966061,-1.28299370148565,0.947580871755315,-0.599274104035702,-0.544317918897881,0.790794108273886,0.389937228445074,-1.59010179490288,-0.982351041614041,0.378622719740229,-1.61596352908539,-0.473198149895995,-0.838495145223863,-0.387531155416451,-0.343889478983476,-1.2943082101905,-1.17954676475563,1.12376393587362,0.632390986406048,-0.138611963909851,-0.560481502761946,-0.757677225903538,-0.0109196513837373,0.246081332054896,0.131319886620035,0.646938211883707,-0.219429883230175,-0.754444509130725,-0.0335486687934284,0.33659740169366,-0.0804230619992161,0.360842777489757,-0.274386068367996,-0.524921618261003,-1.26036468407596,0.343062835239286,-0.870822312951993,-0.754444509130725,-0.722117341402595,-1.07933254479843,-0.426323756690207,-0.253373409344712,-0.819098844586985,-0.258222484503931,0.512780465811967,-0.668777514651181,0.68249809638465,0.407717170695546,-0.490978092146467,-0.334191328665037,0.785945033114666,0.71482526411278,0.486918731629464,-1.1472195970275,-0.132146530364225,-0.266304276435963,-0.361669421233947,-0.579877803398824,-1.20217578216532,0.0585837592317425,-0.736664566880254,0.23961589850927,-0.610588612740547,-0.379449363484418,-1.47534034946802,-0.502292600851312,-0.196800865820485,-0.712419191084157,0.495000523561496,0.640472778338081,-0.974269249682009,-1.05023809384311,-0.198417224206891,-0.667161156264775,0.895857403390307,0.116772661142376,0.157181620802539,-0.848193295542302,0.423880754559611,0.281641216555839,-0.0464795358846799,-0.20326629936611,0.121621736301595,0.216986881099579,-0.119215663272972,-0.183869998729232,-0.253373409344712,0.477220581311025,-0.891834971975278,0.192741505303481,0.103841794051124,-0.836878786837457,-1.18924491507407,-0.557248785989133,-0.607355895967734,0.666334512520585,-0.284084218686435,-0.626752196604612,-1.23611930827986,-0.583110520171637,-1.68385058131446,-0.326109536733004,-0.487745375373653,1.13022936941925,-0.694639248833685,-0.962954740977163,-0.733431850107441,-0.476430866668808,0.596831101905106,-1.13913780509547,-0.0270832352478022,-0.73828092526666,-0.961338382590757,-0.93709300679466,-0.898300405520904,0.499849598720716,-1.07609982802562,-0.0901212123176558,-0.545934277284288,0.252546765600522,-0.389147513802857,0.441660696810082,-0.80293526072292,-0.343889478983476,-0.794853468790888,-0.516839826328971,0.17011248789379,-0.592808670490076,-0.358436704461133,0.0650491927773678,-0.799702543950107,-0.880520463270432,0.527327691289626,-0.618670404672579,-0.555632427602727,0.533793124835252,-0.720500983016189,-0.156391906160322,0.322050176216001,-1.80669381868135,-1.00336370063733,-0.345505837369882,-0.859507804247148,0.532176766448846,0.216986881099579,-1.16984861443719,0.410949887468358,0.221835956258799,-0.085272137158436,-0.309945952868939,-0.195184507434077,-0.971036532909196,-0.479663583441621,-0.916080347771375,-0.444103698940678,0.257395840759741,-0.515223467942564,0.275175783010213,1.26115439871818,-0.555632427602727,-0.0836557787720297,-0.644532138855084,0.132936245006441,0.997687981733917,0.338213760080066,-1.19732670700611,-0.193568149047671,-0.68332474012884,0.49338416517509,-0.153159189387509,-0.988816475159668,-0.158008264546728,0.254163123986929,-0.179020923570012,-0.924162139703408,0.462673355833366,-0.288933293845655,-0.691406532060872,-1.05347081061593,-0.418241964758174,-0.355203987688321,-0.339040403824256,-0.563714219534759,0.255779482373335,-0.71565190785697,0.43357890487805,-0.798086185563701,-0.752828150744319,-0.854658729087928,-1.09064705350328,-1.03245815159264,-0.688173815288059,-1.03892358513827,-1.27491190955362,-1.05185445222952,-2.15744358853156,-0.0480958942710862],"opacity":0.4,"type":"scatter3d","mode":"markers","name":"B","marker":{"color":"rgba(230,159,0,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","line":{"color":"rgba(230,159,0,1)"}},"textfont":{"color":"rgba(230,159,0,1)","size":55},"error_y":{"color":"rgba(230,159,0,1)","width":55},"error_x":{"color":"rgba(230,159,0,1)","width":55},"line":{"color":"rgba(230,159,0,1)","width":55},"frame":null},{"x":[2.30157547982572,1.53377643077062,1.34629061646647,-0.249719577363966,1.33736272054722,-0.11490834898336,1.36712237361137,0.0993611530785282,-0.031581320403737,-0.28602635410223,0.492188573525325,0.870136167440046,1.32248289401514,0.14102466736834,0.0457937775630561,0.50111646944457,0.480284712299665,0.879064063359292,2.36704671656685,0.530876122508722,2.40275830024384,2.07540211653817,1.34331465116005,0.450525059235513,0.971318987858161,1.25105972666118,0.822520722537404,1.58436784097968,0.36124610004306,0.858232306214385,1.61115152873741,0.757049485796271,0.780857208247592,0.266015210237776,-0.348819222067589,0.00115429796682918,-0.141692036741097,-0.596419535561328,2.08730597776383,0.173760285738906,-0.052413077548643,1.28974727564458,-0.132764140821852,0.828472653150234,0.310654689834002,1.87006051039553,0.2511353837057,0.352318204123814,0.13507273675551,0.218399765335133,1.74506996752609,1.31950692870873,0.090433257159283,0.640986838846082,1.2748674491125,1.87601244100836,3.10806207786422,1.01298250214797,1.33736272054722,0.0338899163373958,1.35819447769213,0.00710622857965951,0.48326067760608,1.45342536749741,0.066625534707962,0.0398418469502257,-0.0256293897909067,2.96223977784988,0.590395428637024,0.685626318442309,0.652890700071742,1.13499707971099,2.19146476348836,0.176736251045322,1.21832410829062,1.23320393482269,0.524924191895892,0.667770526603817,1.14094901032382,-0.452978007792119,0.420765406171362,0.646938769458912,-0.456251569629175,0.763001416409102,1.17070866338797,2.01290684510345,2.28967161860006,0.697530179667968,1.42961764504609,0.277919071463436,0.527900157202307,0.48326067760608,3.378874920748,2.0605222900061,0.655866665378157,0.194592042883812,0.950487230713254,-0.0256293897909067,-0.165499759192418,0.337438377591738,0.12912080614268,0.649914734765327,1.75994979405817,0.316606620446833,0.9594151266325,2.07540211653817,0.632058942926836,0.310654689834002,0.676698422523063,1.51889660423854,2.41763812677591,0.391005753107211,0.230303626560794,-0.0851486959192092,1.87601244100836,2.17063300634346,0.554683844960043,-0.0583650081614733,0.780857208247592,1.64983907772081,2.93843205539856,1.62007942465666,1.01000653684156,1.12011725317892,1.7272141756876,1.56353608383477,0.703482110280799,1.66174293894647,0.0249620204181501,2.12301756144081,0.37314996126872,1.08440566950193,0.566587706185703,1.63793521649515,0.62313104700759,0.911799681729858,0.25708731431853,0.989174779696651,3.17650927991177,2.63785955945063,0.828472653150234,0.646938769458912,1.56353608383477,1.34331465116005,0.584443498024194,-0.659510000057329,1.89982016345968,1.53377643077062,1.00107864092231,1.27784341441892,1.89982016345968,0.670746491910233,0.191616077577397,0.507068400057401,1.06952584296986,1.60222363281817,2.83129730436761,1.49806484709364,0.36124610004306,3.63183197179328,0.414813475558532,1.60519959812458,1.5694880144476,2.74499431048158,2.61107587169289,0.655866665378157,1.33438675524081,1.77185365528383,-0.461310710650081,-0.150619932660342,1.03381425929288,1.03679022459929,1.92660385121742,1.25998762258043,0.917751612342688,0.0844813265464526,1.48318502056156,0.539804018427967,1.15285287154948,1.13202111440458,0.197568008190228,0.760025451102687,0.774905277634762,1.13499707971099,1.81351716957364,0.968343022551746,1.33438675524081,4.28356837389819,1.08142970419552,0.441597163316268,1.38795413075628,0.596347359249854,1.07547777358269,1.16475673277514,1.66471890425288,-0.0375332510165674,3.10211014725139,0.310654689834002,0.179712216351737,0.194592042883812,1.03976618990571,1.58436784097968,2.92950415947931,1.33141078993439,1.57543994506043,-0.0881246612256246,0.638010873539666,2.13789738797289,1.75102189813892,1.42068974912684,0.578491567411364,2.30157547982572],"y":[2.10767181755745,-0.146619958208497,0.854222318593395,1.98783916947293,0.612639700055007,1.26213265267309,0.509104292109984,-0.0210353430159227,1.27890922340493,3.99192037603841,-0.605339335076031,0.595863129323175,0.439601356220964,-0.191677033888276,2.02330963330595,2.06309407247001,0.0920866767758621,0.988434884448055,1.27028127274284,1.71749671539426,0.207605349529337,0.945774461729966,0.542178102981311,1.3503294816633,0.347090551899716,1.7318766331644,-0.111628824967818,1.63505185351211,2.02954093100635,1.37381668068786,1.61491996863391,1.22330687469371,1.28801650465935,1.18112578256796,-1.18973919325461,1.10635021016322,-0.305278384272399,0.623664303678783,2.16662948041503,0.451584621029415,0.482261778939052,2.21600053142586,1.09484627594711,-0.0473985255945167,-0.00473810287642824,0.554640698382101,0.414676165419384,2.01324369086685,0.624143634271121,0.14481304193305,-0.01672136768488,1.8426019999945,0.0273770468102224,0.051343576427126,0.51006295329466,2.37705561045145,1.79946224668407,-0.138950668731088,0.208564010714013,0.300595484442923,1.45386488960832,0.0594921964968734,1.18927440263771,0.659614098104138,0.226299242630522,0.21431597782207,1.75152918745026,3.30072566188691,0.950088437061009,2.22127316794157,-0.226668167128955,0.263687028832892,1.47687275804055,0.514856259218041,0.232530540330917,1.4145597810366,0.51245960625635,0.129474462978232,0.595863129323175,-0.261179969777296,0.303471467996952,0.0384016504339982,0.854222318593395,0.412758843050032,-0.219478208243884,1.95955866452499,0.587714509253427,-0.193594356257628,1.03924392723589,-0.0373325831554169,1.48981468403368,1.5051532629885,1.25494269378802,1.94517874675484,0.0863347096678053,0.435287380889921,0.391188966394818,2.76387539846827,0.816355201798687,0.894965418942131,0.521087556918436,-0.0895796177202668,0.547930070089368,1.07615238284592,0.376809048624676,2.47819436543478,0.922287262705401,0.290050211411485,-0.378615964900124,0.546012747720015,0.229654556776889,0.0388809810263362,0.489931068416461,0.917493956782021,0.429056083189526,0.610243047093317,0.601135765838894,1.70647211177049,1.10059824305516,0.682621966536366,1.4850213781103,0.209043341306352,0.248827780470411,0.352842519007773,2.04631750173818,2.76435472906061,0.314496071620727,0.764587497826176,0.233489201515593,0.732951678731863,0.81827252416804,1.65805972194434,1.42893969880674,0.511021614479336,-0.724213321975873,-0.20318096810439,-0.221395530613236,0.559434004305482,0.345173229530364,1.4787900804099,-0.307675037234089,-0.24536206023014,1.45338555901598,0.764108167233838,1.10443288779387,-1.01133234678638,1.62929988640406,1.05937581211409,0.542178102981311,-0.0555471456642638,1.25686001615737,0.419469471342765,0.298198831481233,1.0708797463302,0.574293252667962,0.916535295597344,1.00521145517989,0.964468354831151,1.98927716124995,1.78747898187562,0.626540287232811,-0.00953140879980896,0.4702785141306,0.0666821553819445,0.975013627862589,2.09233323860263,0.624143634271121,0.688853264236761,2.7226529675272,-0.0224733347929368,0.530674168765197,1.35704010995603,2.07603599846314,3.02558990188486,0.277587616010696,-0.563158242950281,0.71377845503834,3.01839994299979,1.2396041148332,0.570458607929257,0.645713510926334,1.10922619371725,0.751645571833048,1.76255379107404,0.803892606397898,0.601615096431232,-0.0397292361171073,1.97058326814876,1.17105984012886,1.52192983372033,1.54062372682151,-0.117380792075875,-0.0852656423892241,0.388792313433128,1.17777046842159,0.315934063397741,0.513897598033365,1.52864046201306,1.14277933518091,0.0690788083436348,0.497121027301532,0.70131585963755,0.928039229813458,0.177407522212039,0.820189846537392,0.724803058662116,4.30348526105815,1.85841990954165,0.663928073435181,0.236365185069622,0.326479336429179,3.1947936009802],"z":[2.74820411421215,-0.243675259026272,1.15124202844253,6.04072614732218,-0.86758959617918,1.75252734818575,0.262244915918961,0.477220581311025,2.3877561940435,2.36835989340663,0.0763637014822138,1.4405701796093,0.444893413582895,-0.14831011422829,1.12376393587362,2.12913885221846,0.20728873078114,1.30156335837834,-0.214580808070956,2.85488376771498,-0.127297455205005,1.15124202844253,1.88345237748468,2.20349133799316,-0.90476583906653,1.82041440041482,-0.233977108707833,0.878077461139836,3.00682145603719,1.01708428237079,1.24660717324052,2.2131894883116,3.17169001145065,1.11568214394159,-2.15905994691797,-0.151542831001102,0.150716187256913,0.102225435664718,2.8597328428742,1.35490318512975,1.28055069935505,1.45188468831414,1.6151368853412,0.194357863689888,-0.36490213800676,1.02839879107564,1.28863249128709,-0.0917375707040622,0.779479599569039,0.679265379611837,-0.565330577921165,0.666334512520585,-0.503908959237718,-0.405311097666922,1.37429948576663,4.1043288004072,-0.882136821656839,-0.953256590658724,1.28378341612787,0.192741505303481,1.70565295497996,-0.557248785989133,-0.107901154568127,1.27408526580943,-0.295398727391281,-0.403694739280516,0.398019020377106,1.86567243523421,1.10598399362315,0.603296535450732,3.20240082079238,-0.0109196513837373,0.519245899357593,0.920102779186404,-0.0965866458632811,0.653403645429333,-0.103052079408907,0.936266363050469,0.33659740169366,-0.11598294650016,0.829586709547641,-0.1757882067972,4.64419250146697,-0.707570115924937,-0.739897283653067,1.19973278003473,1.11244942716878,-0.146693755841882,-1.19732670700611,-0.0270832352478022,0.509547749039155,0.247697690441302,-0.0723412700671836,1.93517584584968,0.866762952434991,0.443277055196488,0.49338416517509,3.66144660253182,0.507931390652748,0.160414337575351,0.289723008487871,-0.859507804247148,0.472371506151805,2.99389058894594,0.0440365337540838,0.480453298083837,2.47503954690945,0.831203067934048,0.604912893837138,0.0133257244123602,-2.02490220084623,-2.09763832823452,2.94701619574015,1.17872012101144,0.273559424623806,-0.303480519323313,1.765458215277,0.818272200842796,0.33659740169366,-0.749595433971506,0.326899251375221,-1.0712507528664,-0.0771903452264035,0.0311056666628315,0.36407549426257,-0.245291617412679,0.383471794899448,0.773014166023413,0.270326707850994,-0.133762888750631,0.577434801268227,0.608145610609951,0.987989831415478,0.404484453922732,-0.725350058175409,0.268710349464586,-0.351971270915508,0.509547749039155,-0.052944969430306,-0.109517512954533,-0.641299422082271,-0.539468843738662,0.577434801268227,1.11406578555518,-0.211348091298142,-1.49150393333209,0.108690869210344,0.635623703178862,-0.14346103906907,0.249314048827709,4.29505909000317,0.326899251375221,-0.266304276435963,0.191125146917075,-0.448952774099898,1.25792168194536,-0.497443525692093,1.84950885137014,2.17278052865144,1.27570162419583,-0.398845664121296,-0.471581791509588,0.598447460291512,-0.631601271763832,-0.258222484503931,3.1086520343808,-0.276002426754402,-0.342273120597069,2.02569191548845,-0.684941098515246,-0.524921618261003,0.462673355833366,1.49875908151993,0.556422142244943,0.257395840759741,0.537025841608065,0.165263412734571,-0.0561776862031187,0.21213780594036,0.171728846280197,0.449742488742115,-0.647764855627897,-0.0949702874768748,0.11515630275597,-1.0227600012742,-0.982351041614041,0.176577921439416,-0.419858323144581,-0.96942017452279,0.674416304452617,0.59036566835948,2.87104735157905,0.566120292563382,-0.631601271763832,-0.680092023356027,1.21266364712598,0.0117093660259539,0.181426996598636,1.10598399362315,-1.00013098386451,0.280024858169432,-0.568563294693978,0.414182604241171,0.516013182584781,0.284873933328651,-0.327725895119411,1.92062862037203,0.0456528921404902,-1.35896254564676,-0.531387051806629,-1.10357792059453,1.91739590359921],"opacity":0.4,"type":"scatter3d","mode":"markers","name":"M","marker":{"color":"rgba(86,180,233,1)","size":[55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55],"sizemode":"area","line":{"color":"rgba(86,180,233,1)"}},"textfont":{"color":"rgba(86,180,233,1)","size":55},"error_y":{"color":"rgba(86,180,233,1)","width":55},"error_x":{"color":"rgba(86,180,233,1)","width":55},"line":{"color":"rgba(86,180,233,1)","width":55},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p><em>Normally we recommend against 3D plots, but here for learning purposes we want to illustrate what happens when we go to higher dimensions.</em></p>
<p>Each explanatory variable/predictor can give us new information to help create our classifier. The distance formula for 3-dimensions is
<span class="math display">\[Distance = \sqrt{(x_a -x_b)^2 + (y_a - y_b)^2 + (z_a - z_b)^2}\]</span>
We can generalize for n-dimensions by</p>
<ul>
<li>summing up the squares of the differences between each individual coordinate</li>
<li>taking the square root of the sum</li>
</ul>
</div>
</div>
<div id="additional-readingsresources-2" class="section level2">
<h2><span class="header-section-number">6.5</span> Additional readings/resources</h2>
<ul>
<li><a href="https://topepo.github.io/caret/index.html">The <code>caret</code> Package</a></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="GitHub.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classification-continued.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-classification.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
