<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Regression I: K-nearest neighbours | Data Science: A First Introduction</title>
  <meta name="description" content="This is a textbook for teaching a first introduction to data science." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Regression I: K-nearest neighbours | Data Science: A First Introduction" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a textbook for teaching a first introduction to data science." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Regression I: K-nearest neighbours | Data Science: A First Introduction" />
  
  <meta name="twitter:description" content="This is a textbook for teaching a first introduction to data science." />
  

<meta name="author" content="Tiffany-Anne Timbers" />
<meta name="author" content="Trevor Campbell" />
<meta name="author" content="Melissa Lee" />


<meta name="date" content="2021-07-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classification-continued.html"/>
<link rel="next" href="regression2.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.3/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science: A First Introduction</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> R and the tidyverse</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#preface"><i class="fa fa-check"></i><b>1.1</b> Preface</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#overview"><i class="fa fa-check"></i><b>1.2</b> Overview</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#chapter-learning-objectives"><i class="fa fa-check"></i><b>1.3</b> Chapter Learning Objectives</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#ask-a-question"><i class="fa fa-check"></i><b>1.4</b> Ask a question</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#canadian-languages-data-set-question"><i class="fa fa-check"></i><b>1.5</b> Canadian languages data set question</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#loading-a-tabular-data-set"><i class="fa fa-check"></i><b>1.6</b> Loading a tabular data set</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#naming-things-in-r"><i class="fa fa-check"></i><b>1.7</b> Naming things in R</a></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#creating-subsets-of-data-frames-with-filter-select"><i class="fa fa-check"></i><b>1.8</b> Creating subsets of data frames with <code>filter</code> &amp; <code>select</code></a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="index.html"><a href="index.html#using-filter-to-extract-rows"><i class="fa fa-check"></i><b>1.8.1</b> Using <code>filter</code> to extract rows</a></li>
<li class="chapter" data-level="1.8.2" data-path="index.html"><a href="index.html#using-select-to-extract-columns"><i class="fa fa-check"></i><b>1.8.2</b> Using <code>select</code> to extract columns</a></li>
<li class="chapter" data-level="1.8.3" data-path="index.html"><a href="index.html#using-arrange-to-order-and-slice-to-select-rows-by-index-number"><i class="fa fa-check"></i><b>1.8.3</b> Using <code>arrange</code> to order and <code>slice</code> to select rows by index number</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#exploring-data-with-visualizations"><i class="fa fa-check"></i><b>1.9</b> Exploring data with visualizations</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="index.html"><a href="index.html#using-ggplot-to-create-a-bar-plot"><i class="fa fa-check"></i><b>1.9.1</b> Using <code>ggplot</code> to create a bar plot</a></li>
<li class="chapter" data-level="1.9.2" data-path="index.html"><a href="index.html#formatting-ggplot-objects"><i class="fa fa-check"></i><b>1.9.2</b> Formatting ggplot objects</a></li>
<li class="chapter" data-level="1.9.3" data-path="index.html"><a href="index.html#putting-it-all-together"><i class="fa fa-check"></i><b>1.9.3</b> Putting it all together</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reading.html"><a href="reading.html"><i class="fa fa-check"></i><b>2</b> Reading in data locally and from the web</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reading.html"><a href="reading.html#overview-1"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="reading.html"><a href="reading.html#chapter-learning-objectives-1"><i class="fa fa-check"></i><b>2.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="2.3" data-path="reading.html"><a href="reading.html#absolute-and-relative-file-paths"><i class="fa fa-check"></i><b>2.3</b> Absolute and relative file paths</a></li>
<li class="chapter" data-level="2.4" data-path="reading.html"><a href="reading.html#reading-tabular-data-from-a-plain-text-file-into-r"><i class="fa fa-check"></i><b>2.4</b> Reading tabular data from a plain text file into R</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="reading.html"><a href="reading.html#readcsv"><i class="fa fa-check"></i><b>2.4.1</b> <code>read_csv</code> to read in comma-separated files</a></li>
<li class="chapter" data-level="2.4.2" data-path="reading.html"><a href="reading.html#skipping-rows-when-reading-in-data"><i class="fa fa-check"></i><b>2.4.2</b> Skipping rows when reading in data</a></li>
<li class="chapter" data-level="2.4.3" data-path="reading.html"><a href="reading.html#read_tsv-to-read-in-tab-separated-files"><i class="fa fa-check"></i><b>2.4.3</b> <code>read_tsv</code> to read in tab-separated files</a></li>
<li class="chapter" data-level="2.4.4" data-path="reading.html"><a href="reading.html#read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4.4</b> <code>read_delim</code> as a more flexible method to get tabular data into R</a></li>
<li class="chapter" data-level="2.4.5" data-path="reading.html"><a href="reading.html#reading-tabular-data-directly-from-a-url"><i class="fa fa-check"></i><b>2.4.5</b> Reading tabular data directly from a URL</a></li>
<li class="chapter" data-level="2.4.6" data-path="reading.html"><a href="reading.html#previewing-a-data-file-before-reading-it-into-r"><i class="fa fa-check"></i><b>2.4.6</b> Previewing a data file before reading it into R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reading.html"><a href="reading.html#reading-tabular-data-from-a-microsoft-excel-file"><i class="fa fa-check"></i><b>2.5</b> Reading tabular data from a Microsoft Excel file</a></li>
<li class="chapter" data-level="2.6" data-path="reading.html"><a href="reading.html#reading-data-from-a-database"><i class="fa fa-check"></i><b>2.6</b> Reading data from a database</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="reading.html"><a href="reading.html#connecting-to-a-database"><i class="fa fa-check"></i><b>2.6.1</b> Connecting to a database</a></li>
<li class="chapter" data-level="2.6.2" data-path="reading.html"><a href="reading.html#interacting-with-a-database"><i class="fa fa-check"></i><b>2.6.2</b> Interacting with a database</a></li>
<li class="chapter" data-level="2.6.3" data-path="reading.html"><a href="reading.html#why-should-we-bother-with-databases-at-all"><i class="fa fa-check"></i><b>2.6.3</b> Why should we bother with databases at all?</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="reading.html"><a href="reading.html#writing-data-from-r-to-a-.csv-file"><i class="fa fa-check"></i><b>2.7</b> Writing data from R to a <code>.csv</code> file</a></li>
<li class="chapter" data-level="2.8" data-path="reading.html"><a href="reading.html#obtaining-data-from-the-web"><i class="fa fa-check"></i><b>2.8</b> Obtaining data from the web</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="reading.html"><a href="reading.html#web-scraping"><i class="fa fa-check"></i><b>2.8.1</b> Web scraping</a></li>
<li class="chapter" data-level="2.8.2" data-path="reading.html"><a href="reading.html#using-an-api"><i class="fa fa-check"></i><b>2.8.2</b> Using an API</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="reading.html"><a href="reading.html#additional-resources"><i class="fa fa-check"></i><b>2.9</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="wrangling.html"><a href="wrangling.html"><i class="fa fa-check"></i><b>3</b> Cleaning and wrangling data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="wrangling.html"><a href="wrangling.html#overview-2"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="wrangling.html"><a href="wrangling.html#chapter-learning-objectives-2"><i class="fa fa-check"></i><b>3.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="3.3" data-path="wrangling.html"><a href="wrangling.html#data-frames-and-vectors"><i class="fa fa-check"></i><b>3.3</b> Data frames and Vectors</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="wrangling.html"><a href="wrangling.html#what-is-a-data-frame"><i class="fa fa-check"></i><b>3.3.1</b> What is a data frame?</a></li>
<li class="chapter" data-level="3.3.2" data-path="wrangling.html"><a href="wrangling.html#what-is-a-vector"><i class="fa fa-check"></i><b>3.3.2</b> What is a vector?</a></li>
<li class="chapter" data-level="3.3.3" data-path="wrangling.html"><a href="wrangling.html#how-are-vectors-different-from-a-list"><i class="fa fa-check"></i><b>3.3.3</b> How are vectors different from a list?</a></li>
<li class="chapter" data-level="3.3.4" data-path="wrangling.html"><a href="wrangling.html#what-does-this-have-to-do-with-data-frames"><i class="fa fa-check"></i><b>3.3.4</b> What does this have to do with data frames?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="wrangling.html"><a href="wrangling.html#tidy-data"><i class="fa fa-check"></i><b>3.4</b> Tidy Data</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="wrangling.html"><a href="wrangling.html#what-is-tidy-data"><i class="fa fa-check"></i><b>3.4.1</b> What is tidy data?</a></li>
<li class="chapter" data-level="3.4.2" data-path="wrangling.html"><a href="wrangling.html#why-is-tidy-data-important-in-r"><i class="fa fa-check"></i><b>3.4.2</b> Why is tidy data important in R?</a></li>
<li class="chapter" data-level="3.4.3" data-path="wrangling.html"><a href="wrangling.html#going-from-wide-to-long-or-tidy-using-pivot_longer"><i class="fa fa-check"></i><b>3.4.3</b> Going from wide to long (or tidy!) using <code>pivot_longer</code></a></li>
<li class="chapter" data-level="3.4.4" data-path="wrangling.html"><a href="wrangling.html#pivot-wider"><i class="fa fa-check"></i><b>3.4.4</b> Going from long to wide using <code>pivot_wider</code></a></li>
<li class="chapter" data-level="3.4.5" data-path="wrangling.html"><a href="wrangling.html#using-separate-to-deal-with-multiple-delimiters"><i class="fa fa-check"></i><b>3.4.5</b> Using <code>separate</code> to deal with multiple delimiters</a></li>
<li class="chapter" data-level="3.4.6" data-path="wrangling.html"><a href="wrangling.html#notes-on-defining-tidy-data"><i class="fa fa-check"></i><b>3.4.6</b> Notes on defining tidy data</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="wrangling.html"><a href="wrangling.html#using-select-to-extract-a-range-of-columns"><i class="fa fa-check"></i><b>3.5</b> Using <code>select</code> to extract a range of columns</a></li>
<li class="chapter" data-level="3.6" data-path="wrangling.html"><a href="wrangling.html#using-filter-to-extract-rows-1"><i class="fa fa-check"></i><b>3.6</b> Using <code>filter</code> to extract rows</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="wrangling.html"><a href="wrangling.html#using-filter-to-extract-rows-with"><i class="fa fa-check"></i><b>3.6.1</b> Using <code>filter</code> to extract rows with <code>==</code></a></li>
<li class="chapter" data-level="3.6.2" data-path="wrangling.html"><a href="wrangling.html#using-filter-to-extract-rows-with-1"><i class="fa fa-check"></i><b>3.6.2</b> Using <code>filter</code> to extract rows with <code>!=</code></a></li>
<li class="chapter" data-level="3.6.3" data-path="wrangling.html"><a href="wrangling.html#using-filter-to-extract-rows-with-2"><i class="fa fa-check"></i><b>3.6.3</b> Using <code>filter</code> to extract rows with <code>,</code> &amp;`</a></li>
<li class="chapter" data-level="3.6.4" data-path="wrangling.html"><a href="wrangling.html#using-filter-to-extract-rows-with-3"><i class="fa fa-check"></i><b>3.6.4</b> Using <code>filter</code> to extract rows with <code>|</code></a></li>
<li class="chapter" data-level="3.6.5" data-path="wrangling.html"><a href="wrangling.html#using-filter-to-extract-rows-with-in"><i class="fa fa-check"></i><b>3.6.5</b> Using <code>filter</code> to extract rows with <code>%in%</code></a></li>
<li class="chapter" data-level="3.6.6" data-path="wrangling.html"><a href="wrangling.html#using-filter-to-extract-rows-with-values-above-or-below-a-threshold"><i class="fa fa-check"></i><b>3.6.6</b> Using <code>filter</code> to extract rows with values above or below a threshold</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="wrangling.html"><a href="wrangling.html#using-mutate-to-modify-or-add-columns"><i class="fa fa-check"></i><b>3.7</b> Using <code>mutate</code> to modify or add columns</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="wrangling.html"><a href="wrangling.html#using-mutate-to-modify-columns"><i class="fa fa-check"></i><b>3.7.1</b> Using <code>mutate</code> to modify columns</a></li>
<li class="chapter" data-level="3.7.2" data-path="wrangling.html"><a href="wrangling.html#using-mutate-to-create-new-columns"><i class="fa fa-check"></i><b>3.7.2</b> Using <code>mutate</code> to create new columns</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="wrangling.html"><a href="wrangling.html#creating-a-visualization-with-tidy-data"><i class="fa fa-check"></i><b>3.8</b> Creating a visualization with tidy data</a></li>
<li class="chapter" data-level="3.9" data-path="wrangling.html"><a href="wrangling.html#combining-functions-using-the-pipe-operator"><i class="fa fa-check"></i><b>3.9</b> Combining functions using the pipe operator, <code>|&gt;</code></a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="wrangling.html"><a href="wrangling.html#using-to-combine-filter-and-select"><i class="fa fa-check"></i><b>3.9.1</b> Using <code>|&gt;</code> to combine <code>filter</code> and <code>select</code></a></li>
<li class="chapter" data-level="3.9.2" data-path="wrangling.html"><a href="wrangling.html#using-with-more-than-two-functions"><i class="fa fa-check"></i><b>3.9.2</b> Using <code>|&gt;</code> with more than two functions</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="wrangling.html"><a href="wrangling.html#iterating-over-data-with-group_by-summarize"><i class="fa fa-check"></i><b>3.10</b> Iterating over data with <code>group_by</code> + <code>summarize</code></a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics"><i class="fa fa-check"></i><b>3.10.1</b> Calculating summary statistics:</a></li>
<li class="chapter" data-level="3.10.2" data-path="wrangling.html"><a href="wrangling.html#calculating-group-summary-statistics"><i class="fa fa-check"></i><b>3.10.2</b> Calculating group summary statistics:</a></li>
<li class="chapter" data-level="3.10.3" data-path="wrangling.html"><a href="wrangling.html#additional-reading-on-the-dplyr-functions"><i class="fa fa-check"></i><b>3.10.3</b> Additional reading on the <code>dplyr</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="wrangling.html"><a href="wrangling.html#using-purrrs-map-functions-to-iterate"><i class="fa fa-check"></i><b>3.11</b> Using <code>purrr</code>’s <code>map*</code> functions to iterate</a></li>
<li class="chapter" data-level="3.12" data-path="wrangling.html"><a href="wrangling.html#additional-resources-1"><i class="fa fa-check"></i><b>3.12</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>4</b> Effective data visualization</a>
<ul>
<li class="chapter" data-level="4.1" data-path="viz.html"><a href="viz.html#overview-3"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="viz.html"><a href="viz.html#chapter-learning-objectives-3"><i class="fa fa-check"></i><b>4.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="4.3" data-path="viz.html"><a href="viz.html#choosing-the-visualization"><i class="fa fa-check"></i><b>4.3</b> Choosing the visualization</a></li>
<li class="chapter" data-level="4.4" data-path="viz.html"><a href="viz.html#refining-the-visualization"><i class="fa fa-check"></i><b>4.4</b> Refining the visualization</a></li>
<li class="chapter" data-level="4.5" data-path="viz.html"><a href="viz.html#creating-visualizations-with-ggplot2"><i class="fa fa-check"></i><b>4.5</b> Creating visualizations with <code>ggplot2</code></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="viz.html"><a href="viz.html#the-mauna-loa-co2-data-set"><i class="fa fa-check"></i><b>4.5.1</b> The Mauna Loa CO2 data set</a></li>
<li class="chapter" data-level="4.5.2" data-path="viz.html"><a href="viz.html#the-island-landmass-data-set"><i class="fa fa-check"></i><b>4.5.2</b> The island landmass data set</a></li>
<li class="chapter" data-level="4.5.3" data-path="viz.html"><a href="viz.html#the-old-faithful-eruptionwaiting-time-data-set"><i class="fa fa-check"></i><b>4.5.3</b> The Old Faithful eruption/waiting time data set</a></li>
<li class="chapter" data-level="4.5.4" data-path="viz.html"><a href="viz.html#the-canadian-languages-data-set"><i class="fa fa-check"></i><b>4.5.4</b> The Canadian languages data set</a></li>
<li class="chapter" data-level="4.5.5" data-path="viz.html"><a href="viz.html#the-michelson-speed-of-light-data-set"><i class="fa fa-check"></i><b>4.5.5</b> The Michelson speed of light data set</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="viz.html"><a href="viz.html#explaining-the-visualization"><i class="fa fa-check"></i><b>4.6</b> Explaining the visualization</a></li>
<li class="chapter" data-level="4.7" data-path="viz.html"><a href="viz.html#saving-the-visualization"><i class="fa fa-check"></i><b>4.7</b> Saving the visualization</a></li>
<li class="chapter" data-level="4.8" data-path="viz.html"><a href="viz.html#additional-resources-2"><i class="fa fa-check"></i><b>4.8</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="version-control.html"><a href="version-control.html"><i class="fa fa-check"></i><b>5</b> Collaboration with version control</a>
<ul>
<li class="chapter" data-level="5.1" data-path="version-control.html"><a href="version-control.html#overview-4"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="version-control.html"><a href="version-control.html#chapter-learning-objectives-4"><i class="fa fa-check"></i><b>5.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="5.3" data-path="version-control.html"><a href="version-control.html#what-is-version-control-and-why-should-i-use-it"><i class="fa fa-check"></i><b>5.3</b> What is version control, and why should I use it?</a></li>
<li class="chapter" data-level="5.4" data-path="version-control.html"><a href="version-control.html#creating-a-space-for-your-project-online"><i class="fa fa-check"></i><b>5.4</b> Creating a space for your project online</a></li>
<li class="chapter" data-level="5.5" data-path="version-control.html"><a href="version-control.html#creating-and-editing-files-on-github"><i class="fa fa-check"></i><b>5.5</b> Creating and editing files on GitHub</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="version-control.html"><a href="version-control.html#the-pen-tool"><i class="fa fa-check"></i><b>5.5.1</b> The pen tool</a></li>
<li class="chapter" data-level="5.5.2" data-path="version-control.html"><a href="version-control.html#the-add-file-menu"><i class="fa fa-check"></i><b>5.5.2</b> The “Add file” menu</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="version-control.html"><a href="version-control.html#cloning-your-repository-on-jupyterhub"><i class="fa fa-check"></i><b>5.6</b> Cloning your repository on JupyterHub</a></li>
<li class="chapter" data-level="5.7" data-path="version-control.html"><a href="version-control.html#working-in-a-cloned-repository-on-jupyterhub"><i class="fa fa-check"></i><b>5.7</b> Working in a cloned repository on JupyterHub</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="version-control.html"><a href="version-control.html#specifying-files-to-commit"><i class="fa fa-check"></i><b>5.7.1</b> Specifying files to commit</a></li>
<li class="chapter" data-level="5.7.2" data-path="version-control.html"><a href="version-control.html#making-the-commit"><i class="fa fa-check"></i><b>5.7.2</b> Making the commit</a></li>
<li class="chapter" data-level="5.7.3" data-path="version-control.html"><a href="version-control.html#pushing-the-commits-to-github"><i class="fa fa-check"></i><b>5.7.3</b> Pushing the commits to GitHub</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="version-control.html"><a href="version-control.html#collaboration"><i class="fa fa-check"></i><b>5.8</b> Collaboration</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="version-control.html"><a href="version-control.html#giving-collaborators-access-to-your-project"><i class="fa fa-check"></i><b>5.8.1</b> Giving collaborators access to your project</a></li>
<li class="chapter" data-level="5.8.2" data-path="version-control.html"><a href="version-control.html#pulling-changes-from-github"><i class="fa fa-check"></i><b>5.8.2</b> Pulling changes from GitHub</a></li>
<li class="chapter" data-level="5.8.3" data-path="version-control.html"><a href="version-control.html#handling-merge-conflicts"><i class="fa fa-check"></i><b>5.8.3</b> Handling merge conflicts</a></li>
<li class="chapter" data-level="5.8.4" data-path="version-control.html"><a href="version-control.html#communicating-using-github-issues"><i class="fa fa-check"></i><b>5.8.4</b> Communicating using GitHub issues</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="version-control.html"><a href="version-control.html#additional-resources-3"><i class="fa fa-check"></i><b>5.9</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>6</b> Classification I: training &amp; predicting</a>
<ul>
<li class="chapter" data-level="6.1" data-path="classification.html"><a href="classification.html#overview-5"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="classification.html"><a href="classification.html#chapter-learning-objectives-5"><i class="fa fa-check"></i><b>6.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="6.3" data-path="classification.html"><a href="classification.html#the-classification-problem"><i class="fa fa-check"></i><b>6.3</b> The classification problem</a></li>
<li class="chapter" data-level="6.4" data-path="classification.html"><a href="classification.html#exploring-a-data-set"><i class="fa fa-check"></i><b>6.4</b> Exploring a data set</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="classification.html"><a href="classification.html#loading-the-cancer-data"><i class="fa fa-check"></i><b>6.4.1</b> Loading the cancer data</a></li>
<li class="chapter" data-level="6.4.2" data-path="classification.html"><a href="classification.html#describing-the-variables-in-the-cancer-data-set"><i class="fa fa-check"></i><b>6.4.2</b> Describing the variables in the cancer data set</a></li>
<li class="chapter" data-level="6.4.3" data-path="classification.html"><a href="classification.html#exploring-the-cancer-data"><i class="fa fa-check"></i><b>6.4.3</b> Exploring the cancer data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="classification.html"><a href="classification.html#classification-with-k-nearest-neighbours"><i class="fa fa-check"></i><b>6.5</b> Classification with K-nearest neighbours</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="classification.html"><a href="classification.html#distance-between-points"><i class="fa fa-check"></i><b>6.5.1</b> Distance between points</a></li>
<li class="chapter" data-level="6.5.2" data-path="classification.html"><a href="classification.html#more-than-two-explanatory-variables"><i class="fa fa-check"></i><b>6.5.2</b> More than two explanatory variables</a></li>
<li class="chapter" data-level="6.5.3" data-path="classification.html"><a href="classification.html#summary-of-k-nearest-neighbours-algorithm"><i class="fa fa-check"></i><b>6.5.3</b> Summary of K-nearest neighbours algorithm</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="classification.html"><a href="classification.html#k-nearest-neighbours-with-tidymodels"><i class="fa fa-check"></i><b>6.6</b> K-nearest neighbours with <code>tidymodels</code></a></li>
<li class="chapter" data-level="6.7" data-path="classification.html"><a href="classification.html#data-preprocessing-with-tidymodels"><i class="fa fa-check"></i><b>6.7</b> Data preprocessing with <code>tidymodels</code></a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="classification.html"><a href="classification.html#centering-and-scaling"><i class="fa fa-check"></i><b>6.7.1</b> Centering and scaling</a></li>
<li class="chapter" data-level="6.7.2" data-path="classification.html"><a href="classification.html#balancing"><i class="fa fa-check"></i><b>6.7.2</b> Balancing</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="classification.html"><a href="classification.html#puttingittogetherworkflow"><i class="fa fa-check"></i><b>6.8</b> Putting it together in a <code>workflow</code></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="classification-continued.html"><a href="classification-continued.html"><i class="fa fa-check"></i><b>7</b> Classification II: evaluation &amp; tuning</a>
<ul>
<li class="chapter" data-level="7.1" data-path="classification-continued.html"><a href="classification-continued.html#overview-6"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="classification-continued.html"><a href="classification-continued.html#chapter-learning-objectives-6"><i class="fa fa-check"></i><b>7.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="7.3" data-path="classification-continued.html"><a href="classification-continued.html#evaluating-accuracy"><i class="fa fa-check"></i><b>7.3</b> Evaluating accuracy</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="classification-continued.html"><a href="classification-continued.html#create-the-train-test-split"><i class="fa fa-check"></i><b>7.3.1</b> Create the train / test split</a></li>
<li class="chapter" data-level="7.3.2" data-path="classification-continued.html"><a href="classification-continued.html#preprocess-the-data"><i class="fa fa-check"></i><b>7.3.2</b> Preprocess the data</a></li>
<li class="chapter" data-level="7.3.3" data-path="classification-continued.html"><a href="classification-continued.html#train-the-classifier"><i class="fa fa-check"></i><b>7.3.3</b> Train the classifier</a></li>
<li class="chapter" data-level="7.3.4" data-path="classification-continued.html"><a href="classification-continued.html#predict-the-labels-in-the-test-set"><i class="fa fa-check"></i><b>7.3.4</b> Predict the labels in the test set</a></li>
<li class="chapter" data-level="7.3.5" data-path="classification-continued.html"><a href="classification-continued.html#compute-the-accuracy"><i class="fa fa-check"></i><b>7.3.5</b> Compute the accuracy</a></li>
<li class="chapter" data-level="7.3.6" data-path="classification-continued.html"><a href="classification-continued.html#critically-analyze-performance"><i class="fa fa-check"></i><b>7.3.6</b> Critically analyze performance</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="classification-continued.html"><a href="classification-continued.html#tuning-the-classifier"><i class="fa fa-check"></i><b>7.4</b> Tuning the classifier</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="classification-continued.html"><a href="classification-continued.html#cross-validation"><i class="fa fa-check"></i><b>7.4.1</b> Cross-validation</a></li>
<li class="chapter" data-level="7.4.2" data-path="classification-continued.html"><a href="classification-continued.html#parameter-value-selection"><i class="fa fa-check"></i><b>7.4.2</b> Parameter value selection</a></li>
<li class="chapter" data-level="7.4.3" data-path="classification-continued.html"><a href="classification-continued.html#underoverfitting"><i class="fa fa-check"></i><b>7.4.3</b> Under/Overfitting</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="classification-continued.html"><a href="classification-continued.html#summary"><i class="fa fa-check"></i><b>7.5</b> Summary</a></li>
<li class="chapter" data-level="7.6" data-path="classification-continued.html"><a href="classification-continued.html#predictor-variable-selection"><i class="fa fa-check"></i><b>7.6</b> Predictor variable selection</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="classification-continued.html"><a href="classification-continued.html#the-effect-of-irrelevant-predictors"><i class="fa fa-check"></i><b>7.6.1</b> The effect of irrelevant predictors</a></li>
<li class="chapter" data-level="7.6.2" data-path="classification-continued.html"><a href="classification-continued.html#finding-a-good-subset-of-predictors"><i class="fa fa-check"></i><b>7.6.2</b> Finding a good subset of predictors</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="classification-continued.html"><a href="classification-continued.html#additional-resources-4"><i class="fa fa-check"></i><b>7.7</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression1.html"><a href="regression1.html"><i class="fa fa-check"></i><b>8</b> Regression I: K-nearest neighbours</a>
<ul>
<li class="chapter" data-level="8.1" data-path="regression1.html"><a href="regression1.html#overview-7"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="regression1.html"><a href="regression1.html#chapter-learning-objectives-7"><i class="fa fa-check"></i><b>8.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="8.3" data-path="regression1.html"><a href="regression1.html#the-regression-problem"><i class="fa fa-check"></i><b>8.3</b> The regression problem</a></li>
<li class="chapter" data-level="8.4" data-path="regression1.html"><a href="regression1.html#exploring-a-data-set-1"><i class="fa fa-check"></i><b>8.4</b> Exploring a data set</a></li>
<li class="chapter" data-level="8.5" data-path="regression1.html"><a href="regression1.html#k-nearest-neighbours-regression"><i class="fa fa-check"></i><b>8.5</b> K-nearest neighbours regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression1.html"><a href="regression1.html#training-evaluating-and-tuning-the-model"><i class="fa fa-check"></i><b>8.6</b> Training, evaluating, and tuning the model</a></li>
<li class="chapter" data-level="8.7" data-path="regression1.html"><a href="regression1.html#underfitting-and-overfitting"><i class="fa fa-check"></i><b>8.7</b> Underfitting and overfitting</a></li>
<li class="chapter" data-level="8.8" data-path="regression1.html"><a href="regression1.html#evaluating-on-the-test-set"><i class="fa fa-check"></i><b>8.8</b> Evaluating on the test set</a></li>
<li class="chapter" data-level="8.9" data-path="regression1.html"><a href="regression1.html#strengths-and-limitations-of-knn-regression"><i class="fa fa-check"></i><b>8.9</b> Strengths and limitations of KNN regression</a></li>
<li class="chapter" data-level="8.10" data-path="regression1.html"><a href="regression1.html#multivariate-knn-regression"><i class="fa fa-check"></i><b>8.10</b> Multivariate KNN regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="regression2.html"><a href="regression2.html"><i class="fa fa-check"></i><b>9</b> Regression II: linear regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="regression2.html"><a href="regression2.html#overview-8"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="regression2.html"><a href="regression2.html#chapter-learning-objectives-8"><i class="fa fa-check"></i><b>9.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="9.3" data-path="regression2.html"><a href="regression2.html#simple-linear-regression"><i class="fa fa-check"></i><b>9.3</b> Simple linear regression</a></li>
<li class="chapter" data-level="9.4" data-path="regression2.html"><a href="regression2.html#linear-regression-in-r"><i class="fa fa-check"></i><b>9.4</b> Linear regression in R</a></li>
<li class="chapter" data-level="9.5" data-path="regression2.html"><a href="regression2.html#comparing-simple-linear-and-knn-regression"><i class="fa fa-check"></i><b>9.5</b> Comparing simple linear and KNN regression</a></li>
<li class="chapter" data-level="9.6" data-path="regression2.html"><a href="regression2.html#multivariate-linear-regression"><i class="fa fa-check"></i><b>9.6</b> Multivariate linear regression</a></li>
<li class="chapter" data-level="9.7" data-path="regression2.html"><a href="regression2.html#multicollinearity-and-outliers"><i class="fa fa-check"></i><b>9.7</b> Multicollinearity and outliers</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="regression2.html"><a href="regression2.html#outliers"><i class="fa fa-check"></i><b>9.7.1</b> Outliers</a></li>
<li class="chapter" data-level="9.7.2" data-path="regression2.html"><a href="regression2.html#multicollinearity"><i class="fa fa-check"></i><b>9.7.2</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="regression2.html"><a href="regression2.html#designing-new-predictors"><i class="fa fa-check"></i><b>9.8</b> Designing new predictors</a></li>
<li class="chapter" data-level="9.9" data-path="regression2.html"><a href="regression2.html#the-other-sides-of-regression"><i class="fa fa-check"></i><b>9.9</b> The other sides of regression</a></li>
<li class="chapter" data-level="9.10" data-path="regression2.html"><a href="regression2.html#additional-resources-5"><i class="fa fa-check"></i><b>9.10</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>10</b> Clustering</a>
<ul>
<li class="chapter" data-level="10.1" data-path="clustering.html"><a href="clustering.html#overview-9"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="clustering.html"><a href="clustering.html#chapter-learning-objectives-9"><i class="fa fa-check"></i><b>10.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="10.3" data-path="clustering.html"><a href="clustering.html#clustering-1"><i class="fa fa-check"></i><b>10.3</b> Clustering</a></li>
<li class="chapter" data-level="10.4" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>10.4</b> K-means</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="clustering.html"><a href="clustering.html#measuring-cluster-quality"><i class="fa fa-check"></i><b>10.4.1</b> Measuring cluster quality</a></li>
<li class="chapter" data-level="10.4.2" data-path="clustering.html"><a href="clustering.html#the-clustering-algorithm"><i class="fa fa-check"></i><b>10.4.2</b> The clustering algorithm</a></li>
<li class="chapter" data-level="10.4.3" data-path="clustering.html"><a href="clustering.html#random-restarts"><i class="fa fa-check"></i><b>10.4.3</b> Random restarts</a></li>
<li class="chapter" data-level="10.4.4" data-path="clustering.html"><a href="clustering.html#choosing-k"><i class="fa fa-check"></i><b>10.4.4</b> Choosing K</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="clustering.html"><a href="clustering.html#data-pre-processing-for-k-means"><i class="fa fa-check"></i><b>10.5</b> Data pre-processing for K-means</a></li>
<li class="chapter" data-level="10.6" data-path="clustering.html"><a href="clustering.html#k-means-in-r"><i class="fa fa-check"></i><b>10.6</b> K-means in R</a></li>
<li class="chapter" data-level="10.7" data-path="clustering.html"><a href="clustering.html#additional-resources-6"><i class="fa fa-check"></i><b>10.7</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>11</b> Introduction to Statistical Inference</a>
<ul>
<li class="chapter" data-level="11.1" data-path="inference.html"><a href="inference.html#overview-10"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="inference.html"><a href="inference.html#chapter-learning-objectives-10"><i class="fa fa-check"></i><b>11.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="11.3" data-path="inference.html"><a href="inference.html#why-do-we-need-sampling"><i class="fa fa-check"></i><b>11.3</b> Why do we need sampling?</a></li>
<li class="chapter" data-level="11.4" data-path="inference.html"><a href="inference.html#sampling-distributions"><i class="fa fa-check"></i><b>11.4</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="inference.html"><a href="inference.html#sampling-distributions-for-proportions"><i class="fa fa-check"></i><b>11.4.1</b> Sampling distributions for proportions</a></li>
<li class="chapter" data-level="11.4.2" data-path="inference.html"><a href="inference.html#sampling-distributions-for-means"><i class="fa fa-check"></i><b>11.4.2</b> Sampling distributions for means</a></li>
<li class="chapter" data-level="11.4.3" data-path="inference.html"><a href="inference.html#summary-1"><i class="fa fa-check"></i><b>11.4.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="inference.html"><a href="inference.html#bootstrapping"><i class="fa fa-check"></i><b>11.5</b> Bootstrapping</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="inference.html"><a href="inference.html#overview-11"><i class="fa fa-check"></i><b>11.5.1</b> Overview</a></li>
<li class="chapter" data-level="11.5.2" data-path="inference.html"><a href="inference.html#bootstrapping-in-r"><i class="fa fa-check"></i><b>11.5.2</b> Bootstrapping in R</a></li>
<li class="chapter" data-level="11.5.3" data-path="inference.html"><a href="inference.html#using-the-bootstrap-to-calculate-a-plausible-range"><i class="fa fa-check"></i><b>11.5.3</b> Using the bootstrap to calculate a plausible range</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="inference.html"><a href="inference.html#additional-resources-7"><i class="fa fa-check"></i><b>11.6</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html"><i class="fa fa-check"></i><b>12</b> Getting started with Jupyter</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#overview-12"><i class="fa fa-check"></i><b>12.1</b> Overview</a></li>
<li class="chapter" data-level="12.2" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#chapter-learning-objectives-11"><i class="fa fa-check"></i><b>12.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="12.3" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#jupyter"><i class="fa fa-check"></i><b>12.3</b> Jupyter</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#accessing-jupyter"><i class="fa fa-check"></i><b>12.3.1</b> Accessing Jupyter</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#code-cells"><i class="fa fa-check"></i><b>12.4</b> Code cells</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#executing-code-cells"><i class="fa fa-check"></i><b>12.4.1</b> Executing code cells</a></li>
<li class="chapter" data-level="12.4.2" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#creating-new-code-cells"><i class="fa fa-check"></i><b>12.4.2</b> Creating new code cells</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#markdown-cells"><i class="fa fa-check"></i><b>12.5</b> Markdown cells</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#editing-markdown-cells"><i class="fa fa-check"></i><b>12.5.1</b> Editing Markdown cells</a></li>
<li class="chapter" data-level="12.5.2" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#creating-new-markdown-cells"><i class="fa fa-check"></i><b>12.5.2</b> Creating new Markdown cells</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#saving-your-work"><i class="fa fa-check"></i><b>12.6</b> Saving your work</a></li>
<li class="chapter" data-level="12.7" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#best-practices-for-running-a-notebook"><i class="fa fa-check"></i><b>12.7</b> Best practices for running a notebook</a>
<ul>
<li class="chapter" data-level="12.7.1" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#best-practices-for-executing-code-cells"><i class="fa fa-check"></i><b>12.7.1</b> Best practices for executing code cells</a></li>
<li class="chapter" data-level="12.7.2" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#best-practices-for-including-r-packages-in-notebooks"><i class="fa fa-check"></i><b>12.7.2</b> Best practices for including R packages in notebooks</a></li>
<li class="chapter" data-level="12.7.3" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#summary-of-best-practices-for-running-a-notebook"><i class="fa fa-check"></i><b>12.7.3</b> Summary of best practices for running a notebook</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#exploring-data-files"><i class="fa fa-check"></i><b>12.8</b> Exploring data files</a></li>
<li class="chapter" data-level="12.9" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#exporting-to-a-different-file-format"><i class="fa fa-check"></i><b>12.9</b> Exporting to a different file format</a>
<ul>
<li class="chapter" data-level="12.9.1" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#exporting-to-html"><i class="fa fa-check"></i><b>12.9.1</b> Exporting to HTML</a></li>
<li class="chapter" data-level="12.9.2" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#exporting-to-pdf"><i class="fa fa-check"></i><b>12.9.2</b> Exporting to PDF</a></li>
</ul></li>
<li class="chapter" data-level="12.10" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#creating-a-new-jupyter-notebook"><i class="fa fa-check"></i><b>12.10</b> Creating a new Jupyter notebook</a></li>
<li class="chapter" data-level="12.11" data-path="Getting-started-with-Jupyter.html"><a href="Getting-started-with-Jupyter.html#additional-resources-8"><i class="fa fa-check"></i><b>12.11</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html"><i class="fa fa-check"></i><b>13</b> Moving to your own machine</a>
<ul>
<li class="chapter" data-level="13.1" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#overview-13"><i class="fa fa-check"></i><b>13.1</b> Overview</a></li>
<li class="chapter" data-level="13.2" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#chapter-learning-objectives-12"><i class="fa fa-check"></i><b>13.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="13.3" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#installing-software-on-your-own-computer"><i class="fa fa-check"></i><b>13.3</b> Installing software on your own computer</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#git"><i class="fa fa-check"></i><b>13.3.1</b> Git</a></li>
<li class="chapter" data-level="13.3.2" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#miniconda"><i class="fa fa-check"></i><b>13.3.2</b> Miniconda</a></li>
<li class="chapter" data-level="13.3.3" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#jupyterlab"><i class="fa fa-check"></i><b>13.3.3</b> JupyterLab</a></li>
<li class="chapter" data-level="13.3.4" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#r-and-the-irkernel"><i class="fa fa-check"></i><b>13.3.4</b> R and the IRkernel</a></li>
<li class="chapter" data-level="13.3.5" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#r-packages"><i class="fa fa-check"></i><b>13.3.5</b> R packages</a></li>
<li class="chapter" data-level="13.3.6" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#latex"><i class="fa fa-check"></i><b>13.3.6</b> LaTeX</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="move-to-your-own-machine.html"><a href="move-to-your-own-machine.html#moving-files-to-your-computer"><i class="fa fa-check"></i><b>13.4</b> Moving files to your computer</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science: A First Introduction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression1" class="section level1" number="8">
<h1><span class="header-section-number">Chapter 8</span> Regression I: K-nearest neighbours</h1>
<div id="overview-7" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Overview</h2>
<p>This chapter continues our foray into answering predictive questions.
Here we will focus on <em>regression</em>, which is the process of predicting
<em>numerical</em> variables.
This is unlike the past two chapters, which focused on predicting categorical
variables via classification. However, regression does have many similarities
to classification: for example, just as in the case of classification,
we will split our data into training, validation, and test sets, we will
use <code>tidymodels</code> workflows, we will use a K-nearest neighbours (KNN)
approach to make predictions, and we will use cross-validation to choose K.
Because of how similar these procedures are, make sure to read Chapters
6 and 7 before reading this one—we will move a little bit faster here with the
concepts that have already been covered.
This chapter will primarily focus on the case where there is a single predictor,
but the end of the chapter shows how to perform
regression with more than one predictor variable, i.e., <em>multivariate regression</em>.</p>
</div>
<div id="chapter-learning-objectives-7" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Chapter learning objectives</h2>
<p>By the end of the chapter, readers will be able to:</p>
<ul>
<li>Recognize situations where a simple regression analysis would be appropriate for making predictions.</li>
<li>Explain the K-nearest neighbour (KNN) regression algorithm and describe how it differs from KNN classification.</li>
<li>Interpret the output of a KNN regression.</li>
<li>In a dataset with two or more variables, perform K-nearest neighbour regression in R using a <code>tidymodels</code> workflow</li>
<li>Execute cross-validation in R to choose the number of neighbours.</li>
<li>Evaluate KNN regression prediction accuracy in R using a test data set and an appropriate metric (<em>e.g.</em>, root means square prediction error).</li>
<li>In the context of KNN regression, compare and contrast goodness of fit and prediction properties (namely RMSE vs RMSPE).</li>
<li>Describe the advantages and disadvantages of the K-nearest neighbour regression approach.</li>
</ul>
</div>
<div id="the-regression-problem" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> The regression problem</h2>
<p>Regression, like classification, is a predictive problem setting where we want
to use past information to predict future observations. But in the case of
regression, the goal is to predict <em>numerical</em> values instead of <em>categorical</em> values.
The variable that you want to predict is often called the <em>response variable</em>.
For example, we could try to use the number of hours a person spends on
exercise each week to predict their race time in the annual Boston marathon. As
another example, we could try to use the size of a house to
predict its sale price. Both of these response variables—race time and sale price—are
numerical, and so predicting them given past data is considered a regression problem.</p>
<p>Just like in the classification setting, there are many possible methods that we can use
to predict numerical response variables. In this chapter we will
focus on the <strong>K-nearest neighbours</strong> algorithm, and in the next chapter
we will study <strong>linear regression</strong>.
In your future studies, you might encounter regression trees, splines,
and general local regression methods; see the additional resources
section at the end of the next chapter for where to begin learning more about
these other methods.</p>
<p>Many of the concepts from classification map over to the setting of regression. For example,
a regression model predicts a new observation’s response variable based on the response variables
for similar observations in the data set of past observations. When building a regression model,
we first split the data into training and test sets, in order to ensure that we assess the performance
of our method on observations not seen during training. And finally, we can use cross-validation to evaluate different
choices of model parameters (e.g., K in a K-nearest neighbours model). The major difference
is that we are now predicting numerical variables instead of categorical variables.</p>
<blockquote>
<p>You can usually tell whether a variable is numerical or categorical—and therefore whether you
need to perform regression or classification—by taking two response variables X and Y from your
data, and asking the question “is response variable X <em>more</em> than response variable Y?”
If the variable is categorical, the question will make no sense (“is blue more than red?”
or “is benign more than malignant?”). If the variable is numerical, it will make sense
(“is 1.5 hours more than 2.25 hours?” or “is $500,000 more than $400,000?”).
Be careful when applying this heuristic, though: sometimes a categorical variables will be encoded as
numbers in your data (e.g. “1” represents “benign,” and “0” represents “malignant”). In these cases
you have to ask the question about the <em>meaning</em> of the labels (“benign” and “malignant”), not their values (“1” and “0”).</p>
</blockquote>
</div>
<div id="exploring-a-data-set-1" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Exploring a data set</h2>
<p>In this chapter and the next, we will study the Sacramento real estate data
set. This data set contains 932 real estate transactions in Sacramento,
California <a href="https://support.spatialkey.com/spatialkey-sample-csv-data/">originally reported in the Sacramento Bee newspaper</a>.
We first need to formulate a precise question that
we want to answer. In this example, our question is again predictive:
can we use the size of a house in the Sacramento, CA area to predict
its sale price? A rigorous, quantitative answer to this question might help
a realtor advise a client as to whether the price of a particular listing
is fair, or perhaps how to set the price of a new listing.
We begin the analysis by loading and examining the data.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="regression1.html#cb310-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb310-2"><a href="regression1.html#cb310-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb310-3"><a href="regression1.html#cb310-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb310-4"><a href="regression1.html#cb310-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb310-5"><a href="regression1.html#cb310-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5</span>)</span>
<span id="cb310-6"><a href="regression1.html#cb310-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb310-7"><a href="regression1.html#cb310-7" aria-hidden="true" tabindex="-1"></a>sacramento <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/sacramento.csv&quot;</span>)</span>
<span id="cb310-8"><a href="regression1.html#cb310-8" aria-hidden="true" tabindex="-1"></a>sacramento</span></code></pre></div>
<pre><code>## # A tibble: 932 x 9
##    city           zip     beds baths  sqft type        price latitude longitude
##    &lt;chr&gt;          &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;
##  1 SACRAMENTO     z95838     2     1   836 Residential 59222     38.6     -121.
##  2 SACRAMENTO     z95823     3     1  1167 Residential 68212     38.5     -121.
##  3 SACRAMENTO     z95815     2     1   796 Residential 68880     38.6     -121.
##  4 SACRAMENTO     z95815     2     1   852 Residential 69307     38.6     -121.
##  5 SACRAMENTO     z95824     2     1   797 Residential 81900     38.5     -121.
##  6 SACRAMENTO     z95841     3     1  1122 Condo       89921     38.7     -121.
##  7 SACRAMENTO     z95842     3     2  1104 Residential 90895     38.7     -121.
##  8 SACRAMENTO     z95820     3     1  1177 Residential 91002     38.5     -121.
##  9 RANCHO_CORDOVA z95670     2     2   941 Condo       94905     38.6     -121.
## 10 RIO_LINDA      z95673     3     2  1146 Residential 98937     38.7     -121.
## # … with 922 more rows</code></pre>
<p>The scientific question guides our initial exploration: the columns in the
data that we are interested in are <code>sqft</code> (house size, in livable square feet)
and <code>price</code> (house sale price, in US dollars (USD)). The first step is to visualize
the data as a scatter plot where we place the predictor variable
(house size) on the x-axis, and we place the target/response variable that we
want to predict (sale price) on the y-axis.</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="regression1.html#cb312-1" aria-hidden="true" tabindex="-1"></a>eda <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sacramento, <span class="fu">aes</span>(<span class="at">x =</span> sqft, <span class="at">y =</span> price)) <span class="sc">+</span></span>
<span id="cb312-2"><a href="regression1.html#cb312-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb312-3"><a href="regression1.html#cb312-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;House size (square feet)&quot;</span>) <span class="sc">+</span></span>
<span id="cb312-4"><a href="regression1.html#cb312-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Price (USD)&quot;</span>) <span class="sc">+</span></span>
<span id="cb312-5"><a href="regression1.html#cb312-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> <span class="fu">dollar_format</span>())</span>
<span id="cb312-6"><a href="regression1.html#cb312-6" aria-hidden="true" tabindex="-1"></a>eda</span></code></pre></div>
<div class="figure"><span id="fig:07-edaRegr"></span>
<img src="_main_files/figure-html/07-edaRegr-1.png" alt="Scatter plot of price (USD) versus house size (square feet)" width="480" />
<p class="caption">
Figure 8.1: Scatter plot of price (USD) versus house size (square feet)
</p>
</div>
<p>The plot is shown in Figure <a href="regression1.html#fig:07-edaRegr">8.1</a>.
We can see that in Sacramento, CA, as the
size of a house increases, so does its sale price. Thus, we can reason that we
may be able to use the size of a not-yet-sold house (for which we don’t know
the sale price) to predict its final sale price. Note that we do not suggest here
that a larger house size <em>causes</em> a higher sale price; just that house price
tends to increase with house size, and that we may be able to use the latter to
predict the former.</p>
</div>
<div id="k-nearest-neighbours-regression" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> K-nearest neighbours regression</h2>
<p>Much like in the case of classification, we can use a K-nearest
neighbours-based approach in regression to make predictions. Let’s take a small
sample of the data above and walk through how K-nearest neighbours (knn) works
in a regression context before we dive in to creating our model and assessing
how well it predicts house sale price. This subsample is taken to allow us to
illustrate the mechanics of KNN regression with a few data points; later in
this chapter we will use all the data.</p>
<p>To take a small random sample of size 30, we’ll use the function <code>slice_sample</code>, and input the data frame to sample from and the number of rows to randomly select.</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="regression1.html#cb313-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb313-2"><a href="regression1.html#cb313-2" aria-hidden="true" tabindex="-1"></a>small_sacramento <span class="ot">&lt;-</span> <span class="fu">slice_sample</span>(sacramento, <span class="at">n =</span> <span class="dv">30</span>)</span></code></pre></div>
<p>Next let’s say we come across a 2,000 square-foot house in Sacramento we are
interested in purchasing, with an advertised list price of $350,000. Should we
offer to pay the asking price for this house, or is it overpriced and we should
offer less? Absent any other information, we can get a sense for a good answer
to this question by using the data we have to predict the sale price given the
sale prices we have already observed. But in Figure (fig:07-small-eda-regr),
you can see that we have no
observations of a house of size <em>exactly</em> 2,000 square feet. How can we predict
the sale price?</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="regression1.html#cb314-1" aria-hidden="true" tabindex="-1"></a>small_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(small_sacramento, <span class="fu">aes</span>(<span class="at">x =</span> sqft, <span class="at">y =</span> price)) <span class="sc">+</span></span>
<span id="cb314-2"><a href="regression1.html#cb314-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb314-3"><a href="regression1.html#cb314-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;House size (square feet)&quot;</span>) <span class="sc">+</span></span>
<span id="cb314-4"><a href="regression1.html#cb314-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Price (USD)&quot;</span>) <span class="sc">+</span></span>
<span id="cb314-5"><a href="regression1.html#cb314-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> <span class="fu">dollar_format</span>()) <span class="sc">+</span></span>
<span id="cb314-6"><a href="regression1.html#cb314-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">2000</span>, <span class="at">linetype =</span> <span class="st">&quot;dotted&quot;</span>)</span>
<span id="cb314-7"><a href="regression1.html#cb314-7" aria-hidden="true" tabindex="-1"></a>small_plot</span></code></pre></div>
<div class="figure"><span id="fig:07-small-eda-regr"></span>
<img src="_main_files/figure-html/07-small-eda-regr-1.png" alt="Scatter plot of price (USD) versus house size (square feet) with vertical line indicating 2,000 square feet on x-axis" width="480" />
<p class="caption">
Figure 8.2: Scatter plot of price (USD) versus house size (square feet) with vertical line indicating 2,000 square feet on x-axis
</p>
</div>
<p>We will employ the same intuition from the classification chapter, and use the
neighbouring points to the new point of interest to suggest/predict what its
sale price might be. For the example above, we find and label the 5 nearest
neighbours to our observation of a house that is 2,000 square feet.</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="regression1.html#cb315-1" aria-hidden="true" tabindex="-1"></a>nearest_neighbours <span class="ot">&lt;-</span> small_sacramento <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb315-2"><a href="regression1.html#cb315-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">diff =</span> <span class="fu">abs</span>(<span class="dv">2000</span> <span class="sc">-</span> sqft)) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb315-3"><a href="regression1.html#cb315-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(diff) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb315-4"><a href="regression1.html#cb315-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">slice</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>) <span class="co">#subset the first 5 rows</span></span>
<span id="cb315-5"><a href="regression1.html#cb315-5" aria-hidden="true" tabindex="-1"></a>nearest_neighbours</span></code></pre></div>
<pre><code>## # A tibble: 5 x 10
##   city       zip     beds baths  sqft type        price latitude longitude  diff
##   &lt;chr&gt;      &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;
## 1 ORANGEVALE z95662     4     2  2004 Residenti… 315000     38.7     -121.     4
## 2 ANTELOPE   z95843     4     3  1915 Residenti… 240000     38.7     -121.    85
## 3 ELK_GROVE  z95757     3     2  1857 Residenti… 291000     38.4     -121.   143
## 4 SACRAMENTO z95834     4     2  2169 Residenti… 292000     38.6     -122.   169
## 5 GALT       z95632     4     3  2214 Residenti… 278000     38.3     -121.   214</code></pre>
<div class="figure"><span id="fig:07-knn3-example"></span>
<img src="_main_files/figure-html/07-knn3-example-1.png" alt="Scatter plot of price (USD) versus house size (square feet) with lines to 5 nearest neighbours" width="480" />
<p class="caption">
Figure 8.3: Scatter plot of price (USD) versus house size (square feet) with lines to 5 nearest neighbours
</p>
</div>
<p>Figure <a href="regression1.html#fig:07-knn3-example">8.3</a> illustrates the difference between the house sizes
of the 5 nearest neighbours (in terms of house size) to our new
2,000 square-foot house of interest. Now that we have obtained these nearest neighbours,
we can use their values to predict the
sale price for the new home. Specifically, we can take the mean (or
average) of these 5 values as our predicted value, as illustrated by
the red point in Figure <a href="regression1.html#fig:07-predictedViz-knn">8.4</a>.</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="regression1.html#cb317-1" aria-hidden="true" tabindex="-1"></a>prediction <span class="ot">&lt;-</span> nearest_neighbours <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb317-2"><a href="regression1.html#cb317-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">predicted =</span> <span class="fu">mean</span>(price))</span>
<span id="cb317-3"><a href="regression1.html#cb317-3" aria-hidden="true" tabindex="-1"></a>prediction</span></code></pre></div>
<pre><code>## # A tibble: 1 x 1
##   predicted
##       &lt;dbl&gt;
## 1    283200</code></pre>
<div class="figure"><span id="fig:07-predictedViz-knn"></span>
<img src="_main_files/figure-html/07-predictedViz-knn-1.png" alt="Scatter plot of price (USD) versus house size (square feet) with predicted price for a 2,000 square-foot house based on 5 nearest neighbours represented as a red dot" width="480" />
<p class="caption">
Figure 8.4: Scatter plot of price (USD) versus house size (square feet) with predicted price for a 2,000 square-foot house based on 5 nearest neighbours represented as a red dot
</p>
</div>
<p>Our predicted price is $283,200
(shown as a red point in Figure <a href="regression1.html#fig:07-predictedViz-knn">8.4</a>), which is much less than $350,000; perhaps we
might want to offer less than the list price at which the house is advertised.
But this is only the very beginning of the story. We still have all the same
unanswered questions here with KNN regression that we had with KNN
classification: which <span class="math inline">\(K\)</span> do we choose, and is our model any good at making
predictions? In the next few sections, we will address these questions in the
context of KNN regression.</p>
</div>
<div id="training-evaluating-and-tuning-the-model" class="section level2" number="8.6">
<h2><span class="header-section-number">8.6</span> Training, evaluating, and tuning the model</h2>
<p>As usual, we must start by putting some test data away in a lock box that we
will come back to only after we choose our final model. Let’s take care of that
now. Note that for the remainder of the chapter we’ll be working with the
entire Sacramento data set, as opposed to the smaller sample of 30 points above.</p>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="regression1.html#cb319-1" aria-hidden="true" tabindex="-1"></a>sacramento_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(sacramento, <span class="at">prop =</span> <span class="fl">0.75</span>, <span class="at">strata =</span> price)</span>
<span id="cb319-2"><a href="regression1.html#cb319-2" aria-hidden="true" tabindex="-1"></a>sacramento_train <span class="ot">&lt;-</span> <span class="fu">training</span>(sacramento_split)</span>
<span id="cb319-3"><a href="regression1.html#cb319-3" aria-hidden="true" tabindex="-1"></a>sacramento_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(sacramento_split)</span></code></pre></div>
<p>Next, we’ll use cross-validation to choose <span class="math inline">\(K\)</span>. In KNN classification, we used
accuracy to see how well our predictions matched the true labels. We cannot use
the same metric in the regression setting, since our predictions will almost never
<em>exactly</em> match the true response variable values. Therefore in the
context of KNN regression we will use root mean square prediction error
(RMSPE) instead. The mathematical formula for calculating RMSPE is:</p>
<p><span class="math display">\[\text{RMSPE} = \sqrt{\frac{1}{n}\sum\limits_{i=1}^{n}(y_i - \hat{y}_i)^2}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(n\)</span> is the number of observations</li>
<li><span class="math inline">\(y_i\)</span> is the observed value for the <span class="math inline">\(i^\text{th}\)</span> observation</li>
<li><span class="math inline">\(\hat{y}_i\)</span> is the forcasted/predicted value for the <span class="math inline">\(i^\text{th}\)</span> observation</li>
</ul>
<p>In other words, we compute the <em>squared</em> difference between the predicted and true response
value for each observation in our test (or validation) set, compute the average, and then finally
take the square root. The reason we use the <em>squared</em> difference (and not just the difference)
is that the differences can be positive or negative, i.e., we can overshoot or undershoot the true
response value. Figure <a href="regression1.html#fig:07-verticalerrors">8.5</a> illustrates both positive and negative differences
between predicted and true response values.
So if we want to measure error—a notion of distance between our predicted and true response values—we
want to make sure that we are only adding up positive values, with larger positive values representing larger
mistakes.
If the predictions are very close to the true values, then
RMSPE will be small. If, on the other-hand, the predictions are very
different to the true values, then RMSPE will be quite large. When we
use cross validation, we will choose the <span class="math inline">\(K\)</span> that gives
us the smallest RMSPE.</p>
<div class="figure"><span id="fig:07-verticalerrors"></span>
<img src="_main_files/figure-html/07-verticalerrors-1.png" alt="Scatter plot of price (USD) versus house size (square feet) with example predictions (blue line) and the error in those predictions compared with true response values for three selected observations (vertical red lines)." width="480" />
<p class="caption">
Figure 8.5: Scatter plot of price (USD) versus house size (square feet) with example predictions (blue line) and the error in those predictions compared with true response values for three selected observations (vertical red lines).
</p>
</div>
<blockquote>
<p><strong>RMSPE versus RMSE</strong>
When using many code packages (<code>tidymodels</code> included), the evaluation output
we will get to assess the prediction quality of
our KNN regression models is labelled “RMSE,” or “root mean squared
error.” Why is this so, and why not just RMSPE?
In statistics, we try to be very precise with our
language to indicate whether we are calculating the prediction error on the
training data (<em>in-sample</em> prediction) versus on the testing data
(<em>out-of-sample</em> prediction). When predicting and evaluating prediction quality on the training data, we
say RMSE. By contrast, when predicting and evaluating prediction quality
on the testing or validation data, we say RMSPE.
The equation for calculating RMSE and RMSPE is exactly the same; all that changes is whether the <span class="math inline">\(y\)</span>s are
training or testing data. But many people just use RMSE for both,
and rely on context to denote which data the root mean squared error is being calculated on.</p>
</blockquote>
<p>Now that we know how we can assess how well our model predicts a numerical
value, let’s use R to perform cross-validation and to choose the optimal <span class="math inline">\(K\)</span>.
First, we will create a recipe for preprocessing our data.
Note that we include standardization
in our preprocessing to build good habits, but since we only have one
predictor it is technically not necessary; there is no risk of comparing two predictors
of different scales.
Next we create a model specification for K-nearest neighbours regression. Note
that we use <code>set_mode("regression")</code>
now in the model specification to denote a regression problem, as opposed to the classification
problems from the previous chapters.
The use of <code>set_mode("regression")</code> essentially
tells <code>tidymodels</code> that we need to use different metrics (RMSPE, not accuracy)
for tuning and evaluation.
Then we create a 5-fold cross validation object, and put the recipe and model specification together
in a workflow.</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="regression1.html#cb320-1" aria-hidden="true" tabindex="-1"></a>sacr_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(price <span class="sc">~</span> sqft, <span class="at">data =</span> sacramento_train) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb320-2"><a href="regression1.html#cb320-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_scale</span>(<span class="fu">all_predictors</span>()) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb320-3"><a href="regression1.html#cb320-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_center</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb320-4"><a href="regression1.html#cb320-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-5"><a href="regression1.html#cb320-5" aria-hidden="true" tabindex="-1"></a>sacr_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">weight_func =</span> <span class="st">&quot;rectangular&quot;</span>, <span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb320-6"><a href="regression1.html#cb320-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb320-7"><a href="regression1.html#cb320-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb320-8"><a href="regression1.html#cb320-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-9"><a href="regression1.html#cb320-9" aria-hidden="true" tabindex="-1"></a>sacr_vfold <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(sacramento_train, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">strata =</span> price)</span>
<span id="cb320-10"><a href="regression1.html#cb320-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb320-11"><a href="regression1.html#cb320-11" aria-hidden="true" tabindex="-1"></a>sacr_wkflw <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb320-12"><a href="regression1.html#cb320-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(sacr_recipe) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb320-13"><a href="regression1.html#cb320-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(sacr_spec)</span>
<span id="cb320-14"><a href="regression1.html#cb320-14" aria-hidden="true" tabindex="-1"></a>sacr_wkflw</span></code></pre></div>
<pre><code>## ══ Workflow ════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: nearest_neighbor()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 2 Recipe Steps
## 
## • step_scale()
## • step_center()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## K-Nearest Neighbor Model Specification (regression)
## 
## Main Arguments:
##   neighbors = tune()
##   weight_func = rectangular
## 
## Computational engine: kknn</code></pre>
<p>Next we run cross validation for a grid of numbers of neighbours ranging from 1 to 200.
The following code tunes
the model and returns the RMSPE for each number of neighbours. In the below
results data frame, the <code>neighbors</code> variable contains the value of <span class="math inline">\(K\)</span>,
the mean (<code>mean</code>) contains the value of the RMSPE estimated via cross-validation,
and the standard error (<code>std_err</code>) is a measure of how uncertain we are in the mean value. A detailed treatment of this
is beyond the scope of this chapter; but roughly, if your estimated mean is 100,000 and standard
error is 1,000, you can expect the <em>true</em> RMSPE to be somewhere roughly between 99,000 and 101,000 (although it may
fall outside this range). You may ignore the other columns in the metrics data frame,
as they do not provide any additional insight.</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="regression1.html#cb322-1" aria-hidden="true" tabindex="-1"></a>gridvals <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">neighbors =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">1</span>, <span class="at">to =</span> <span class="dv">200</span>, <span class="at">by =</span> <span class="dv">3</span>))</span>
<span id="cb322-2"><a href="regression1.html#cb322-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb322-3"><a href="regression1.html#cb322-3" aria-hidden="true" tabindex="-1"></a>sacr_results <span class="ot">&lt;-</span> sacr_wkflw <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb322-4"><a href="regression1.html#cb322-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tune_grid</span>(<span class="at">resamples =</span> sacr_vfold, <span class="at">grid =</span> gridvals) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb322-5"><a href="regression1.html#cb322-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>() <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb322-6"><a href="regression1.html#cb322-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;rmse&quot;</span>)</span>
<span id="cb322-7"><a href="regression1.html#cb322-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb322-8"><a href="regression1.html#cb322-8" aria-hidden="true" tabindex="-1"></a><span class="co"># show the results</span></span>
<span id="cb322-9"><a href="regression1.html#cb322-9" aria-hidden="true" tabindex="-1"></a>sacr_results</span></code></pre></div>
<pre><code>## # A tibble: 67 x 7
##    neighbors .metric .estimator    mean     n std_err .config              
##        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
##  1         1 rmse    standard   117747.     5   1850. Preprocessor1_Model01
##  2         4 rmse    standard    95239.     5   2607. Preprocessor1_Model02
##  3         7 rmse    standard    91913.     5   2499. Preprocessor1_Model03
##  4        10 rmse    standard    90523.     5   2685. Preprocessor1_Model04
##  5        13 rmse    standard    89419.     5   2820. Preprocessor1_Model05
##  6        16 rmse    standard    88757.     5   3037. Preprocessor1_Model06
##  7        19 rmse    standard    88227.     5   3310. Preprocessor1_Model07
##  8        22 rmse    standard    87815.     5   3490. Preprocessor1_Model08
##  9        25 rmse    standard    87705.     5   3501. Preprocessor1_Model09
## 10        28 rmse    standard    87594.     5   3551. Preprocessor1_Model10
## # … with 57 more rows</code></pre>
<div class="figure"><span id="fig:07-choose-k-knn-plot"></span>
<img src="_main_files/figure-html/07-choose-k-knn-plot-1.png" alt="Effect of the number of neighbours on the RMSPE" width="480" />
<p class="caption">
Figure 8.6: Effect of the number of neighbours on the RMSPE
</p>
</div>
<p>Figure <a href="regression1.html#fig:07-choose-k-knn-plot">8.6</a> visualizes how the RMSPE varies with the number of neighbours <span class="math inline">\(K\)</span>.
We take the <em>minimum</em> RMSPE to find the best setting for the number of neighbours:</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="regression1.html#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="co"># show only the row of minimum RMSPE</span></span>
<span id="cb324-2"><a href="regression1.html#cb324-2" aria-hidden="true" tabindex="-1"></a>sacr_min <span class="ot">&lt;-</span> sacr_results <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb324-3"><a href="regression1.html#cb324-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(mean <span class="sc">==</span> <span class="fu">min</span>(mean))</span>
<span id="cb324-4"><a href="regression1.html#cb324-4" aria-hidden="true" tabindex="-1"></a>sacr_min</span></code></pre></div>
<pre><code>## # A tibble: 1 x 7
##   neighbors .metric .estimator   mean     n std_err .config              
##       &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
## 1        49 rmse    standard   87362.     5   4295. Preprocessor1_Model17</code></pre>
<p>The smallest RMSPE occurs when <span class="math inline">\(K =\)</span> 49.</p>
</div>
<div id="underfitting-and-overfitting" class="section level2" number="8.7">
<h2><span class="header-section-number">8.7</span> Underfitting and overfitting</h2>
<p>Similar to the setting of classification, by setting the number of neighbours
to be too small or too large, we cause the RMSPE to increase, as shown in
Figure <a href="regression1.html#fig:07-choose-k-knn-plot">8.6</a>. What is happening here?</p>
<p>Figure <a href="regression1.html#fig:07-howK">8.7</a> visualizes the effect of different settings of <span class="math inline">\(K\)</span> on the
regression model. Each plot shows the predicted values for house sale price from
our KNN regression model for 6 different values for <span class="math inline">\(K\)</span>: 1, 3, 49, 41, 250, and 932 (i.e., the entire dataset).
For each model, we predict prices for the range of possible home sizes we
observed in the data set (here 500 to 5,000 square feet) and we plot the
predicted prices as a blue line.</p>
<div class="figure"><span id="fig:07-howK"></span>
<img src="_main_files/figure-html/07-howK-1.png" alt="Predicted values for house price (represented as a blue line) from KNN regression models for six different values for $K$" width="960" />
<p class="caption">
Figure 8.7: Predicted values for house price (represented as a blue line) from KNN regression models for six different values for <span class="math inline">\(K\)</span>
</p>
</div>
<p>Figure <a href="regression1.html#fig:07-howK">8.7</a> shows that when <span class="math inline">\(K\)</span> = 1, the blue line runs perfectly
through (almost) all of our training observations.
This happens because our
predicted values for a given region (typically) depend on just a single observation.
In general, when <span class="math inline">\(K\)</span> is too small, the line follows the training data quite
closely, even if it does not match it perfectly.
If we used a different training data set of house prices and sizes
from the Sacramento real estate market, we would end up with completely different
predictions. In other words, the model is <em>influenced too much</em> by the data.
Because the model follows the training data so closely, it will not make accurate
predictions on new observations which, generally, will not have the same fluctuations
as the original training data.
Recall from the classification
chapters that this behaviour—where the model is influenced too much
by the noisy data—is called <em>overfitting</em>; we use this same term
in the context of regression.</p>
<p>What about the plots in Figure <a href="regression1.html#fig:07-howK">8.7</a> where <span class="math inline">\(K\)</span> is quite large,
say, <span class="math inline">\(K\)</span> = 250 or 932?
In this case the blue line becomes extremely smooth, and actually becomes flat
once <span class="math inline">\(K\)</span> is equal to the number of datapoints in the entire data set.
This happens because our predicted values for a given x value (here home
size), depend on many neighbouring observations; in the case where <span class="math inline">\(K\)</span> is equal
to the size of the dataset, the prediction is just the mean of the house prices
in the dataset (completely ignoring the house size).
In contrast to the <span class="math inline">\(K=1\)</span> example,
the smooth, inflexible blue line does not follow the training observations very closely.
In other words, the model is <em>not influenced enough</em> by the training data.
Recall from the classification
chapters that this behaviour is called <em>underfitting</em>; we again use this same
term in the context of regression.</p>
<p>Ideally, what we want is neither of the two situations discussed above. Instead,
we would like a model that (1) follows the overall “trend” in the training data, so the model
actually uses the training data to learn something useful, and (2) does not follow
the noisy fluctuations, so that we can be confident that our model will transfer/generalize
well to other new data. If we explore
the other values for <span class="math inline">\(K\)</span>, in particular <span class="math inline">\(K\)</span> = 49
(as suggested by cross-validation),
we can see it achieves this goal: it follows the increasing trend of house price
versus house size, but is not influenced too much by the idiosyncratic variations
in price. All of this is similar to how
the choice of <span class="math inline">\(K\)</span> affects K-nearest neighbours classification, as discussed in the previous
chapter.</p>
</div>
<div id="evaluating-on-the-test-set" class="section level2" number="8.8">
<h2><span class="header-section-number">8.8</span> Evaluating on the test set</h2>
<p>To assess how well our model might do at predicting on unseen data, we will
assess its RMSPE on the test data. To do this, we will first
re-train our KNN regression model on the entire training data set,
using <span class="math inline">\(K =\)</span> 49 neighbours. Then we will
use <code>predict</code> to make predictions on the test data, and use the <code>metrics</code>
function again to compute the summary of regression quality. Because
we specify that we are performing regression in <code>set_mode</code>, the <code>metrics</code>
function knows to output a quality summary related to regression, and not, say, classification.</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="regression1.html#cb326-1" aria-hidden="true" tabindex="-1"></a>kmin <span class="ot">&lt;-</span> sacr_min <span class="sc">|</span><span class="er">&gt;</span> <span class="fu">pull</span>(neighbors)</span>
<span id="cb326-2"><a href="regression1.html#cb326-2" aria-hidden="true" tabindex="-1"></a>sacr_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">weight_func =</span> <span class="st">&quot;rectangular&quot;</span>, <span class="at">neighbors =</span> kmin) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb326-3"><a href="regression1.html#cb326-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb326-4"><a href="regression1.html#cb326-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb326-5"><a href="regression1.html#cb326-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-6"><a href="regression1.html#cb326-6" aria-hidden="true" tabindex="-1"></a>sacr_fit <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb326-7"><a href="regression1.html#cb326-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(sacr_recipe) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb326-8"><a href="regression1.html#cb326-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(sacr_spec) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb326-9"><a href="regression1.html#cb326-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> sacramento_train)</span>
<span id="cb326-10"><a href="regression1.html#cb326-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-11"><a href="regression1.html#cb326-11" aria-hidden="true" tabindex="-1"></a>sacr_summary <span class="ot">&lt;-</span> sacr_fit <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb326-12"><a href="regression1.html#cb326-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(sacramento_test) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb326-13"><a href="regression1.html#cb326-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(sacramento_test) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb326-14"><a href="regression1.html#cb326-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> price, <span class="at">estimate =</span> .pred) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb326-15"><a href="regression1.html#cb326-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&#39;rmse&#39;</span>)</span>
<span id="cb326-16"><a href="regression1.html#cb326-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-17"><a href="regression1.html#cb326-17" aria-hidden="true" tabindex="-1"></a>sacr_summary</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard      81141.</code></pre>
<p>Our final model’s test error as assessed by RMSPE
is 81,141.
Note that RMSPE is measured in the same units as the response variable.
In other words, on new observations, we expect the error in our prediction to be
<em>roughly</em> $81,141.
From one perspective, this is good news: this is about the same as the cross-validation
RMSPE estimate of our tuned model, so we can say that the model appears to generalize well
to new data that it has never seen before.
However, much like in the case of KNN classification, whether this value for RMSPE is <em>good</em>—i.e.,
whether an error of around $81,141
is acceptable—depends entirely on the application.</p>
<p>Finally, Figure <a href="regression1.html#fig:07-predict-all">8.8</a> shows the predictions that our final model makes across
the range of house sizes we might encounter in the Sacramento area—from 500 to 5000 square feet.
You have already seen a few plots like this in this chapter, but here we also provide the code that generated it
as a learning challenge.</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="regression1.html#cb328-1" aria-hidden="true" tabindex="-1"></a>sacr_preds <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">sqft =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">500</span>, <span class="at">to =</span> <span class="dv">5000</span>, <span class="at">by =</span> <span class="dv">10</span>))</span>
<span id="cb328-2"><a href="regression1.html#cb328-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb328-3"><a href="regression1.html#cb328-3" aria-hidden="true" tabindex="-1"></a>sacr_preds <span class="ot">&lt;-</span> sacr_fit <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb328-4"><a href="regression1.html#cb328-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(sacr_preds) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb328-5"><a href="regression1.html#cb328-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(sacr_preds)</span>
<span id="cb328-6"><a href="regression1.html#cb328-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb328-7"><a href="regression1.html#cb328-7" aria-hidden="true" tabindex="-1"></a>plot_final <span class="ot">&lt;-</span> <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb328-8"><a href="regression1.html#cb328-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> sacramento_train, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> sqft, <span class="at">y =</span> price), <span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb328-9"><a href="regression1.html#cb328-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> sacr_preds, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> sqft, <span class="at">y =</span> .pred), <span class="at">color=</span><span class="st">&quot;blue&quot;</span>) <span class="sc">+</span></span>
<span id="cb328-10"><a href="regression1.html#cb328-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;House size (square feet)&quot;</span>) <span class="sc">+</span></span>
<span id="cb328-11"><a href="regression1.html#cb328-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Price (USD)&quot;</span>) <span class="sc">+</span></span>
<span id="cb328-12"><a href="regression1.html#cb328-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> <span class="fu">dollar_format</span>()) <span class="sc">+</span></span>
<span id="cb328-13"><a href="regression1.html#cb328-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">paste0</span>(<span class="st">&quot;K = &quot;</span>, kmin))</span>
<span id="cb328-14"><a href="regression1.html#cb328-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb328-15"><a href="regression1.html#cb328-15" aria-hidden="true" tabindex="-1"></a>plot_final</span></code></pre></div>
<div class="figure"><span id="fig:07-predict-all"></span>
<img src="_main_files/figure-html/07-predict-all-1.png" alt="Predicted values of house price (blue line) for the final KNN regression model" width="480" />
<p class="caption">
Figure 8.8: Predicted values of house price (blue line) for the final KNN regression model
</p>
</div>
</div>
<div id="strengths-and-limitations-of-knn-regression" class="section level2" number="8.9">
<h2><span class="header-section-number">8.9</span> Strengths and limitations of KNN regression</h2>
<p>As with KNN classification (or any prediction algorithm for that matter), KNN
regression has both strengths and weaknesses. Some are listed here:</p>
<p><strong>Strengths:</strong> K-nearest neighbours regression</p>
<ol style="list-style-type: decimal">
<li>is a simple, intuitive algorithm</li>
<li>requires few assumptions about what the data must look like</li>
<li>works well with non-linear relationships (i.e., if the relationship is not a straight line)</li>
</ol>
<p><strong>Weaknesses:</strong> K-nearest neighbours regression</p>
<ol style="list-style-type: decimal">
<li>becomes very slow as the training data gets larger</li>
<li>may not perform well with a large number of predictors</li>
<li>may not predict well beyond the range of values input in your training data</li>
</ol>
</div>
<div id="multivariate-knn-regression" class="section level2" number="8.10">
<h2><span class="header-section-number">8.10</span> Multivariate KNN regression</h2>
<p>As in KNN classification, we can use multiple predictors in KNN regression.
In this setting, we have the same concerns regarding the scale of the predictors. Once again,
predictions are made by identifying the <span class="math inline">\(K\)</span>
observations that are nearest to the new point we want to predict; any
variables that are on a large scale will have a much larger effect than
variables on a small scale. But since the <code>recipe</code> we built above scales and centers
all predictor variables, this is handled for us.</p>
<p>Note that we also have the same concern regarding the selection of predictors
in KNN regression as in KNN classification: more predictors is <strong>not</strong> always
better, and the choice of which predictors to use has a potentially large influence
on the quality of predictions. Fortunately, we can use the predictor selection
algorithm from the classification chapter in KNN regression as well.
As the algorithm is the same, we will not cover it again in this chapter.</p>
<p>We will now demonstrate a multivariate KNN regression analysis of the
Sacramento real estate data using <code>tidymodels</code>. This time we will use
house size (measured in square feet) as well as number of bedrooms as our
predictors, and continue to use house sale price as our outcome/target variable
that we are trying to predict.
It is always a good practice to do exploratory data analysis, such as
visualizing the data, before we start modeling the data. Figure <a href="regression1.html#fig:07-bedscatter">8.9</a>
shows that the number of bedrooms might provide useful information
to help predict the sale price of a house.</p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="regression1.html#cb329-1" aria-hidden="true" tabindex="-1"></a>plot_beds <span class="ot">&lt;-</span> sacramento <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb329-2"><a href="regression1.html#cb329-2" aria-hidden="true" tabindex="-1"></a>             <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> beds, <span class="at">y =</span> price)) <span class="sc">+</span></span>
<span id="cb329-3"><a href="regression1.html#cb329-3" aria-hidden="true" tabindex="-1"></a>             <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb329-4"><a href="regression1.html#cb329-4" aria-hidden="true" tabindex="-1"></a>             <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&#39;Number of Bedrooms&#39;</span>, <span class="at">y =</span> <span class="st">&#39;Price (USD)&#39;</span>)</span>
<span id="cb329-5"><a href="regression1.html#cb329-5" aria-hidden="true" tabindex="-1"></a>plot_beds</span></code></pre></div>
<div class="figure"><span id="fig:07-bedscatter"></span>
<img src="_main_files/figure-html/07-bedscatter-1.png" alt="Scatter plot of the sale price of houses versus the number of bedrooms" width="576" />
<p class="caption">
Figure 8.9: Scatter plot of the sale price of houses versus the number of bedrooms
</p>
</div>
<p>Figure <a href="regression1.html#fig:07-bedscatter">8.9</a> shows that as the number of bedrooms increases,
the house sale price tends to increase as well, but that the relationship
is quite weak. Does adding the number of bedrooms
to our model improve our ability to predict price? To answer that
question, we will have to create a new KNN regression
model using house size and number of bedrooms, and then we can compare it to
the model we previously came up with that only used house
size. Let’s do that now!</p>
<p>First we’ll build a new model specification and recipe for the analysis. Note that
we use the formula <code>price ~ sqft + beds</code> to denote that we have two predictors,
and set <code>neighbors = tune()</code> to tell <code>tidymodels</code> to tune the number of neighbours for us.</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="regression1.html#cb330-1" aria-hidden="true" tabindex="-1"></a>sacr_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(price <span class="sc">~</span> sqft <span class="sc">+</span> beds, <span class="at">data =</span> sacramento_train) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb330-2"><a href="regression1.html#cb330-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_scale</span>(<span class="fu">all_predictors</span>()) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb330-3"><a href="regression1.html#cb330-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_center</span>(<span class="fu">all_predictors</span>())</span>
<span id="cb330-4"><a href="regression1.html#cb330-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb330-5"><a href="regression1.html#cb330-5" aria-hidden="true" tabindex="-1"></a>sacr_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">weight_func =</span> <span class="st">&quot;rectangular&quot;</span>, <span class="at">neighbors =</span> <span class="fu">tune</span>()) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb330-6"><a href="regression1.html#cb330-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb330-7"><a href="regression1.html#cb330-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span></code></pre></div>
<p>Next, we’ll use 5-fold cross-validation to choose the number of neighbours via the minimum RMSPE:</p>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="regression1.html#cb331-1" aria-hidden="true" tabindex="-1"></a>gridvals <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">neighbors =</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">200</span>))</span>
<span id="cb331-2"><a href="regression1.html#cb331-2" aria-hidden="true" tabindex="-1"></a>sacr_multi <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb331-3"><a href="regression1.html#cb331-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(sacr_recipe) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb331-4"><a href="regression1.html#cb331-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(sacr_spec) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb331-5"><a href="regression1.html#cb331-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tune_grid</span>(sacr_vfold, <span class="at">grid =</span> gridvals) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb331-6"><a href="regression1.html#cb331-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">collect_metrics</span>() <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb331-7"><a href="regression1.html#cb331-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;rmse&quot;</span>) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb331-8"><a href="regression1.html#cb331-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(mean <span class="sc">==</span> <span class="fu">min</span>(mean))</span>
<span id="cb331-9"><a href="regression1.html#cb331-9" aria-hidden="true" tabindex="-1"></a>sacr_k <span class="ot">&lt;-</span> sacr_multi <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb331-10"><a href="regression1.html#cb331-10" aria-hidden="true" tabindex="-1"></a>              <span class="fu">pull</span>(neighbors)</span>
<span id="cb331-11"><a href="regression1.html#cb331-11" aria-hidden="true" tabindex="-1"></a>sacr_multi</span></code></pre></div>
<pre><code>## # A tibble: 1 x 7
##   neighbors .metric .estimator   mean     n std_err .config               
##       &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                 
## 1        17 rmse    standard   86294.     5   3524. Preprocessor1_Model017</code></pre>
<p>Here we see that the smallest estimated RMSPE from cross-validation occurs when <span class="math inline">\(K =\)</span> 17.
If we want to compare this multivariate KNN regression model to the model with only a single
predictor <em>as part of the model tuning process</em> (e.g., if we are running forward selection as described
in the chapter on evaluating and tuning classification models),
then we must compare the accuracy estimated using only the training data via cross-validation.
Looking back, the estimated cross-validation accuracy for the single-predictor
model was 87,362.
The estimated cross validation accuracy for the multivariate model is
86,294.
Thus in this case, we did not improve the model
by a large amount by adding this additional predictor.</p>
<p>Regardless, let’s continue the analysis to see how we can make predictions with a multivariate KNN regression model
and evaluate its performance on test data. We first need to re-train the model on the entire
training data set with <span class="math inline">\(K =\)</span> 17, and then use that model to make predictions
on the test data.</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="regression1.html#cb333-1" aria-hidden="true" tabindex="-1"></a>sacr_spec <span class="ot">&lt;-</span> <span class="fu">nearest_neighbor</span>(<span class="at">weight_func =</span> <span class="st">&quot;rectangular&quot;</span>, <span class="at">neighbors =</span> sacr_k) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb333-2"><a href="regression1.html#cb333-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;kknn&quot;</span>) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb333-3"><a href="regression1.html#cb333-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb333-4"><a href="regression1.html#cb333-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-5"><a href="regression1.html#cb333-5" aria-hidden="true" tabindex="-1"></a>knn_mult_fit <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb333-6"><a href="regression1.html#cb333-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(sacr_recipe) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb333-7"><a href="regression1.html#cb333-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(sacr_spec) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb333-8"><a href="regression1.html#cb333-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> sacramento_train)</span>
<span id="cb333-9"><a href="regression1.html#cb333-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-10"><a href="regression1.html#cb333-10" aria-hidden="true" tabindex="-1"></a>knn_mult_preds <span class="ot">&lt;-</span> knn_mult_fit <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb333-11"><a href="regression1.html#cb333-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(sacramento_test) <span class="sc">|</span><span class="er">&gt;</span></span>
<span id="cb333-12"><a href="regression1.html#cb333-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(sacramento_test)</span>
<span id="cb333-13"><a href="regression1.html#cb333-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb333-14"><a href="regression1.html#cb333-14" aria-hidden="true" tabindex="-1"></a>knn_mult_mets <span class="ot">&lt;-</span> <span class="fu">metrics</span>(knn_mult_preds, <span class="at">truth =</span> price, <span class="at">estimate =</span> .pred) <span class="sc">%&gt;%</span></span>
<span id="cb333-15"><a href="regression1.html#cb333-15" aria-hidden="true" tabindex="-1"></a>                     <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&#39;rmse&#39;</span>)</span>
<span id="cb333-16"><a href="regression1.html#cb333-16" aria-hidden="true" tabindex="-1"></a>knn_mult_mets</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard      79030.</code></pre>
This time when we performed KNN regression on the same data set, but also
included number of bedrooms as a predictor, we obtained a RMSPE test error
of 79,030.
Figure <a href="regression1.html#fig:07-knn-mult-viz">8.10</a> visualizes the model’s predictions overlaid on top of the data. This
time the predictions are a surface in 3-D space, instead of a line in 2-D space, as we have 2
predictors instead of 1.<br />

<div class="figure"><span id="fig:07-knn-mult-viz"></span>
<div id="htmlwidget-ef82a92d3343481a1724" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-ef82a92d3343481a1724">{"x":{"visdat":{"628d43fb":["function () ","plotlyVisDat"],"67969da0c":["function () ","data"]},"cur_data":"67969da0c","attrs":{"67969da0c":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","marker":{"size":5,"opacity":0.4,"color":"red"},"inherit":true},"67969da0c.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"z":{},"type":"surface","x":{},"y":{},"colorbar":{"title":"Price (USD)"},"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"House size (square feet)"},"zaxis":{"title":"Price (USD)"},"yaxis":{"title":"Number of bedrooms"}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"showSendToCloud":false},"data":[{"x":[836,1167,796,852,797,1122,1104,1177,1146,909,871,1020,1022,1134,844,795,1356,1118,1240,901,963,1380,1248,1039,1152,1380,1039,1418,1082,1472,1146,795,1099,840,746,1067,1316,1337,868,924,610,1220,722,1643,1080,1039,1051,967,1098,1050,1110,888,957,952,1264,1080,1266,994,1039,1448,1188,1183,1320,1117,1364,1310,1104,810,1123,840,484,970,623,796,834,924,795,1250,984,1013,795,918,1082,964,1404,625,888,1120,1331,1014,1448,966,836,1100,1174,1207,1995,804,901,1080,1104,1390,1354,795,780,1587,1139,1690,1245,1416,1300,1120,1590,1407,1516,1676,1370,1370,1000,1032,1080,990,900,861,906,1011,832,800,1292,1064,911,846,1320,1115,1169,1164,1341,1219,1127,1272,1253,1120,1400,1264,1060,1132,1466,1092,960,1512,933,864,1092,1139,1058,1040,1354,1051,682,1161,1004,1229,1161,1010,1005,1462,1269,1188,1570,1093,1309,1000,1285,1392,924,1217,1056,1043,1580,1656,1188,1590,1463,1714,1185,1406,1172,1851,1215,1130,1603,1479,1420,1280,1586,1266,1715,1820,1665,1511,1590,904,1156,1392,1439,1159,1740,1265,1007,1716,1685,1829,1137,1174,1393,1415,2126,1289,1308,1953,723,1376,948,1360,1351,1152,1452,990,1162,1182,1112,1100,1280,1039,1159,1917,1436,1451,1638,1000,1154,1329,1009,1144,930,1766,1940,1776,1872,1112,1856,998,1758,2142,950,1428,1358,2475,1711,1483,1140,1549,1410,1240,1712,1580,1669,1103,1650,1200,1695,1410,1174,1593,1093,1770,1139,1328,1273,1082,1578,1386,1513,1578,1736,1498,1473,1127,1144,972,2306,1430,1800,1232,984,1462,2329,1351,1284,1376,1300,1566,1115,1419,1261,1302,1488,1373,1381,1265,881,1917,1608,1344,1202,1104,1057,1859,1232,1638,904,1340,1477,1194,1428,1039,1529,1887,1294,1677,1073,1231,1175,1416,936,1358,1609,1968,1189,795,1262,1740,1517,1450,1416,888,1882,1418,1319,1770,1596,1341,2136,1478,1287,2235,2093,1193,2163,1473,958,2508,1305,1591,1843,1921,2790,1672,1380,2372,1446,1284,3009,3612,1993,1857,1126,2494,1843,1520,2800,1360,1751,1465,1605,1475,1216,1315,2187,1291,1129,1453,2491,1269,1498,2085,2170,1595,1567,2943,1768,1980,2030,1531,1750,1653,2056,2494,1440,1527,1401,1329,1910,1981,1739,988,1555,1212,1302,2026,1375,1250,1187,1324,2382,1427,1678,1798,1816,3076,1176,1182,1160,1574,1830,1724,1255,1718,1904,1808,2711,1713,1457,2724,1847,1468,2550,1343,1510,1624,2109,1524,1876,2489,1851,1776,1338,1257,2254,1441,2126,1094,2258,1074,1686,2367,1962,1406,1789,1876,1235,2504,2029,1676,1367,1899,1636,1828,1771,1438,1451,1520,1506,2605,1196,1811,1540,2647,2750,1910,1846,1543,1650,2214,1582,1857,1735,2096,1720,2160,1382,1282,1721,1328,1919,1144,1623,1457,2555,2592,1401,1040,960,1197,1456,1358,1329,1715,1262,2280,1477,1216,1685,1362,2367,3516,2536,1690,1801,1961,3134,1915,1638,2734,2110,3599,2054,1627,3440,2846,3714,2687,2724,3440,3508,2462,2900,3705,3527,2325,4878,1665,3072,1449,539,2208,1108,1595,2159,2295,1900,3389,2190,3260,2607,2724,3969,3192,2829,3928,3577,2068,2129,3992,3167,1598,1929,3070,2272,2791,3117,2544,3984,3838,3059,2484,1624,1829,2218,1394,2346,2347,1659,2442,2590,2155,1673,2789,1606,3499,2166,1119,1871,1800,1683,1625,2752,1596,2716,1179,2724,1993,2548,1744,1939,2376,1788,1691,4303,4246,2274,2962,3056,3198,3332,1905,1873,3157,3037,3741,2660,3357,2896,3670,2048,1327,2169,2457,2264,2004,2212,3134,1360,1951,1276,2962,2155,1744,1548,2109,1616,2372,2877,2960,2172,1795,1924,2295,2577,2616,1727,1485,1655,3179,3479,2049,3042,3566,2199,2242,1304,2334,1493,3913,3151,2787,2824,3261,2053,2379,2480,1704,2418,3282,4091,2806,3380,1348,1252,3863,3901,2346,2356,3579,3464,3885,3782,4400],"y":[2,3,2,2,2,3,3,3,3,3,1,3,2,2,2,2,3,3,4,3,3,4,3,2,3,3,2,3,3,4,4,2,4,2,2,3,4,3,2,3,2,2,1,3,3,3,3,2,3,3,3,3,3,2,3,3,3,2,2,4,3,4,3,3,3,4,3,2,2,2,1,3,2,2,2,2,2,3,2,3,2,2,3,2,4,1,2,4,3,3,4,3,2,2,3,3,4,2,2,3,3,4,4,2,2,4,2,2,3,3,3,3,4,3,5,3,3,3,1,2,2,2,2,2,2,2,2,2,4,4,2,1,3,3,3,3,4,3,4,3,4,3,3,3,3,2,3,3,3,4,2,2,3,2,3,3,3,3,1,3,3,3,3,3,2,4,3,2,4,3,4,3,3,4,2,3,3,2,4,4,3,4,3,4,3,3,3,4,3,3,4,3,3,3,3,3,4,3,2,3,4,2,3,3,3,3,3,3,2,3,4,4,3,3,3,3,4,3,3,4,2,2,2,3,4,3,3,2,2,3,2,3,4,3,3,4,3,3,4,2,3,3,3,3,2,4,4,4,4,2,4,3,3,3,2,3,4,6,3,4,3,4,3,3,5,4,3,3,3,3,4,3,3,3,3,3,4,3,3,3,4,3,3,4,4,2,3,3,3,3,4,3,4,3,1,3,4,3,3,4,3,4,2,4,3,3,3,3,4,3,2,4,4,3,3,3,2,4,3,3,2,3,4,1,3,3,3,4,3,3,3,3,3,3,1,3,4,4,2,2,3,4,3,3,3,3,3,3,4,4,4,2,5,3,3,4,3,3,3,3,3,5,3,4,3,4,5,3,3,4,3,2,4,8,4,3,2,5,3,2,5,3,4,3,4,4,3,2,3,3,2,3,4,2,3,5,3,4,3,4,4,4,4,3,4,4,4,4,3,3,3,3,4,3,4,3,4,3,3,4,3,2,3,2,5,3,3,4,4,5,4,4,3,4,3,4,2,3,4,4,4,3,3,4,3,3,4,3,3,3,4,4,4,5,4,4,3,2,5,3,4,3,5,3,3,4,3,2,3,4,3,4,3,3,3,4,3,3,3,4,3,3,3,4,3,3,3,4,2,3,4,3,3,4,4,3,3,4,3,4,4,3,4,4,3,2,2,3,6,5,3,3,3,3,3,3,4,4,3,4,3,3,4,3,5,5,4,2,4,3,4,4,3,4,3,5,4,3,4,3,6,5,4,4,5,4,5,4,4,3,6,3,5,2,2,4,3,4,4,4,4,5,4,5,4,4,5,4,3,5,5,3,3,4,5,2,4,4,4,3,5,3,5,4,4,5,4,3,4,3,5,5,4,3,4,4,3,4,4,5,4,2,4,3,3,3,4,2,4,3,5,3,3,4,4,4,2,3,4,5,3,4,4,3,4,3,2,5,4,5,4,4,5,5,4,3,4,5,3,4,4,5,3,4,3,4,3,3,3,4,3,4,5,3,3,3,3,4,4,5,3,3,3,5,5,3,4,5,4,4,2,3,3,5,5,5,5,4,4,4,3,3,3,4,5,4,4,3,2,5,5,4,4,5,5,3,4,4],"z":[59222,68212,68880,69307,81900,89921,90895,91002,98937,100309,106852,107502,108750,110700,113263,116250,121630,122000,123000,125000,127281,131200,132000,133000,134555,136500,141000,146250,147308,148750,149593,69000,70000,71000,78400,80000,89000,90000,90000,92000,93675,98000,98000,99000,106716,111000,111000,114800,120108,123225,123750,125000,129000,134000,135500,140000,140000,142500,145000,145000,145000,146000,148500,149000,150000,150000,156000,156000,156000,40000,48000,61500,62050,65000,68000,77000,82732,84000,84675,85000,90000,91000,95000,97500,100000,100000,101000,102750,112500,113000,114000,114000,115000,115000,116100,119250,120000,120000,121500,122000,123000,125573,126714,126960,127000,127500,133105,136500,139500,140000,140800,145000,147000,149600,150000,155000,155435,155500,30000,65000,65000,66500,71000,75000,77000,85000,96140,104250,105000,109000,115000,115000,115500,116000,122000,122500,123000,124000,124000,124413,125000,130000,138000,140000,145000,145000,150000,150000,155000,56950,62000,68566,85500,93600,95000,97750,104000,105000,107666,109000,110000,110000,114800,116000,119000,121500,122000,123675,126854,127059,131750,134000,143012,150000,150454,151087,156896,161250,165000,166357,170000,173000,174250,174313,178480,178760,181000,182587,182716,182750,183200,188741,189000,192067,194000,198000,199500,200000,206000,208000,212864,157788,161653,165000,168000,169000,176250,179000,180000,180400,182000,184500,194000,195000,200000,201000,202500,205000,205000,205000,207000,210000,211500,215500,158000,158000,160000,160000,164000,164000,165000,167000,167293,168000,170000,170000,180000,180000,180000,182000,191500,192700,198000,200345,203000,207000,208000,210000,213675,213697,215000,215100,217500,218000,220000,156142,158000,159900,161500,161600,162000,165000,165000,167293,168000,168000,168750,170000,173000,176095,179000,180000,180000,181000,182000,182587,186785,188335,190000,190000,190000,191250,193500,195000,195000,195000,195000,199900,200000,201000,204918,205878,207000,210000,210944,212500,213750,215000,215000,215000,216033,220000,220000,220000,220000,157500,160000,160000,161250,164000,165000,165000,165750,166000,169000,170000,170000,170000,170000,170725,173056,174000,176850,188000,188700,189000,189000,190000,191250,195500,198000,200000,200000,200000,200100,201528,204750,205000,207000,207973,209347,211500,212000,213000,216000,216021,219000,220000,220000,220000,221000,221000,223058,231477,234697,236685,237800,240122,242638,244500,244960,245918,250000,250000,254200,254200,258000,265000,265000,273750,275086,280908,280987,282400,287417,291000,292024,297000,298000,299000,304037,222381,225000,225000,228000,229665,230000,230000,235000,236250,240000,242000,245000,245000,250000,256054,257729,260000,261000,261800,265000,270000,270000,270000,270000,275000,275000,280000,292000,293993,294000,300000,300500,305000,221000,223139,225500,228327,230000,231200,232000,232500,234000,234500,236000,236073,238000,238861,240000,240000,247234,247480,249862,252155,254172,258000,260000,261000,261000,262500,266000,266000,270000,274425,274500,275336,277980,284893,285000,289000,296000,296056,299940,304000,305000,221250,222000,222500,222750,225000,228750,229000,232500,233000,239000,240000,240971,242000,243450,243500,246544,246750,247000,247000,249000,249000,250000,250000,250000,252000,255000,255000,255000,257200,260000,263500,266510,267750,270000,271000,272700,275000,276500,278000,280000,285000,288000,289000,290000,290000,293996,294000,294173,295000,298000,299000,300000,300000,300000,303000,305000,224000,224252,224500,225000,229027,229500,230000,230000,232425,234000,235000,235301,235738,315537,320000,320000,334150,346210,347029,347650,351300,370000,370500,372000,381300,381942,391000,394470,395000,445000,460000,461000,489332,510000,539000,585000,600000,606238,660000,830000,312500,315000,330000,334000,336000,339000,339000,345000,350000,361745,370000,380000,385000,402000,406026,425000,425000,433500,436746,438700,460000,460000,460000,480000,484000,485000,495000,500500,504000,541000,560000,572500,613401,614000,699000,839000,307000,311328,313138,320000,325000,328578,331000,331500,340000,344755,351000,353767,355000,356035,360000,360552,362305,365000,367554,368500,370000,371086,378000,383000,400000,413000,416767,423000,423000,427500,430922,450000,452000,470000,471000,475000,487500,488750,500000,512000,520000,528000,579093,636000,668365,676200,760000,306000,310000,311518,312000,313000,315000,315000,315000,315000,315000,320000,322000,325500,326951,328370,330000,335000,341000,349000,350000,350000,351000,356200,360000,367463,375000,380000,380578,386222,389000,390000,395500,396000,400000,400000,412500,413500,415000,425000,433500,438000,441000,445000,446000,450000,455000,460000,475000,490000,493000,508000,511000,533000,545000,575000,598695,600000,600000,600000,610000,622500,680000,879000,884790],"type":"scatter3d","mode":"markers","marker":{"color":"red","size":5,"opacity":0.4,"line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"Price (USD)","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"z":[[131391,131391,131391,119582.588235294,102373.764705882,130559.764705882,121312.470588235,160369.588235294,168513.941176471,181821.764705882,195204.117647059,214238.941176471,226208.588235294,261473.294117647,268943.882352941,275011.411764706,275011.411764706,276240.823529412,279123.176470588,279714.705882353,291744.117647059,291744.117647059,291744.117647059,291744.117647059,291744.117647059,291744.117647059,330979.411764706,354950,381302.941176471,390773.529411765,390773.529411765,400008.823529412,411185.294117647,411185.294117647,423479.411764706,454273.529411765,454273.529411765,462264.705882353,462264.705882353,462264.705882353,462264.705882353,463000,509481.823529412,509481.823529412,515952.411764706,515952.411764706,532142.882352941,532142.882352941,528288.176470588,524131.235294118],[131391,131391,131391,119582.588235294,102373.764705882,130559.764705882,121312.470588235,160369.588235294,178778.647058824,212821.764705882,203733.529411765,233317.411764706,232796.823529412,275011.411764706,276240.823529412,276240.823529412,277626.470588235,289391.176470588,291744.117647059,291744.117647059,291744.117647059,291744.117647059,291744.117647059,291744.117647059,291744.117647059,332273.529411765,350567.647058824,381302.941176471,390773.529411765,390773.529411765,411185.294117647,411185.294117647,411185.294117647,423479.411764706,442647.058823529,462264.705882353,462264.705882353,462264.705882353,462264.705882353,455529.411764706,464176.470588235,509481.823529412,509481.823529412,515952.411764706,515952.411764706,532142.882352941,532142.882352941,528288.176470588,524131.235294118,531190.058823529],[127170.411764706,127170.411764706,131391,119582.588235294,102373.764705882,130559.764705882,125488.941176471,171663.705882353,190484.529411765,227282.588235294,216194.352941176,261114.823529412,259917.294117647,289391.176470588,289391.176470588,289391.176470588,289391.176470588,289391.176470588,291744.117647059,291744.117647059,291744.117647059,291744.117647059,294214.705882353,294214.705882353,340773.529411765,362920.588235294,364097.058823529,390773.529411765,388479.411764706,388832.352941176,411185.294117647,423479.411764706,442647.058823529,462264.705882353,462264.705882353,462264.705882353,462264.705882353,455529.411764706,455529.411764706,455529.411764706,468964.764705882,509481.823529412,515952.411764706,515952.411764706,532142.882352941,528288.176470588,528288.176470588,524131.235294118,531190.058823529,531190.058823529],[122813.294117647,120378.529411765,127170.411764706,112582.588235294,98558.4705882353,135618.588235294,133464.470588235,176554.235294118,199595.529411765,234266.294117647,263347.529411765,274788.705882353,283597.058823529,289391.176470588,302655.882352941,302655.882352941,302655.882352941,302655.882352941,294214.705882353,294214.705882353,294214.705882353,294214.705882353,294214.705882353,338185.294117647,366744.117647059,379685.294117647,381567.647058824,388832.352941176,395597.058823529,395597.058823529,442647.058823529,462264.705882353,462264.705882353,462264.705882353,462264.705882353,455529.411764706,455529.411764706,455529.411764706,455529.411764706,494200.058823529,509481.823529412,515952.411764706,515952.411764706,532142.882352941,528288.176470588,528288.176470588,524131.235294118,531190.058823529,531190.058823529,531190.058823529],[115474.705882353,119710,119710,109734.411764706,93744,128094,124910.294117647,182551.529411765,211594.352941176,250504.882352941,264465.176470588,279024,289062.235294118,302655.882352941,302655.882352941,302655.882352941,302655.882352941,302655.882352941,294214.705882353,294214.705882353,294214.705882353,294214.705882353,313420.588235294,359891.176470588,366802.941176471,381567.647058824,388832.352941176,395597.058823529,422302.941176471,462264.705882353,462264.705882353,462264.705882353,455529.411764706,455529.411764706,455529.411764706,455529.411764706,455529.411764706,455529.411764706,494200.058823529,492729.470588235,509481.823529412,515952.411764706,532142.882352941,528288.176470588,533868.294117647,524131.235294118,531190.058823529,531190.058823529,531190.058823529,531190.058823529],[119710,119710,119710,109734.411764706,93744,128094,124910.294117647,182551.529411765,211594.352941176,250504.882352941,264465.176470588,279024,289062.235294118,302655.882352941,302655.882352941,302655.882352941,302655.882352941,302655.882352941,294214.705882353,294214.705882353,294214.705882353,330126.470588235,359891.176470588,364891.176470588,389802.941176471,384567.647058824,422302.941176471,440676.470588235,440676.470588235,462264.705882353,455529.411764706,455529.411764706,455529.411764706,455529.411764706,455529.411764706,455529.411764706,455529.411764706,477117.647058824,490670.647058824,492729.470588235,515952.411764706,532142.882352941,533868.294117647,524131.235294118,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529],[119710,119710,119710,109734.411764706,93744,128094,124910.294117647,182551.529411765,211594.352941176,250504.882352941,264465.176470588,279024,289062.235294118,302655.882352941,302655.882352941,302655.882352941,302655.882352941,302655.882352941,294214.705882353,294214.705882353,338773.529411765,366479.411764706,392244.117647059,404302.941176471,405744.117647059,421273.529411765,440676.470588235,440676.470588235,440676.470588235,455529.411764706,455529.411764706,455529.411764706,455529.411764706,439235.294117647,439235.294117647,439235.294117647,460705.882352941,502435.352941176,501919.941176471,515952.411764706,532142.882352941,528288.176470588,524131.235294118,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529],[119710,119710,119710,109734.411764706,93744,128094,124910.294117647,182551.529411765,211594.352941176,250504.882352941,264465.176470588,279024,289062.235294118,302655.882352941,302655.882352941,302655.882352941,302655.882352941,302655.882352941,294214.705882353,303463.470588235,351597.058823529,396420.588235294,398950,419097.058823529,425823.529411765,440676.470588235,440676.470588235,429352.941176471,429352.941176471,455529.411764706,439235.294117647,439235.294117647,439235.294117647,439235.294117647,439235.294117647,460705.882352941,502435.352941176,501919.941176471,501919.941176471,532142.882352941,533868.294117647,524131.235294118,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,540858.588235294],[119710,119710,119710,109734.411764706,93744,128094,124910.294117647,182551.529411765,211594.352941176,250504.882352941,264465.176470588,279024,289062.235294118,302655.882352941,302655.882352941,302655.882352941,302655.882352941,301861.764705882,331526.470588235,303706.882352941,351971.588235294,387244.117647059,396021.588235294,425823.529411765,421264.705882353,429352.941176471,429352.941176471,419823.529411765,419823.529411765,439235.294117647,439235.294117647,439235.294117647,439235.294117647,439235.294117647,439235.294117647,477955.176470588,499272.882352941,501919.941176471,503300.529411765,528288.176470588,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,540858.588235294,540858.588235294,540858.588235294],[119710,119710,119710,109734.411764706,93744,128094,124910.294117647,182551.529411765,211594.352941176,250504.882352941,264465.176470588,279024,289062.235294118,302655.882352941,302655.882352941,302655.882352941,322373.529411765,332920.588235294,336975.764705882,326930.411764706,373492.176470588,396021.588235294,383698.058823529,399992.176470588,406307.588235294,419823.529411765,419823.529411765,419823.529411765,419823.529411765,439235.294117647,439235.294117647,439235.294117647,439235.294117647,439235.294117647,461072.823529412,491974.705882353,498065.235294118,505614.176470588,505025.941176471,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,540858.588235294,553726.235294118,553726.235294118,557226.235294118],[119710,119710,119710,109734.411764706,93744,128094,124910.294117647,182551.529411765,211594.352941176,250504.882352941,264465.176470588,279024,289062.235294118,300168.941176471,310167.705882353,304148.352941176,311991.176470588,343567.647058824,334508.117647059,363009.823529412,370451,380639.235294118,380639.235294118,399992.176470588,406307.588235294,419823.529411765,419823.529411765,419823.529411765,419823.529411765,439235.294117647,439235.294117647,439235.294117647,439235.294117647,448615.882352941,467002.352941176,490767.058823529,505614.176470588,509908.294117647,531190.058823529,531190.058823529,531190.058823529,531190.058823529,531190.058823529,554623.294117647,553726.235294118,553726.235294118,553726.235294118,557226.235294118,557226.235294118,560226.235294118],[132551.176470588,132551.176470588,138614.588235294,152797.764705882,152797.764705882,152797.764705882,139086.647058824,155327.882352941,190092.764705882,208530.705882353,209878.941176471,227551.882352941,250139.588235294,262441.529411765,277621.176470588,264894.941176471,303004.235294118,332529.411764706,318068.647058824,356421.588235294,370451,386639.235294118,394403.941176471,399992.176470588,406307.588235294,419823.529411765,419823.529411765,419823.529411765,419823.529411765,439235.294117647,439235.294117647,439235.294117647,464727.352941176,462694.235294118,470414.117647059,509908.294117647,509908.294117647,520738.588235294,531190.058823529,531190.058823529,554623.294117647,554623.294117647,553726.235294118,553726.235294118,553726.235294118,557226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118],[152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,139086.647058824,155327.882352941,190092.764705882,208530.705882353,209878.941176471,227551.882352941,250139.588235294,262441.529411765,277621.176470588,264894.941176471,303004.235294118,332529.411764706,318068.647058824,356421.588235294,370451,386639.235294118,394403.941176471,403256.882352941,404698.058823529,419823.529411765,419823.529411765,419823.529411765,419823.529411765,439235.294117647,439235.294117647,451647.058823529,478771.470588235,474435.588235294,490185.588235294,517973.882352941,520738.588235294,531326.823529412,554623.294117647,554623.294117647,553726.235294118,553726.235294118,557226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118],[152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,139086.647058824,155327.882352941,190092.764705882,208530.705882353,209878.941176471,227551.882352941,250139.588235294,262441.529411765,277621.176470588,264894.941176471,303004.235294118,332529.411764706,318068.647058824,356421.588235294,370451,386639.235294118,394403.941176471,403256.882352941,404698.058823529,419101.705882353,419101.705882353,419823.529411765,419823.529411765,439235.294117647,450411.764705882,449514.705882353,467701,494244.411764706,533032.705882353,533032.705882353,533856.235294118,531326.823529412,553726.235294118,553726.235294118,557226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,566226.235294118],[152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,139086.647058824,155327.882352941,190092.764705882,208530.705882353,209878.941176471,227551.882352941,250139.588235294,262441.529411765,277621.176470588,264894.941176471,303004.235294118,332529.411764706,318068.647058824,356421.588235294,370451,386639.235294118,394403.941176471,403256.882352941,404698.058823529,419101.705882353,419101.705882353,419101.705882353,418822.764705882,474764.705882353,466155.882352941,471515.588235294,492185.588235294,490694.411764706,533032.705882353,533032.705882353,533856.235294118,530679.764705882,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,560226.235294118,564638,566226.235294118,566226.235294118,566226.235294118],[152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,139086.647058824,155327.882352941,190092.764705882,208530.705882353,209878.941176471,227551.882352941,250139.588235294,262441.529411765,277621.176470588,264894.941176471,303004.235294118,332529.411764706,318068.647058824,356421.588235294,370451,386639.235294118,394403.941176471,403256.882352941,404698.058823529,419101.705882353,419101.705882353,431576.470588235,440999.235294118,444743.352941176,460155.882352941,476974.529411765,484517.941176471,490694.411764706,533032.705882353,530444.470588235,529944.470588235,560226.235294118,560226.235294118,560226.235294118,560226.235294118,564638,564638,564638,564638,564638,566226.235294118,566226.235294118,569873.294117647,569873.294117647],[152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,139086.647058824,155327.882352941,190092.764705882,208530.705882353,209878.941176471,227551.882352941,250139.588235294,262441.529411765,277621.176470588,264894.941176471,303004.235294118,332529.411764706,318068.647058824,356421.588235294,370451,386639.235294118,394403.941176471,403256.882352941,404698.058823529,436673.588235294,445294.117647059,420575.705882353,438046.294117647,441037.470588235,460456,472915.705882353,484517.941176471,512753.235294118,523335.647058824,527159.176470588,527159.176470588,564638,564638,564638,564638,564638,564638,564638,564638,566226.235294118,566226.235294118,569873.294117647,569873.294117647,570873.294117647],[152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,152797.764705882,139086.647058824,155327.882352941,190092.764705882,208530.705882353,209878.941176471,227551.882352941,250139.588235294,262441.529411765,277621.176470588,264894.941176471,303004.235294118,332529.411764706,318068.647058824,356421.588235294,370451,386639.235294118,387462.764705882,411070.176470588,422906.647058824,400296.294117647,397461,426134.529411765,429261,425437.470588235,462161.882352941,465414.941176471,484547.352941176,529253.235294118,535688.588235294,535688.588235294,533041.529411765,564638,564638,564638,564638,564638,564638,564638,566226.235294118,567432.117647059,567432.117647059,570873.294117647,570873.294117647,567814.235294118],[152738.941176471,148974.235294118,148974.235294118,136533.705882353,148716.764705882,151684.941176471,146699.117647059,146699.117647059,157640.294117647,159335.705882353,179307.823529412,175437.647058824,205698.411764706,270041.352941176,235147.235294118,245486.764705882,276227.058823529,294221.117647059,310761.470588235,315842.117647059,351241.529411765,368873.117647059,353611.352941176,350557.588235294,347304.705882353,367025.294117647,369310.235294118,409254.352941176,419084.529411765,456267.764705882,454993.176470588,479517.176470588,480487.764705882,532688.588235294,535688.588235294,535688.588235294,533041.529411765,556411.529411765,556411.529411765,564638,564638,564638,564638,567432.117647059,567432.117647059,574873.294117647,570873.294117647,567814.235294118,553998.647058823,557939.823529412],[151184.235294118,151184.235294118,142245.411764706,148582.705882353,146699.117647059,146699.117647059,146699.117647059,146699.117647059,157640.294117647,159335.705882353,179307.823529412,175437.647058824,205698.411764706,270041.352941176,235147.235294118,245486.764705882,276227.058823529,294221.117647059,310761.470588235,315842.117647059,351241.529411765,368873.117647059,353611.352941176,350557.588235294,347304.705882353,367025.294117647,369310.235294118,409254.352941176,415850.764705882,456267.764705882,449413.058823529,479517.176470588,487105.411764706,527306.235294118,531070.941176471,531070.941176471,533482.705882353,556411.529411765,556411.529411765,556411.529411765,556411.529411765,556411.529411765,567432.117647059,567432.117647059,570873.294117647,567814.235294118,553998.647058823,557939.823529412,557939.823529412,557939.823529412],[145262.647058824,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,157640.294117647,159335.705882353,179307.823529412,175437.647058824,205698.411764706,270041.352941176,235147.235294118,245486.764705882,276227.058823529,294221.117647059,310761.470588235,315842.117647059,351241.529411765,368873.117647059,353611.352941176,354513.470588235,347304.705882353,367025.294117647,369310.235294118,409254.352941176,415850.764705882,456267.764705882,454993.176470588,470752.470588235,487105.411764706,527306.235294118,531070.941176471,531070.941176471,529600.352941177,556411.529411765,556411.529411765,556411.529411765,565843.882352941,567432.117647059,574873.294117647,570873.294117647,553998.647058823,557939.823529412,557939.823529412,569953.058823529,569953.058823529,569953.058823529],[146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,157640.294117647,159335.705882353,179307.823529412,175437.647058824,205698.411764706,270041.352941176,235147.235294118,245486.764705882,276227.058823529,294221.117647059,310761.470588235,315842.117647059,351241.529411765,368873.117647059,353611.352941176,354513.470588235,347304.705882353,367025.294117647,369310.235294118,409254.352941176,419084.529411765,456267.764705882,449413.058823529,479517.176470588,487105.411764706,527306.235294118,531070.941176471,531070.941176471,529600.352941177,545529.176470588,556411.529411765,554638,559520.352941177,556564.235294118,549292.764705882,557939.823529412,557939.823529412,569953.058823529,569953.058823529,569953.058823529,575233.117647059,575233.117647059],[146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,157640.294117647,159335.705882353,179307.823529412,175437.647058824,205698.411764706,270041.352941176,235147.235294118,245486.764705882,276227.058823529,294221.117647059,310761.470588235,315842.117647059,351241.529411765,368873.117647059,353611.352941176,350557.588235294,347304.705882353,367025.294117647,369310.235294118,409254.352941176,415850.764705882,456267.764705882,454993.176470588,470752.470588235,487105.411764706,527306.235294118,531070.941176471,531070.941176471,529600.352941177,550475.823529412,566973,560887.764705882,562020.117647059,553157.176470588,553157.176470588,553157.176470588,564017.352941177,564017.352941177,579939,575233.117647059,575233.117647059,575233.117647059],[146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,157640.294117647,159335.705882353,179307.823529412,175437.647058824,205698.411764706,270041.352941176,235147.235294118,245486.764705882,276227.058823529,294221.117647059,310761.470588235,315842.117647059,351241.529411765,368873.117647059,353611.352941176,354513.470588235,347304.705882353,367025.294117647,369310.235294118,409254.352941176,408109.529411765,456267.764705882,449413.058823529,470752.470588235,487105.411764706,527306.235294118,531070.941176471,522012.117647059,554526.411764706,548990.823529412,567355.117647059,560633.235294118,558437.235294118,558437.235294118,579939,579939,579939,579939,579939,579939,579939,579939],[146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,157640.294117647,159335.705882353,179307.823529412,175437.647058824,205698.411764706,270041.352941176,235147.235294118,245486.764705882,276227.058823529,294221.117647059,310761.470588235,315842.117647059,351241.529411765,368873.117647059,353611.352941176,354513.470588235,347304.705882353,367025.294117647,369310.235294118,409254.352941176,408109.529411765,456267.764705882,454993.176470588,479517.176470588,479694.411764706,474076.764705882,520309.176470588,545391.117647059,565387.882352941,555251.470588235,559616.058823529,579939,579939,579939,566707.352941177,566707.352941177,566707.352941177,566707.352941177,566707.352941177,566707.352941177,566707.352941177,593101.470588235],[146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,146699.117647059,149110.882352941,158673.941176471,182896.058823529,163584.941176471,189169,258747.235294118,230309,235041,269756.294117647,259936.529411765,287652.411764706,325085.411764706,319514.235294118,304739.235294118,342041.470588235,354323.058823529,392538.529411765,394798.823529412,399009.117647059,419955.117647059,415543.352941176,414778.647058824,434608.823529412,413911.764705882,439147.058823529,467564.294117647,482960.470588235,494443.176470588,496060.823529412,518090.235294118,538113.823529412,538113.823529412,566707.352941177,566707.352941177,566707.352941177,566707.352941177,566707.352941177,566707.352941177,566707.352941177,566707.352941177,593101.470588235,593101.470588235],[146699.117647059,146699.117647059,146699.117647059,142581.470588235,142581.470588235,142581.470588235,142581.470588235,142581.470588235,146052.058823529,160838.647058824,179837.235294118,163584.941176471,189525.117647059,253989.117647059,232212.647058824,248317.411764706,260935.235294118,278930.411764706,301401,311459.823529412,324106.882352941,324106.882352941,334986.058823529,354323.058823529,392538.529411765,392538.529411765,384303.235294118,419955.117647059,415543.352941176,414778.647058824,440041.176470588,413482.352941176,439147.058823529,467564.294117647,481722.823529412,484149.058823529,496060.823529412,489325.529411765,492972.588235294,492972.588235294,499149.058823529,528842.588235294,541395.588235294,541395.588235294,567295.588235294,567295.588235294,567295.588235294,580236.764705882,580236.764705882,580236.764705882],[142581.470588235,142581.470588235,142581.470588235,142581.470588235,142581.470588235,147228.529411765,147228.529411765,147228.529411765,146052.058823529,160838.647058824,179837.235294118,174675.470588235,193051.235294118,259462.647058824,249774.470588235,278312.764705882,281165.705882353,293224.529411765,293224.529411765,311459.823529412,324106.882352941,324106.882352941,334986.058823529,354323.058823529,392538.529411765,392538.529411765,384303.235294118,419955.117647059,415543.352941176,414778.647058824,440041.176470588,413482.352941176,439147.058823529,467564.294117647,481722.823529412,484149.058823529,496060.823529412,489325.529411765,492972.588235294,492972.588235294,492972.588235294,492972.588235294,520607.294117647,528842.588235294,528842.588235294,528842.588235294,554136.705882353,564413.235294118,564413.235294118,580236.764705882],[142581.470588235,142581.470588235,147228.529411765,147228.529411765,147228.529411765,147228.529411765,147228.529411765,147228.529411765,146052.058823529,163253.588235294,175843.823529412,186749,220729.882352941,278343.176470588,278783.352941176,293224.529411765,293224.529411765,293224.529411765,293224.529411765,311459.823529412,324106.882352941,324106.882352941,334986.058823529,354323.058823529,392538.529411765,392538.529411765,384303.235294118,419955.117647059,415543.352941176,414778.647058824,440041.176470588,413482.352941176,439147.058823529,467564.294117647,481722.823529412,484149.058823529,496060.823529412,489325.529411765,492972.588235294,492972.588235294,492972.588235294,492972.588235294,492972.588235294,520607.294117647,520607.294117647,550607.294117647,554136.705882353,554136.705882353,554136.705882353,554136.705882353],[147228.529411765,147228.529411765,147228.529411765,147228.529411765,147228.529411765,147228.529411765,147228.529411765,147228.529411765,160176.294117647,167080.529411765,181887.941176471,208603.764705882,264779.588235294,279304.352941176,293224.529411765,293224.529411765,293224.529411765,293224.529411765,293224.529411765,311459.823529412,324106.882352941,324106.882352941,334986.058823529,354323.058823529,392538.529411765,392538.529411765,384303.235294118,419955.117647059,415543.352941176,414778.647058824,440041.176470588,413482.352941176,439147.058823529,467564.294117647,481722.823529412,484149.058823529,496060.823529412,489325.529411765,492972.588235294,492972.588235294,492972.588235294,492972.588235294,492972.588235294,492972.588235294,520913.764705882,550607.294117647,550607.294117647,550607.294117647,550607.294117647,554136.705882353],[147228.529411765,147228.529411765,147228.529411765,147228.529411765,147228.529411765,147228.529411765,153467,158838.058823529,160176.294117647,177112.058823529,216701.058823529,271539.058823529,279548.058823529,293224.529411765,293224.529411765,293224.529411765,293224.529411765,293224.529411765,293224.529411765,311459.823529412,324106.882352941,324106.882352941,334986.058823529,354323.058823529,392538.529411765,392538.529411765,384303.235294118,419955.117647059,415543.352941176,414778.647058824,440041.176470588,413482.352941176,439147.058823529,467564.294117647,481722.823529412,484149.058823529,496060.823529412,489325.529411765,492972.588235294,492972.588235294,492972.588235294,492972.588235294,492972.588235294,517090.235294118,517090.235294118,517090.235294118,550313.176470588,553254.352941177,553254.352941177,553254.352941177],[147228.529411765,147228.529411765,147228.529411765,147228.529411765,147228.529411765,153467,158838.058823529,158838.058823529,175088.058823529,212173.058823529,273373.235294118,271498.058823529,280571.588235294,280571.588235294,280571.588235294,280571.588235294,280571.588235294,280571.588235294,293806.882352941,293806.882352941,310983.352941176,310983.352941176,318450.764705882,354323.058823529,392538.529411765,392538.529411765,384303.235294118,419955.117647059,415543.352941176,414778.647058824,440041.176470588,413482.352941176,439147.058823529,467564.294117647,472605.176470588,485325.529411765,496060.823529412,492560.823529412,498266.705882353,498266.705882353,498266.705882353,498266.705882353,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,550313.176470588,553254.352941177,553254.352941177],[147228.529411765,147228.529411765,147228.529411765,147228.529411765,153467,158838.058823529,165764.529411765,169600.235294118,216117.117647059,254578.941176471,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,301571.588235294,322976.764705882,337315,345403.235294118,387356.176470588,375356.176470588,414719.823529412,415543.352941176,414778.647058824,440041.176470588,413482.352941176,442894.117647059,459676.470588235,472605.176470588,485325.529411765,488560.823529412,492560.823529412,498266.705882353,498266.705882353,498266.705882353,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,550313.176470588,550313.176470588],[147228.529411765,147228.529411765,153467,158838.058823529,158838.058823529,169600.235294118,169600.235294118,197113.352941176,234383.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,301571.588235294,322976.764705882,337315,345403.235294118,387356.176470588,375356.176470588,395890.411764706,397419.823529412,394125.705882353,432982.352941176,413852.941176471,442894.117647059,459676.470588235,472605.176470588,485325.529411765,488560.823529412,492560.823529412,498266.705882353,498266.705882353,498266.705882353,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118],[147228.529411765,153467,158838.058823529,158838.058823529,169600.235294118,171653.176470588,197113.352941176,217902,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,301571.588235294,322976.764705882,337315,345403.235294118,387356.176470588,375356.176470588,395890.411764706,397655.117647059,405125.705882353,419447.058823529,407970.588235294,442894.117647059,459676.470588235,472605.176470588,485325.529411765,488560.823529412,492560.823529412,498266.705882353,498266.705882353,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118],[153467,158838.058823529,158838.058823529,169600.235294118,171653.176470588,200878.058823529,205960.823529412,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,301571.588235294,322976.764705882,337315,345403.235294118,387356.176470588,375356.176470588,391478.647058824,397655.117647059,405125.705882353,419447.058823529,398552.941176471,428717.647058824,459676.470588235,472605.176470588,485325.529411765,488560.823529412,492560.823529412,498266.705882353,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118],[158838.058823529,158838.058823529,171653.176470588,182064.941176471,200878.058823529,205960.823529412,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,301571.588235294,322976.764705882,337315,345403.235294118,387356.176470588,387066.882352941,391478.647058824,397655.117647059,405125.705882353,419447.058823529,398552.941176471,402241.176470588,430376.470588235,462016.941176471,485325.529411765,488560.823529412,492560.823529412,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118],[162067.470588235,171653.176470588,182064.941176471,196860.235294118,205960.823529412,258988.176470588,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,301571.588235294,322976.764705882,337315,345403.235294118,372415,387066.882352941,391478.647058824,397655.117647059,405125.705882353,419447.058823529,398552.941176471,402241.176470588,430376.470588235,448540.470588235,477281.647058824,488560.823529412,492560.823529412,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118],[182064.941176471,182064.941176471,196860.235294118,205960.823529412,213326.411764706,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,301571.588235294,322976.764705882,337315,357697.352941176,372415,387066.882352941,391478.647058824,397655.117647059,405125.705882353,419447.058823529,398552.941176471,402241.176470588,430376.470588235,448540.470588235,461187.529411765,488560.823529412,520502,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118,517090.235294118],[182064.941176471,196860.235294118,205960.823529412,213326.411764706,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,301571.588235294,322976.764705882,348315,357697.352941176,372415,387066.882352941,391478.647058824,397655.117647059,403852.941176471,415529.411764706,385164.705882353,393047.058823529,418752.941176471,429934.882352941,442505.176470588,487084.352941176,507113.764705882,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235],[196860.235294118,205960.823529412,205960.823529412,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,301571.588235294,326623.823529412,348315,357697.352941176,371144.411764706,371855.117647059,382325.705882353,399090.411764706,403852.941176471,415529.411764706,385164.705882353,393047.058823529,418752.941176471,429934.882352941,456111.352941176,470799.294117647,494878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235],[205960.823529412,205960.823529412,272341.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,301571.588235294,301571.588235294,312686.058823529,316176.764705882,338985.588235294,353779.705882353,371144.411764706,371855.117647059,382325.705882353,399090.411764706,403852.941176471,415529.411764706,385164.705882353,393047.058823529,418752.941176471,456111.352941176,456111.352941176,470799.294117647,485460.823529412,505937.294117647,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235],[205960.823529412,258988.176470588,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,289395.117647059,296124.529411765,304477.470588235,307239,316176.764705882,338985.588235294,353779.705882353,371144.411764706,371855.117647059,382325.705882353,399090.411764706,403852.941176471,415529.411764706,385164.705882353,393047.058823529,444694.117647059,456111.352941176,456111.352941176,470799.294117647,485460.823529412,491813.764705882,508996.117647059,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235],[213326.411764706,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,282541.117647059,282541.117647059,288183.352941176,304477.470588235,304477.470588235,307239,316176.764705882,338985.588235294,353779.705882353,371144.411764706,371855.117647059,382325.705882353,399090.411764706,403852.941176471,415529.411764706,385164.705882353,393047.058823529,444694.117647059,456111.352941176,456111.352941176,470799.294117647,485460.823529412,491813.764705882,492596.117647059,508996.117647059,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235],[272341.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,288183.352941176,304477.470588235,304477.470588235,307239,316176.764705882,338985.588235294,353779.705882353,371144.411764706,371855.117647059,382325.705882353,399090.411764706,403852.941176471,415529.411764706,385164.705882353,423341.176470588,444694.117647059,456111.352941176,456111.352941176,470799.294117647,485460.823529412,491813.764705882,492596.117647059,492596.117647059,508996.117647059,508996.117647059,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235],[280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,299894.058823529,304477.470588235,304477.470588235,307239,316176.764705882,338985.588235294,353779.705882353,371144.411764706,371855.117647059,382325.705882353,399090.411764706,403852.941176471,415529.411764706,413105.882352941,423341.176470588,444694.117647059,456111.352941176,456111.352941176,470799.294117647,485460.823529412,491813.764705882,492596.117647059,492596.117647059,492596.117647059,508996.117647059,508996.117647059,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235],[280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,280395.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,299894.058823529,299894.058823529,304477.470588235,304477.470588235,307239,316176.764705882,338985.588235294,353779.705882353,371144.411764706,371855.117647059,382325.705882353,399090.411764706,403852.941176471,415529.411764706,413105.882352941,423341.176470588,444694.117647059,456111.352941176,456111.352941176,470799.294117647,485460.823529412,491813.764705882,492596.117647059,492596.117647059,492596.117647059,492596.117647059,508996.117647059,508996.117647059,514878.470588235,514878.470588235,514878.470588235,514878.470588235,514878.470588235],[280395.117647059,280395.117647059,280395.117647059,280395.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,291247,299894.058823529,299894.058823529,304477.470588235,304477.470588235,307239,316176.764705882,338985.588235294,353779.705882353,371144.411764706,371855.117647059,382325.705882353,399090.411764706,403852.941176471,427735.294117647,413105.882352941,423341.176470588,444694.117647059,456111.352941176,456111.352941176,470799.294117647,485460.823529412,491813.764705882,492596.117647059,492596.117647059,492596.117647059,492596.117647059,492596.117647059,508996.117647059,508996.117647059,514878.470588235,514878.470588235,514878.470588235,514878.470588235],[280395.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,291247,291247,299894.058823529,299894.058823529,304477.470588235,304477.470588235,307239,316176.764705882,338985.588235294,353779.705882353,371144.411764706,371855.117647059,382325.705882353,399090.411764706,426500,427735.294117647,413105.882352941,423341.176470588,444694.117647059,456111.352941176,456111.352941176,470799.294117647,485460.823529412,491813.764705882,492596.117647059,492596.117647059,492596.117647059,492596.117647059,492596.117647059,492596.117647059,508996.117647059,508996.117647059,514878.470588235,514878.470588235,514878.470588235],[282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,282541.117647059,291247,291247,291247,299894.058823529,299894.058823529,304477.470588235,304477.470588235,307239,316176.764705882,338985.588235294,353779.705882353,371144.411764706,371855.117647059,382325.705882353,399090.411764706,426500,427735.294117647,413105.882352941,423341.176470588,444694.117647059,456111.352941176,456111.352941176,470799.294117647,485460.823529412,491813.764705882,492596.117647059,492596.117647059,492596.117647059,492596.117647059,492596.117647059,492596.117647059,492596.117647059,508996.117647059,508996.117647059,514878.470588235,514878.470588235]],"type":"surface","x":[484,573.673469387755,663.34693877551,753.020408163265,842.69387755102,932.367346938776,1022.04081632653,1111.71428571429,1201.38775510204,1291.0612244898,1380.73469387755,1470.40816326531,1560.08163265306,1649.75510204082,1739.42857142857,1829.10204081633,1918.77551020408,2008.44897959184,2098.12244897959,2187.79591836735,2277.4693877551,2367.14285714286,2456.81632653061,2546.48979591837,2636.16326530612,2725.83673469388,2815.51020408163,2905.18367346939,2994.85714285714,3084.5306122449,3174.20408163265,3263.87755102041,3353.55102040816,3443.22448979592,3532.89795918367,3622.57142857143,3712.24489795918,3801.91836734694,3891.59183673469,3981.26530612245,4070.9387755102,4160.61224489796,4250.28571428571,4339.95918367347,4429.63265306122,4519.30612244898,4608.97959183673,4698.65306122449,4788.32653061224,4878],"y":[1,1.14285714285714,1.28571428571429,1.42857142857143,1.57142857142857,1.71428571428571,1.85714285714286,2,2.14285714285714,2.28571428571429,2.42857142857143,2.57142857142857,2.71428571428571,2.85714285714286,3,3.14285714285714,3.28571428571429,3.42857142857143,3.57142857142857,3.71428571428571,3.85714285714286,4,4.14285714285714,4.28571428571429,4.42857142857143,4.57142857142857,4.71428571428571,4.85714285714286,5,5.14285714285714,5.28571428571429,5.42857142857143,5.57142857142857,5.71428571428571,5.85714285714286,6,6.14285714285714,6.28571428571429,6.42857142857143,6.57142857142857,6.71428571428571,6.85714285714286,7,7.14285714285714,7.28571428571429,7.42857142857143,7.57142857142857,7.71428571428571,7.85714285714286,8],"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p class="caption">
Figure 8.10: KNN regression model’s predictions represented as a surface in 3-D space overlaid on top of the data using three predictors (price, house size, and the number of bedrooms)
</p>
</div>
<p>We can see that the predictions in this case, where we have 2 predictors, form
a surface instead of a line. Because the newly added predictor (number of bedrooms) is
related to price (as price changes, so does number of bedrooms)
and is not totally determined by house size (our other predictor),
we get additional and useful information for making our
predictions. For example, in this model we would predict that the cost of a
house with a size of 2,500 square feet generally increases slightly as the number
of bedrooms increases. Without having the additional predictor of number of
bedrooms, we would predict the same price for these two houses.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classification-continued.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/07-regression1.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
