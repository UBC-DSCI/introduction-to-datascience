<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Regression II: linear regression |  Data Science</title>
  <meta name="description" content="This is a textbook for teaching a first introduction to data science." />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Regression II: linear regression |  Data Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a textbook for teaching a first introduction to data science." />
  <meta name="github-repo" content="UBC-DSCI/introduction-to-datascience" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Regression II: linear regression |  Data Science" />
  
  <meta name="twitter:description" content="This is a textbook for teaching a first introduction to data science." />
  

<meta name="author" content="Tiffany Timbers, Trevor Campbell, and Melissa Lee" />


<meta name="date" content="2024-08-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression1.html"/>
<link rel="next" href="clustering.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.2/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JJ9MD0LBF5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-JJ9MD0LBF5');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="source/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://datasciencebook.ca">Data Science: A First Introduction</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome!</a></li>
<li class="chapter" data-level="" data-path="foreword.html"><a href="foreword.html"><i class="fa fa-check"></i>Foreword</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the authors</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> R and the Tidyverse</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#overview"><i class="fa fa-check"></i><b>1.1</b> Overview</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#chapter-learning-objectives"><i class="fa fa-check"></i><b>1.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#canadian-languages-data-set"><i class="fa fa-check"></i><b>1.3</b> Canadian languages data set</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#asking-a-question"><i class="fa fa-check"></i><b>1.4</b> Asking a question</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#loading-a-tabular-data-set"><i class="fa fa-check"></i><b>1.5</b> Loading a tabular data set</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#naming-things-in-r"><i class="fa fa-check"></i><b>1.6</b> Naming things in R</a></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#creating-subsets-of-data-frames-with-filter-select"><i class="fa fa-check"></i><b>1.7</b> Creating subsets of data frames with <code>filter</code> &amp; <code>select</code></a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="intro.html"><a href="intro.html#using-filter-to-extract-rows"><i class="fa fa-check"></i><b>1.7.1</b> Using <code>filter</code> to extract rows</a></li>
<li class="chapter" data-level="1.7.2" data-path="intro.html"><a href="intro.html#using-select-to-extract-columns"><i class="fa fa-check"></i><b>1.7.2</b> Using <code>select</code> to extract columns</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#arrangesliceintro"><i class="fa fa-check"></i><b>1.8</b> Using <code>arrange</code> to order and <code>slice</code> to select rows by index number</a></li>
<li class="chapter" data-level="1.9" data-path="intro.html"><a href="intro.html#adding-and-modifying-columns-using-mutate"><i class="fa fa-check"></i><b>1.9</b> Adding and modifying columns using <code>mutate</code></a></li>
<li class="chapter" data-level="1.10" data-path="intro.html"><a href="intro.html#exploring-data-with-visualizations"><i class="fa fa-check"></i><b>1.10</b> Exploring data with visualizations</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="intro.html"><a href="intro.html#using-ggplot-to-create-a-bar-plot"><i class="fa fa-check"></i><b>1.10.1</b> Using <code>ggplot</code> to create a bar plot</a></li>
<li class="chapter" data-level="1.10.2" data-path="intro.html"><a href="intro.html#formatting-ggplot-objects"><i class="fa fa-check"></i><b>1.10.2</b> Formatting ggplot objects</a></li>
<li class="chapter" data-level="1.10.3" data-path="intro.html"><a href="intro.html#putting-it-all-together"><i class="fa fa-check"></i><b>1.10.3</b> Putting it all together</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="intro.html"><a href="intro.html#accessing-documentation"><i class="fa fa-check"></i><b>1.11</b> Accessing documentation</a></li>
<li class="chapter" data-level="1.12" data-path="intro.html"><a href="intro.html#exercises"><i class="fa fa-check"></i><b>1.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="reading.html"><a href="reading.html"><i class="fa fa-check"></i><b>2</b> Reading in data locally and from the web</a>
<ul>
<li class="chapter" data-level="2.1" data-path="reading.html"><a href="reading.html#overview-1"><i class="fa fa-check"></i><b>2.1</b> Overview</a></li>
<li class="chapter" data-level="2.2" data-path="reading.html"><a href="reading.html#chapter-learning-objectives-1"><i class="fa fa-check"></i><b>2.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="2.3" data-path="reading.html"><a href="reading.html#absolute-and-relative-file-paths"><i class="fa fa-check"></i><b>2.3</b> Absolute and relative file paths</a></li>
<li class="chapter" data-level="2.4" data-path="reading.html"><a href="reading.html#reading-tabular-data-from-a-plain-text-file-into-r"><i class="fa fa-check"></i><b>2.4</b> Reading tabular data from a plain text file into R</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="reading.html"><a href="reading.html#readcsv"><i class="fa fa-check"></i><b>2.4.1</b> <code>read_csv</code> to read in comma-separated values files</a></li>
<li class="chapter" data-level="2.4.2" data-path="reading.html"><a href="reading.html#skipping-rows-when-reading-in-data"><i class="fa fa-check"></i><b>2.4.2</b> Skipping rows when reading in data</a></li>
<li class="chapter" data-level="2.4.3" data-path="reading.html"><a href="reading.html#read_tsv-to-read-in-tab-separated-values-files"><i class="fa fa-check"></i><b>2.4.3</b> <code>read_tsv</code> to read in tab-separated values files</a></li>
<li class="chapter" data-level="2.4.4" data-path="reading.html"><a href="reading.html#read_delim-as-a-more-flexible-method-to-get-tabular-data-into-r"><i class="fa fa-check"></i><b>2.4.4</b> <code>read_delim</code> as a more flexible method to get tabular data into R</a></li>
<li class="chapter" data-level="2.4.5" data-path="reading.html"><a href="reading.html#reading-tabular-data-directly-from-a-url"><i class="fa fa-check"></i><b>2.4.5</b> Reading tabular data directly from a URL</a></li>
<li class="chapter" data-level="2.4.6" data-path="reading.html"><a href="reading.html#downloading-data-from-a-url"><i class="fa fa-check"></i><b>2.4.6</b> Downloading data from a URL</a></li>
<li class="chapter" data-level="2.4.7" data-path="reading.html"><a href="reading.html#previewing-a-data-file-before-reading-it-into-r"><i class="fa fa-check"></i><b>2.4.7</b> Previewing a data file before reading it into R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="reading.html"><a href="reading.html#reading-tabular-data-from-a-microsoft-excel-file"><i class="fa fa-check"></i><b>2.5</b> Reading tabular data from a Microsoft Excel file</a></li>
<li class="chapter" data-level="2.6" data-path="reading.html"><a href="reading.html#reading-data-from-a-database"><i class="fa fa-check"></i><b>2.6</b> Reading data from a database</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="reading.html"><a href="reading.html#reading-data-from-a-sqlite-database"><i class="fa fa-check"></i><b>2.6.1</b> Reading data from a SQLite database</a></li>
<li class="chapter" data-level="2.6.2" data-path="reading.html"><a href="reading.html#reading-data-from-a-postgresql-database"><i class="fa fa-check"></i><b>2.6.2</b> Reading data from a PostgreSQL database</a></li>
<li class="chapter" data-level="2.6.3" data-path="reading.html"><a href="reading.html#why-should-we-bother-with-databases-at-all"><i class="fa fa-check"></i><b>2.6.3</b> Why should we bother with databases at all?</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="reading.html"><a href="reading.html#writing-data-from-r-to-a-.csv-file"><i class="fa fa-check"></i><b>2.7</b> Writing data from R to a <code>.csv</code> file</a></li>
<li class="chapter" data-level="2.8" data-path="reading.html"><a href="reading.html#obtaining-data-from-the-web"><i class="fa fa-check"></i><b>2.8</b> Obtaining data from the web</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="reading.html"><a href="reading.html#web-scraping"><i class="fa fa-check"></i><b>2.8.1</b> Web scraping</a></li>
<li class="chapter" data-level="2.8.2" data-path="reading.html"><a href="reading.html#using-an-api"><i class="fa fa-check"></i><b>2.8.2</b> Using an API</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="reading.html"><a href="reading.html#exercises-1"><i class="fa fa-check"></i><b>2.9</b> Exercises</a></li>
<li class="chapter" data-level="2.10" data-path="reading.html"><a href="reading.html#additional-resources"><i class="fa fa-check"></i><b>2.10</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="wrangling.html"><a href="wrangling.html"><i class="fa fa-check"></i><b>3</b> Cleaning and wrangling data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="wrangling.html"><a href="wrangling.html#overview-2"><i class="fa fa-check"></i><b>3.1</b> Overview</a></li>
<li class="chapter" data-level="3.2" data-path="wrangling.html"><a href="wrangling.html#chapter-learning-objectives-2"><i class="fa fa-check"></i><b>3.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="3.3" data-path="wrangling.html"><a href="wrangling.html#data-frames-vectors-and-lists"><i class="fa fa-check"></i><b>3.3</b> Data frames, vectors, and lists</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="wrangling.html"><a href="wrangling.html#what-is-a-data-frame"><i class="fa fa-check"></i><b>3.3.1</b> What is a data frame?</a></li>
<li class="chapter" data-level="3.3.2" data-path="wrangling.html"><a href="wrangling.html#what-is-a-vector"><i class="fa fa-check"></i><b>3.3.2</b> What is a vector?</a></li>
<li class="chapter" data-level="3.3.3" data-path="wrangling.html"><a href="wrangling.html#what-is-a-list"><i class="fa fa-check"></i><b>3.3.3</b> What is a list?</a></li>
<li class="chapter" data-level="3.3.4" data-path="wrangling.html"><a href="wrangling.html#what-does-this-have-to-do-with-data-frames"><i class="fa fa-check"></i><b>3.3.4</b> What does this have to do with data frames?</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="wrangling.html"><a href="wrangling.html#tidy-data"><i class="fa fa-check"></i><b>3.4</b> Tidy data</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="wrangling.html"><a href="wrangling.html#tidying-up-going-from-wide-to-long-using-pivot_longer"><i class="fa fa-check"></i><b>3.4.1</b> Tidying up: going from wide to long using <code>pivot_longer</code></a></li>
<li class="chapter" data-level="3.4.2" data-path="wrangling.html"><a href="wrangling.html#pivot-wider"><i class="fa fa-check"></i><b>3.4.2</b> Tidying up: going from long to wide using <code>pivot_wider</code></a></li>
<li class="chapter" data-level="3.4.3" data-path="wrangling.html"><a href="wrangling.html#separate"><i class="fa fa-check"></i><b>3.4.3</b> Tidying up: using <code>separate</code> to deal with multiple delimiters</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="wrangling.html"><a href="wrangling.html#using-select-to-extract-a-range-of-columns"><i class="fa fa-check"></i><b>3.5</b> Using <code>select</code> to extract a range of columns</a></li>
<li class="chapter" data-level="3.6" data-path="wrangling.html"><a href="wrangling.html#using-filter-to-extract-rows-1"><i class="fa fa-check"></i><b>3.6</b> Using <code>filter</code> to extract rows</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-that-have-a-certain-value-with"><i class="fa fa-check"></i><b>3.6.1</b> Extracting rows that have a certain value with <code>==</code></a></li>
<li class="chapter" data-level="3.6.2" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-that-do-not-have-a-certain-value-with"><i class="fa fa-check"></i><b>3.6.2</b> Extracting rows that do not have a certain value with <code>!=</code></a></li>
<li class="chapter" data-level="3.6.3" data-path="wrangling.html"><a href="wrangling.html#filter-and"><i class="fa fa-check"></i><b>3.6.3</b> Extracting rows satisfying multiple conditions using <code>,</code> or <code>&amp;</code></a></li>
<li class="chapter" data-level="3.6.4" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-satisfying-at-least-one-condition-using"><i class="fa fa-check"></i><b>3.6.4</b> Extracting rows satisfying at least one condition using <code>|</code></a></li>
<li class="chapter" data-level="3.6.5" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-with-values-in-a-vector-using-in"><i class="fa fa-check"></i><b>3.6.5</b> Extracting rows with values in a vector using <code>%in%</code></a></li>
<li class="chapter" data-level="3.6.6" data-path="wrangling.html"><a href="wrangling.html#extracting-rows-above-or-below-a-threshold-using-and"><i class="fa fa-check"></i><b>3.6.6</b> Extracting rows above or below a threshold using <code>&gt;</code> and <code>&lt;</code></a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="wrangling.html"><a href="wrangling.html#using-mutate-to-modify-or-add-columns"><i class="fa fa-check"></i><b>3.7</b> Using <code>mutate</code> to modify or add columns</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="wrangling.html"><a href="wrangling.html#using-mutate-to-modify-columns"><i class="fa fa-check"></i><b>3.7.1</b> Using <code>mutate</code> to modify columns</a></li>
<li class="chapter" data-level="3.7.2" data-path="wrangling.html"><a href="wrangling.html#using-mutate-to-create-new-columns"><i class="fa fa-check"></i><b>3.7.2</b> Using <code>mutate</code> to create new columns</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="wrangling.html"><a href="wrangling.html#combining-functions-using-the-pipe-operator"><i class="fa fa-check"></i><b>3.8</b> Combining functions using the pipe operator, <code>|&gt;</code></a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="wrangling.html"><a href="wrangling.html#using-to-combine-filter-and-select"><i class="fa fa-check"></i><b>3.8.1</b> Using <code>|&gt;</code> to combine <code>filter</code> and <code>select</code></a></li>
<li class="chapter" data-level="3.8.2" data-path="wrangling.html"><a href="wrangling.html#using-with-more-than-two-functions"><i class="fa fa-check"></i><b>3.8.2</b> Using <code>|&gt;</code> with more than two functions</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="wrangling.html"><a href="wrangling.html#aggregating-data-with-summarize-and-map"><i class="fa fa-check"></i><b>3.9</b> Aggregating data with <code>summarize</code> and <code>map</code></a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics-on-whole-columns"><i class="fa fa-check"></i><b>3.9.1</b> Calculating summary statistics on whole columns</a></li>
<li class="chapter" data-level="3.9.2" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics-when-there-are-nas"><i class="fa fa-check"></i><b>3.9.2</b> Calculating summary statistics when there are <code>NA</code>s</a></li>
<li class="chapter" data-level="3.9.3" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics-for-groups-of-rows"><i class="fa fa-check"></i><b>3.9.3</b> Calculating summary statistics for groups of rows</a></li>
<li class="chapter" data-level="3.9.4" data-path="wrangling.html"><a href="wrangling.html#calculating-summary-statistics-on-many-columns"><i class="fa fa-check"></i><b>3.9.4</b> Calculating summary statistics on many columns</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="wrangling.html"><a href="wrangling.html#apply-functions-across-many-columns-with-mutate-and-across"><i class="fa fa-check"></i><b>3.10</b> Apply functions across many columns with <code>mutate</code> and <code>across</code></a></li>
<li class="chapter" data-level="3.11" data-path="wrangling.html"><a href="wrangling.html#apply-functions-across-columns-within-one-row-with-rowwise-and-mutate"><i class="fa fa-check"></i><b>3.11</b> Apply functions across columns within one row with <code>rowwise</code> and <code>mutate</code></a></li>
<li class="chapter" data-level="3.12" data-path="wrangling.html"><a href="wrangling.html#summary"><i class="fa fa-check"></i><b>3.12</b> Summary</a></li>
<li class="chapter" data-level="3.13" data-path="wrangling.html"><a href="wrangling.html#exercises-2"><i class="fa fa-check"></i><b>3.13</b> Exercises</a></li>
<li class="chapter" data-level="3.14" data-path="wrangling.html"><a href="wrangling.html#additional-resources-1"><i class="fa fa-check"></i><b>3.14</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="viz.html"><a href="viz.html"><i class="fa fa-check"></i><b>4</b> Effective data visualization</a>
<ul>
<li class="chapter" data-level="4.1" data-path="viz.html"><a href="viz.html#overview-3"><i class="fa fa-check"></i><b>4.1</b> Overview</a></li>
<li class="chapter" data-level="4.2" data-path="viz.html"><a href="viz.html#chapter-learning-objectives-3"><i class="fa fa-check"></i><b>4.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="4.3" data-path="viz.html"><a href="viz.html#choosing-the-visualization"><i class="fa fa-check"></i><b>4.3</b> Choosing the visualization</a></li>
<li class="chapter" data-level="4.4" data-path="viz.html"><a href="viz.html#refining-the-visualization"><i class="fa fa-check"></i><b>4.4</b> Refining the visualization</a></li>
<li class="chapter" data-level="4.5" data-path="viz.html"><a href="viz.html#creating-visualizations-with-ggplot2"><i class="fa fa-check"></i><b>4.5</b> Creating visualizations with <code>ggplot2</code></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="viz.html"><a href="viz.html#scatter-plots-and-line-plots-the-mauna-loa-co_text2-data-set"><i class="fa fa-check"></i><b>4.5.1</b> Scatter plots and line plots: the Mauna Loa CO<span class="math inline">\(_{\text{2}}\)</span> data set</a></li>
<li class="chapter" data-level="4.5.2" data-path="viz.html"><a href="viz.html#scatter-plots-the-old-faithful-eruption-time-data-set"><i class="fa fa-check"></i><b>4.5.2</b> Scatter plots: the Old Faithful eruption time data set</a></li>
<li class="chapter" data-level="4.5.3" data-path="viz.html"><a href="viz.html#axis-transformation-and-colored-scatter-plots-the-canadian-languages-data-set"><i class="fa fa-check"></i><b>4.5.3</b> Axis transformation and colored scatter plots: the Canadian languages data set</a></li>
<li class="chapter" data-level="4.5.4" data-path="viz.html"><a href="viz.html#bar-plots-the-island-landmass-data-set"><i class="fa fa-check"></i><b>4.5.4</b> Bar plots: the island landmass data set</a></li>
<li class="chapter" data-level="4.5.5" data-path="viz.html"><a href="viz.html#histogramsviz"><i class="fa fa-check"></i><b>4.5.5</b> Histograms: the Michelson speed of light data set</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="viz.html"><a href="viz.html#explaining-the-visualization"><i class="fa fa-check"></i><b>4.6</b> Explaining the visualization</a></li>
<li class="chapter" data-level="4.7" data-path="viz.html"><a href="viz.html#saving-the-visualization"><i class="fa fa-check"></i><b>4.7</b> Saving the visualization</a></li>
<li class="chapter" data-level="4.8" data-path="viz.html"><a href="viz.html#exercises-3"><i class="fa fa-check"></i><b>4.8</b> Exercises</a></li>
<li class="chapter" data-level="4.9" data-path="viz.html"><a href="viz.html#additional-resources-2"><i class="fa fa-check"></i><b>4.9</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="classification1.html"><a href="classification1.html"><i class="fa fa-check"></i><b>5</b> Classification I: training &amp; predicting</a>
<ul>
<li class="chapter" data-level="5.1" data-path="classification1.html"><a href="classification1.html#overview-4"><i class="fa fa-check"></i><b>5.1</b> Overview</a></li>
<li class="chapter" data-level="5.2" data-path="classification1.html"><a href="classification1.html#chapter-learning-objectives-4"><i class="fa fa-check"></i><b>5.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="5.3" data-path="classification1.html"><a href="classification1.html#the-classification-problem"><i class="fa fa-check"></i><b>5.3</b> The classification problem</a></li>
<li class="chapter" data-level="5.4" data-path="classification1.html"><a href="classification1.html#exploring-a-data-set"><i class="fa fa-check"></i><b>5.4</b> Exploring a data set</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="classification1.html"><a href="classification1.html#loading-the-cancer-data"><i class="fa fa-check"></i><b>5.4.1</b> Loading the cancer data</a></li>
<li class="chapter" data-level="5.4.2" data-path="classification1.html"><a href="classification1.html#describing-the-variables-in-the-cancer-data-set"><i class="fa fa-check"></i><b>5.4.2</b> Describing the variables in the cancer data set</a></li>
<li class="chapter" data-level="5.4.3" data-path="classification1.html"><a href="classification1.html#exploring-the-cancer-data"><i class="fa fa-check"></i><b>5.4.3</b> Exploring the cancer data</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="classification1.html"><a href="classification1.html#classification-with-k-nearest-neighbors"><i class="fa fa-check"></i><b>5.5</b> Classification with K-nearest neighbors</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="classification1.html"><a href="classification1.html#distance-between-points"><i class="fa fa-check"></i><b>5.5.1</b> Distance between points</a></li>
<li class="chapter" data-level="5.5.2" data-path="classification1.html"><a href="classification1.html#more-than-two-explanatory-variables"><i class="fa fa-check"></i><b>5.5.2</b> More than two explanatory variables</a></li>
<li class="chapter" data-level="5.5.3" data-path="classification1.html"><a href="classification1.html#summary-of-k-nearest-neighbors-algorithm"><i class="fa fa-check"></i><b>5.5.3</b> Summary of K-nearest neighbors algorithm</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="classification1.html"><a href="classification1.html#k-nearest-neighbors-with-tidymodels"><i class="fa fa-check"></i><b>5.6</b> K-nearest neighbors with <code>tidymodels</code></a></li>
<li class="chapter" data-level="5.7" data-path="classification1.html"><a href="classification1.html#data-preprocessing-with-tidymodels"><i class="fa fa-check"></i><b>5.7</b> Data preprocessing with <code>tidymodels</code></a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="classification1.html"><a href="classification1.html#centering-and-scaling"><i class="fa fa-check"></i><b>5.7.1</b> Centering and scaling</a></li>
<li class="chapter" data-level="5.7.2" data-path="classification1.html"><a href="classification1.html#balancing"><i class="fa fa-check"></i><b>5.7.2</b> Balancing</a></li>
<li class="chapter" data-level="5.7.3" data-path="classification1.html"><a href="classification1.html#missing-data"><i class="fa fa-check"></i><b>5.7.3</b> Missing data</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="classification1.html"><a href="classification1.html#puttingittogetherworkflow"><i class="fa fa-check"></i><b>5.8</b> Putting it together in a <code>workflow</code></a></li>
<li class="chapter" data-level="5.9" data-path="classification1.html"><a href="classification1.html#exercises-4"><i class="fa fa-check"></i><b>5.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classification2.html"><a href="classification2.html"><i class="fa fa-check"></i><b>6</b> Classification II: evaluation &amp; tuning</a>
<ul>
<li class="chapter" data-level="6.1" data-path="classification2.html"><a href="classification2.html#overview-5"><i class="fa fa-check"></i><b>6.1</b> Overview</a></li>
<li class="chapter" data-level="6.2" data-path="classification2.html"><a href="classification2.html#chapter-learning-objectives-5"><i class="fa fa-check"></i><b>6.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="6.3" data-path="classification2.html"><a href="classification2.html#evaluating-performance"><i class="fa fa-check"></i><b>6.3</b> Evaluating performance</a></li>
<li class="chapter" data-level="6.4" data-path="classification2.html"><a href="classification2.html#randomseeds"><i class="fa fa-check"></i><b>6.4</b> Randomness and seeds</a></li>
<li class="chapter" data-level="6.5" data-path="classification2.html"><a href="classification2.html#evaluating-performance-with-tidymodels"><i class="fa fa-check"></i><b>6.5</b> Evaluating performance with <code>tidymodels</code></a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="classification2.html"><a href="classification2.html#create-the-train-test-split"><i class="fa fa-check"></i><b>6.5.1</b> Create the train / test split</a></li>
<li class="chapter" data-level="6.5.2" data-path="classification2.html"><a href="classification2.html#preprocess-the-data"><i class="fa fa-check"></i><b>6.5.2</b> Preprocess the data</a></li>
<li class="chapter" data-level="6.5.3" data-path="classification2.html"><a href="classification2.html#train-the-classifier"><i class="fa fa-check"></i><b>6.5.3</b> Train the classifier</a></li>
<li class="chapter" data-level="6.5.4" data-path="classification2.html"><a href="classification2.html#predict-the-labels-in-the-test-set"><i class="fa fa-check"></i><b>6.5.4</b> Predict the labels in the test set</a></li>
<li class="chapter" data-level="6.5.5" data-path="classification2.html"><a href="classification2.html#eval-performance-cls2"><i class="fa fa-check"></i><b>6.5.5</b> Evaluate performance</a></li>
<li class="chapter" data-level="6.5.6" data-path="classification2.html"><a href="classification2.html#critically-analyze-performance"><i class="fa fa-check"></i><b>6.5.6</b> Critically analyze performance</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="classification2.html"><a href="classification2.html#tuning-the-classifier"><i class="fa fa-check"></i><b>6.6</b> Tuning the classifier</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="classification2.html"><a href="classification2.html#cross-validation"><i class="fa fa-check"></i><b>6.6.1</b> Cross-validation</a></li>
<li class="chapter" data-level="6.6.2" data-path="classification2.html"><a href="classification2.html#parameter-value-selection"><i class="fa fa-check"></i><b>6.6.2</b> Parameter value selection</a></li>
<li class="chapter" data-level="6.6.3" data-path="classification2.html"><a href="classification2.html#underoverfitting"><i class="fa fa-check"></i><b>6.6.3</b> Under/Overfitting</a></li>
<li class="chapter" data-level="6.6.4" data-path="classification2.html"><a href="classification2.html#evaluating-on-the-test-set"><i class="fa fa-check"></i><b>6.6.4</b> Evaluating on the test set</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="classification2.html"><a href="classification2.html#summary-1"><i class="fa fa-check"></i><b>6.7</b> Summary</a></li>
<li class="chapter" data-level="6.8" data-path="classification2.html"><a href="classification2.html#predictor-variable-selection"><i class="fa fa-check"></i><b>6.8</b> Predictor variable selection</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="classification2.html"><a href="classification2.html#the-effect-of-irrelevant-predictors"><i class="fa fa-check"></i><b>6.8.1</b> The effect of irrelevant predictors</a></li>
<li class="chapter" data-level="6.8.2" data-path="classification2.html"><a href="classification2.html#finding-a-good-subset-of-predictors"><i class="fa fa-check"></i><b>6.8.2</b> Finding a good subset of predictors</a></li>
<li class="chapter" data-level="6.8.3" data-path="classification2.html"><a href="classification2.html#forward-selection-in-r"><i class="fa fa-check"></i><b>6.8.3</b> Forward selection in R</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="classification2.html"><a href="classification2.html#exercises-5"><i class="fa fa-check"></i><b>6.9</b> Exercises</a></li>
<li class="chapter" data-level="6.10" data-path="classification2.html"><a href="classification2.html#additional-resources-3"><i class="fa fa-check"></i><b>6.10</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regression1.html"><a href="regression1.html"><i class="fa fa-check"></i><b>7</b> Regression I: K-nearest neighbors</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regression1.html"><a href="regression1.html#overview-6"><i class="fa fa-check"></i><b>7.1</b> Overview</a></li>
<li class="chapter" data-level="7.2" data-path="regression1.html"><a href="regression1.html#chapter-learning-objectives-6"><i class="fa fa-check"></i><b>7.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="7.3" data-path="regression1.html"><a href="regression1.html#the-regression-problem"><i class="fa fa-check"></i><b>7.3</b> The regression problem</a></li>
<li class="chapter" data-level="7.4" data-path="regression1.html"><a href="regression1.html#exploring-a-data-set-1"><i class="fa fa-check"></i><b>7.4</b> Exploring a data set</a></li>
<li class="chapter" data-level="7.5" data-path="regression1.html"><a href="regression1.html#k-nearest-neighbors-regression"><i class="fa fa-check"></i><b>7.5</b> K-nearest neighbors regression</a></li>
<li class="chapter" data-level="7.6" data-path="regression1.html"><a href="regression1.html#training-evaluating-and-tuning-the-model"><i class="fa fa-check"></i><b>7.6</b> Training, evaluating, and tuning the model</a></li>
<li class="chapter" data-level="7.7" data-path="regression1.html"><a href="regression1.html#underfitting-and-overfitting"><i class="fa fa-check"></i><b>7.7</b> Underfitting and overfitting</a></li>
<li class="chapter" data-level="7.8" data-path="regression1.html"><a href="regression1.html#evaluating-on-the-test-set-1"><i class="fa fa-check"></i><b>7.8</b> Evaluating on the test set</a></li>
<li class="chapter" data-level="7.9" data-path="regression1.html"><a href="regression1.html#multivariable-k-nn-regression"><i class="fa fa-check"></i><b>7.9</b> Multivariable K-NN regression</a></li>
<li class="chapter" data-level="7.10" data-path="regression1.html"><a href="regression1.html#strengths-and-limitations-of-k-nn-regression"><i class="fa fa-check"></i><b>7.10</b> Strengths and limitations of K-NN regression</a></li>
<li class="chapter" data-level="7.11" data-path="regression1.html"><a href="regression1.html#exercises-6"><i class="fa fa-check"></i><b>7.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression2.html"><a href="regression2.html"><i class="fa fa-check"></i><b>8</b> Regression II: linear regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="regression2.html"><a href="regression2.html#overview-7"><i class="fa fa-check"></i><b>8.1</b> Overview</a></li>
<li class="chapter" data-level="8.2" data-path="regression2.html"><a href="regression2.html#chapter-learning-objectives-7"><i class="fa fa-check"></i><b>8.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="8.3" data-path="regression2.html"><a href="regression2.html#simple-linear-regression"><i class="fa fa-check"></i><b>8.3</b> Simple linear regression</a></li>
<li class="chapter" data-level="8.4" data-path="regression2.html"><a href="regression2.html#linear-regression-in-r"><i class="fa fa-check"></i><b>8.4</b> Linear regression in R</a></li>
<li class="chapter" data-level="8.5" data-path="regression2.html"><a href="regression2.html#comparing-simple-linear-and-k-nn-regression"><i class="fa fa-check"></i><b>8.5</b> Comparing simple linear and K-NN regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression2.html"><a href="regression2.html#multivariable-linear-regression"><i class="fa fa-check"></i><b>8.6</b> Multivariable linear regression</a></li>
<li class="chapter" data-level="8.7" data-path="regression2.html"><a href="regression2.html#multicollinearity-and-outliers"><i class="fa fa-check"></i><b>8.7</b> Multicollinearity and outliers</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="regression2.html"><a href="regression2.html#outliers"><i class="fa fa-check"></i><b>8.7.1</b> Outliers</a></li>
<li class="chapter" data-level="8.7.2" data-path="regression2.html"><a href="regression2.html#multicollinearity"><i class="fa fa-check"></i><b>8.7.2</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="regression2.html"><a href="regression2.html#designing-new-predictors"><i class="fa fa-check"></i><b>8.8</b> Designing new predictors</a></li>
<li class="chapter" data-level="8.9" data-path="regression2.html"><a href="regression2.html#the-other-sides-of-regression"><i class="fa fa-check"></i><b>8.9</b> The other sides of regression</a></li>
<li class="chapter" data-level="8.10" data-path="regression2.html"><a href="regression2.html#exercises-7"><i class="fa fa-check"></i><b>8.10</b> Exercises</a></li>
<li class="chapter" data-level="8.11" data-path="regression2.html"><a href="regression2.html#additional-resources-4"><i class="fa fa-check"></i><b>8.11</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>9</b> Clustering</a>
<ul>
<li class="chapter" data-level="9.1" data-path="clustering.html"><a href="clustering.html#overview-8"><i class="fa fa-check"></i><b>9.1</b> Overview</a></li>
<li class="chapter" data-level="9.2" data-path="clustering.html"><a href="clustering.html#chapter-learning-objectives-8"><i class="fa fa-check"></i><b>9.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="9.3" data-path="clustering.html"><a href="clustering.html#clustering-1"><i class="fa fa-check"></i><b>9.3</b> Clustering</a></li>
<li class="chapter" data-level="9.4" data-path="clustering.html"><a href="clustering.html#an-illustrative-example"><i class="fa fa-check"></i><b>9.4</b> An illustrative example</a></li>
<li class="chapter" data-level="9.5" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>9.5</b> K-means</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="clustering.html"><a href="clustering.html#measuring-cluster-quality"><i class="fa fa-check"></i><b>9.5.1</b> Measuring cluster quality</a></li>
<li class="chapter" data-level="9.5.2" data-path="clustering.html"><a href="clustering.html#the-clustering-algorithm"><i class="fa fa-check"></i><b>9.5.2</b> The clustering algorithm</a></li>
<li class="chapter" data-level="9.5.3" data-path="clustering.html"><a href="clustering.html#random-restarts"><i class="fa fa-check"></i><b>9.5.3</b> Random restarts</a></li>
<li class="chapter" data-level="9.5.4" data-path="clustering.html"><a href="clustering.html#choosing-k"><i class="fa fa-check"></i><b>9.5.4</b> Choosing K</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="clustering.html"><a href="clustering.html#k-means-in-r"><i class="fa fa-check"></i><b>9.6</b> K-means in R</a></li>
<li class="chapter" data-level="9.7" data-path="clustering.html"><a href="clustering.html#exercises-8"><i class="fa fa-check"></i><b>9.7</b> Exercises</a></li>
<li class="chapter" data-level="9.8" data-path="clustering.html"><a href="clustering.html#additional-resources-5"><i class="fa fa-check"></i><b>9.8</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>10</b> Statistical inference</a>
<ul>
<li class="chapter" data-level="10.1" data-path="inference.html"><a href="inference.html#overview-9"><i class="fa fa-check"></i><b>10.1</b> Overview</a></li>
<li class="chapter" data-level="10.2" data-path="inference.html"><a href="inference.html#chapter-learning-objectives-9"><i class="fa fa-check"></i><b>10.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="10.3" data-path="inference.html"><a href="inference.html#why-do-we-need-sampling"><i class="fa fa-check"></i><b>10.3</b> Why do we need sampling?</a></li>
<li class="chapter" data-level="10.4" data-path="inference.html"><a href="inference.html#sampling-distributions"><i class="fa fa-check"></i><b>10.4</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="inference.html"><a href="inference.html#sampling-distributions-for-proportions"><i class="fa fa-check"></i><b>10.4.1</b> Sampling distributions for proportions</a></li>
<li class="chapter" data-level="10.4.2" data-path="inference.html"><a href="inference.html#sampling-distributions-for-means"><i class="fa fa-check"></i><b>10.4.2</b> Sampling distributions for means</a></li>
<li class="chapter" data-level="10.4.3" data-path="inference.html"><a href="inference.html#summary-2"><i class="fa fa-check"></i><b>10.4.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="inference.html"><a href="inference.html#bootstrapping"><i class="fa fa-check"></i><b>10.5</b> Bootstrapping</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="inference.html"><a href="inference.html#overview-10"><i class="fa fa-check"></i><b>10.5.1</b> Overview</a></li>
<li class="chapter" data-level="10.5.2" data-path="inference.html"><a href="inference.html#bootstrapping-in-r"><i class="fa fa-check"></i><b>10.5.2</b> Bootstrapping in R</a></li>
<li class="chapter" data-level="10.5.3" data-path="inference.html"><a href="inference.html#using-the-bootstrap-to-calculate-a-plausible-range"><i class="fa fa-check"></i><b>10.5.3</b> Using the bootstrap to calculate a plausible range</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="inference.html"><a href="inference.html#exercises-9"><i class="fa fa-check"></i><b>10.6</b> Exercises</a></li>
<li class="chapter" data-level="10.7" data-path="inference.html"><a href="inference.html#additional-resources-6"><i class="fa fa-check"></i><b>10.7</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="jupyter.html"><a href="jupyter.html"><i class="fa fa-check"></i><b>11</b> Combining code and text with Jupyter</a>
<ul>
<li class="chapter" data-level="11.1" data-path="jupyter.html"><a href="jupyter.html#overview-11"><i class="fa fa-check"></i><b>11.1</b> Overview</a></li>
<li class="chapter" data-level="11.2" data-path="jupyter.html"><a href="jupyter.html#chapter-learning-objectives-10"><i class="fa fa-check"></i><b>11.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="11.3" data-path="jupyter.html"><a href="jupyter.html#jupyter-1"><i class="fa fa-check"></i><b>11.3</b> Jupyter</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="jupyter.html"><a href="jupyter.html#accessing-jupyter"><i class="fa fa-check"></i><b>11.3.1</b> Accessing Jupyter</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="jupyter.html"><a href="jupyter.html#code-cells"><i class="fa fa-check"></i><b>11.4</b> Code cells</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="jupyter.html"><a href="jupyter.html#executing-code-cells"><i class="fa fa-check"></i><b>11.4.1</b> Executing code cells</a></li>
<li class="chapter" data-level="11.4.2" data-path="jupyter.html"><a href="jupyter.html#the-kernel"><i class="fa fa-check"></i><b>11.4.2</b> The Kernel</a></li>
<li class="chapter" data-level="11.4.3" data-path="jupyter.html"><a href="jupyter.html#creating-new-code-cells"><i class="fa fa-check"></i><b>11.4.3</b> Creating new code cells</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="jupyter.html"><a href="jupyter.html#markdown-cells"><i class="fa fa-check"></i><b>11.5</b> Markdown cells</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="jupyter.html"><a href="jupyter.html#editing-markdown-cells"><i class="fa fa-check"></i><b>11.5.1</b> Editing Markdown cells</a></li>
<li class="chapter" data-level="11.5.2" data-path="jupyter.html"><a href="jupyter.html#creating-new-markdown-cells"><i class="fa fa-check"></i><b>11.5.2</b> Creating new Markdown cells</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="jupyter.html"><a href="jupyter.html#saving-your-work"><i class="fa fa-check"></i><b>11.6</b> Saving your work</a></li>
<li class="chapter" data-level="11.7" data-path="jupyter.html"><a href="jupyter.html#best-practices-for-running-a-notebook"><i class="fa fa-check"></i><b>11.7</b> Best practices for running a notebook</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="jupyter.html"><a href="jupyter.html#best-practices-for-executing-code-cells"><i class="fa fa-check"></i><b>11.7.1</b> Best practices for executing code cells</a></li>
<li class="chapter" data-level="11.7.2" data-path="jupyter.html"><a href="jupyter.html#best-practices-for-including-r-packages-in-notebooks"><i class="fa fa-check"></i><b>11.7.2</b> Best practices for including R packages in notebooks</a></li>
<li class="chapter" data-level="11.7.3" data-path="jupyter.html"><a href="jupyter.html#summary-of-best-practices-for-running-a-notebook"><i class="fa fa-check"></i><b>11.7.3</b> Summary of best practices for running a notebook</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="jupyter.html"><a href="jupyter.html#exploring-data-files"><i class="fa fa-check"></i><b>11.8</b> Exploring data files</a></li>
<li class="chapter" data-level="11.9" data-path="jupyter.html"><a href="jupyter.html#exporting-to-a-different-file-format"><i class="fa fa-check"></i><b>11.9</b> Exporting to a different file format</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="jupyter.html"><a href="jupyter.html#exporting-to-html"><i class="fa fa-check"></i><b>11.9.1</b> Exporting to HTML</a></li>
<li class="chapter" data-level="11.9.2" data-path="jupyter.html"><a href="jupyter.html#exporting-to-pdf"><i class="fa fa-check"></i><b>11.9.2</b> Exporting to PDF</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="jupyter.html"><a href="jupyter.html#creating-a-new-jupyter-notebook"><i class="fa fa-check"></i><b>11.10</b> Creating a new Jupyter notebook</a></li>
<li class="chapter" data-level="11.11" data-path="jupyter.html"><a href="jupyter.html#additional-resources-7"><i class="fa fa-check"></i><b>11.11</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="version-control.html"><a href="version-control.html"><i class="fa fa-check"></i><b>12</b> Collaboration with version control</a>
<ul>
<li class="chapter" data-level="12.1" data-path="version-control.html"><a href="version-control.html#overview-12"><i class="fa fa-check"></i><b>12.1</b> Overview</a></li>
<li class="chapter" data-level="12.2" data-path="version-control.html"><a href="version-control.html#chapter-learning-objectives-11"><i class="fa fa-check"></i><b>12.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="12.3" data-path="version-control.html"><a href="version-control.html#what-is-version-control-and-why-should-i-use-it"><i class="fa fa-check"></i><b>12.3</b> What is version control, and why should I use it?</a></li>
<li class="chapter" data-level="12.4" data-path="version-control.html"><a href="version-control.html#version-control-repositories"><i class="fa fa-check"></i><b>12.4</b> Version control repositories</a></li>
<li class="chapter" data-level="12.5" data-path="version-control.html"><a href="version-control.html#version-control-workflows"><i class="fa fa-check"></i><b>12.5</b> Version control workflows</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="version-control.html"><a href="version-control.html#commit-changes"><i class="fa fa-check"></i><b>12.5.1</b> Committing changes to a local repository</a></li>
<li class="chapter" data-level="12.5.2" data-path="version-control.html"><a href="version-control.html#pushing-changes-to-a-remote-repository"><i class="fa fa-check"></i><b>12.5.2</b> Pushing changes to a remote repository</a></li>
<li class="chapter" data-level="12.5.3" data-path="version-control.html"><a href="version-control.html#pulling-changes-from-a-remote-repository"><i class="fa fa-check"></i><b>12.5.3</b> Pulling changes from a remote repository</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="version-control.html"><a href="version-control.html#working-with-remote-repositories-using-github"><i class="fa fa-check"></i><b>12.6</b> Working with remote repositories using GitHub</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="version-control.html"><a href="version-control.html#creating-a-remote-repository-on-github"><i class="fa fa-check"></i><b>12.6.1</b> Creating a remote repository on GitHub</a></li>
<li class="chapter" data-level="12.6.2" data-path="version-control.html"><a href="version-control.html#editing-files-on-github-with-the-pen-tool"><i class="fa fa-check"></i><b>12.6.2</b> Editing files on GitHub with the pen tool</a></li>
<li class="chapter" data-level="12.6.3" data-path="version-control.html"><a href="version-control.html#creating-files-on-github-with-the-add-file-menu"><i class="fa fa-check"></i><b>12.6.3</b> Creating files on GitHub with the Add file menu</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="version-control.html"><a href="version-control.html#local-repo-jupyter"><i class="fa fa-check"></i><b>12.7</b> Working with local repositories using Jupyter</a>
<ul>
<li class="chapter" data-level="12.7.1" data-path="version-control.html"><a href="version-control.html#generating-a-github-personal-access-token"><i class="fa fa-check"></i><b>12.7.1</b> Generating a GitHub personal access token</a></li>
<li class="chapter" data-level="12.7.2" data-path="version-control.html"><a href="version-control.html#cloning-a-repository-using-jupyter"><i class="fa fa-check"></i><b>12.7.2</b> Cloning a repository using Jupyter</a></li>
<li class="chapter" data-level="12.7.3" data-path="version-control.html"><a href="version-control.html#specifying-files-to-commit"><i class="fa fa-check"></i><b>12.7.3</b> Specifying files to commit</a></li>
<li class="chapter" data-level="12.7.4" data-path="version-control.html"><a href="version-control.html#making-the-commit"><i class="fa fa-check"></i><b>12.7.4</b> Making the commit</a></li>
<li class="chapter" data-level="12.7.5" data-path="version-control.html"><a href="version-control.html#pushing-the-commits-to-github"><i class="fa fa-check"></i><b>12.7.5</b> Pushing the commits to GitHub</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="version-control.html"><a href="version-control.html#collaboration"><i class="fa fa-check"></i><b>12.8</b> Collaboration</a>
<ul>
<li class="chapter" data-level="12.8.1" data-path="version-control.html"><a href="version-control.html#giving-collaborators-access-to-your-project"><i class="fa fa-check"></i><b>12.8.1</b> Giving collaborators access to your project</a></li>
<li class="chapter" data-level="12.8.2" data-path="version-control.html"><a href="version-control.html#pulling-changes-from-github-using-jupyter"><i class="fa fa-check"></i><b>12.8.2</b> Pulling changes from GitHub using Jupyter</a></li>
<li class="chapter" data-level="12.8.3" data-path="version-control.html"><a href="version-control.html#handling-merge-conflicts"><i class="fa fa-check"></i><b>12.8.3</b> Handling merge conflicts</a></li>
<li class="chapter" data-level="12.8.4" data-path="version-control.html"><a href="version-control.html#communicating-using-github-issues"><i class="fa fa-check"></i><b>12.8.4</b> Communicating using GitHub issues</a></li>
</ul></li>
<li class="chapter" data-level="12.9" data-path="version-control.html"><a href="version-control.html#exercises-10"><i class="fa fa-check"></i><b>12.9</b> Exercises</a></li>
<li class="chapter" data-level="12.10" data-path="version-control.html"><a href="version-control.html#vc-add-res"><i class="fa fa-check"></i><b>12.10</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="setup.html"><a href="setup.html"><i class="fa fa-check"></i><b>13</b> Setting up your computer</a>
<ul>
<li class="chapter" data-level="13.1" data-path="setup.html"><a href="setup.html#overview-13"><i class="fa fa-check"></i><b>13.1</b> Overview</a></li>
<li class="chapter" data-level="13.2" data-path="setup.html"><a href="setup.html#chapter-learning-objectives-12"><i class="fa fa-check"></i><b>13.2</b> Chapter learning objectives</a></li>
<li class="chapter" data-level="13.3" data-path="setup.html"><a href="setup.html#obtaining-the-worksheets-for-this-book"><i class="fa fa-check"></i><b>13.3</b> Obtaining the worksheets for this book</a></li>
<li class="chapter" data-level="13.4" data-path="setup.html"><a href="setup.html#working-with-docker"><i class="fa fa-check"></i><b>13.4</b> Working with Docker</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="setup.html"><a href="setup.html#windows"><i class="fa fa-check"></i><b>13.4.1</b> Windows</a></li>
<li class="chapter" data-level="13.4.2" data-path="setup.html"><a href="setup.html#macos"><i class="fa fa-check"></i><b>13.4.2</b> MacOS</a></li>
<li class="chapter" data-level="13.4.3" data-path="setup.html"><a href="setup.html#ubuntu"><i class="fa fa-check"></i><b>13.4.3</b> Ubuntu</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="setup.html"><a href="setup.html#working-with-jupyterlab-desktop"><i class="fa fa-check"></i><b>13.5</b> Working with JupyterLab Desktop</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="setup.html"><a href="setup.html#windows-1"><i class="fa fa-check"></i><b>13.5.1</b> Windows</a></li>
<li class="chapter" data-level="13.5.2" data-path="setup.html"><a href="setup.html#macos-1"><i class="fa fa-check"></i><b>13.5.2</b> MacOS</a></li>
<li class="chapter" data-level="13.5.3" data-path="setup.html"><a href="setup.html#ubuntu-1"><i class="fa fa-check"></i><b>13.5.3</b> Ubuntu</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><p><img src="img/frontmatter/ds-a-first-intro-graphic.jpg" />
Data Science</p></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression2" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Regression II: linear regression<a href="regression2.html#regression2" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="overview-7" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Overview<a href="regression2.html#overview-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Up to this point, we have solved all of our predictive problemsboth classification
and regressionusing K-nearest neighbors (K-NN)-based approaches. In the context of regression,
there is another commonly used method known as <em>linear regression</em>. This chapter provides an introduction
to the basic concept of linear regression, shows how to use <code>tidymodels</code> to perform linear regression in R,
and characterizes its strengths and weaknesses compared to K-NN regression. The focus is, as usual,
on the case where there is a single predictor and single response variable of interest; but the chapter
concludes with an example using <em>multivariable linear regression</em> when there is more than one
predictor.</p>
</div>
<div id="chapter-learning-objectives-7" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Chapter learning objectives<a href="regression2.html#chapter-learning-objectives-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>By the end of the chapter, readers will be able to do the following:</p>
<ul>
<li>Use R to fit simple and multivariable linear regression models on training data.</li>
<li>Evaluate the linear regression model on test data.</li>
<li>Compare and contrast predictions obtained from K-nearest neighbors regression to those obtained using linear regression from the same data set.</li>
<li>Describe how linear regression is affected by outliers and multicollinearity.</li>
</ul>
</div>
<div id="simple-linear-regression" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Simple linear regression<a href="regression2.html#simple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>At the end of the previous chapter, we noted some limitations of K-NN regression.
While the method is simple and easy to understand, K-NN regression does not
predict well beyond the range of the predictors in the training data, and
the method gets significantly slower as the training data set grows.
Fortunately, there is an alternative to K-NN regression<em>linear regression</em>that addresses
both of these limitations. Linear regression is also very commonly
used in practice because it provides an interpretable mathematical equation that describes
the relationship between the predictor and response variables. In this first part of the chapter, we will focus on <em>simple</em> linear regression,
which involves only one predictor variable and one response variable; later on, we will consider
<em>multivariable</em> linear regression, which involves multiple predictor variables.
Like K-NN regression, simple linear regression involves
predicting a numerical response variable (like race time, house price, or height);
but <em>how</em> it makes those predictions for a new observation is quite different from K-NN regression.
Instead of looking at the K nearest neighbors and averaging
over their values for a prediction, in simple linear regression, we create a
straight line of best fit through the training data and then
look up the prediction using the line.</p>
<blockquote>
<p><strong>Note:</strong> Although we did not cover it in earlier chapters, there
is another popular method for classification called <em>logistic
regression</em> (it is used for classification even though the name, somewhat confusingly,
has the word regression in it). In logistic regressionsimilar to linear regressionyou
fit the model to the training data and then look up the prediction for each new observation.
Logistic regression and K-NN classification have an advantage/disadvantage comparison
similar to that of linear regression and K-NN
regression. It is useful to have a good understanding of linear regression before learning about
logistic regression. After reading this chapter, see the Additional Resources section at the end of the
classification chapters to learn more about logistic regression. </p>
</blockquote>
<p>Lets return to the Sacramento housing data from Chapter <a href="regression1.html#regression1">7</a> to learn
how to apply linear regression and compare it to K-NN regression. For now, we
will consider
a smaller version of the housing data to help make our visualizations clear.
Recall our predictive question: can we use the size of a house in the Sacramento, CA area to predict
its sale price? In particular, recall that we have come across a new 2,000 square-foot house we are interested
in purchasing with an advertised list price of
$350,000. Should we offer the list price, or is that over/undervalued?
To answer this question using simple linear regression, we use the data we have
to draw the straight line of best fit through our existing data points.
The small subset of data as well as the line of best fit are shown
in Figure <a href="regression2.html#fig:08-lin-reg1">8.1</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-lin-reg1"></span>
<img src="_main_files/figure-html/08-lin-reg1-1.png" alt="Scatter plot of sale price versus size with line of best fit for subset of the Sacramento housing data." width="432"  />
<p class="caption">
Figure 8.1: Scatter plot of sale price versus size with line of best fit for subset of the Sacramento housing data.
</p>
</div>
<p>The equation for the straight line is: </p>
<p><span class="math display">\[\text{house sale price} = \beta_0 + \beta_1 \cdot (\text{house size}),\]</span>
where</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span> is the <em>vertical intercept</em> of the line (the price when house size is 0)</li>
<li><span class="math inline">\(\beta_1\)</span> is the <em>slope</em> of the line (how quickly the price increases as you increase house size)</li>
</ul>
<p>Therefore using the data to find the line of best fit is equivalent to finding coefficients
<span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> that <em>parametrize</em> (correspond to) the line of best fit.
Now of course, in this particular problem, the idea of a 0 square-foot house is a bit silly;
but you can think of <span class="math inline">\(\beta_0\)</span> here as the base price, and
<span class="math inline">\(\beta_1\)</span> as the increase in price for each square foot of space.
Lets push this thought even further: what would happen in the equation for the line if you
tried to evaluate the price of a house with size 6 <em>million</em> square feet?
Or what about <em>negative</em> 2,000 square feet? As it turns out, nothing in the formula breaks; linear
regression will happily make predictions for nonsensical predictor values if you ask it to. But even though
you <em>can</em> make these wild predictions, you shouldnt. You should only make predictions roughly within
the range of your original data, and perhaps a bit beyond it only if it makes sense. For example,
the data in Figure <a href="regression2.html#fig:08-lin-reg1">8.1</a> only reaches around 800 square feet on the low end, but
it would probably be reasonable to use the linear regression model to make a prediction at 600 square feet, say.</p>
<p>Back to the example! Once we have the coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>, we can use the equation
above to evaluate the predicted sale price given the value we have for the
predictor variablehere 2,000 square feet. Figure
<a href="regression2.html#fig:08-lin-reg2">8.2</a> demonstrates this process.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-lin-reg2"></span>
<img src="_main_files/figure-html/08-lin-reg2-1.png" alt="Scatter plot of sale price versus size with line of best fit and a red dot at the predicted sale price for a 2,000 square-foot home." width="432" />
<p class="caption">
Figure 8.2: Scatter plot of sale price versus size with line of best fit and a red dot at the predicted sale price for a 2,000 square-foot home.
</p>
</div>
<p>By using simple linear regression on this small data set to predict the sale price
for a 2,000 square-foot house, we get a predicted value of
$295,564. But wait a minute how
exactly does simple linear regression choose the line of best fit? Many
different lines could be drawn through the data points.
Some plausible examples are shown in Figure <a href="regression2.html#fig:08-several-lines">8.3</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-several-lines"></span>
<img src="_main_files/figure-html/08-several-lines-1.png" alt="Scatter plot of sale price versus size with many possible lines that could be drawn through the data points." width="432" />
<p class="caption">
Figure 8.3: Scatter plot of sale price versus size with many possible lines that could be drawn through the data points.
</p>
</div>
<p>Simple linear regression chooses the straight line of best fit by choosing
the line that minimizes the <strong>average squared vertical distance</strong> between itself and
each of the observed data points in the training data (equivalent to minimizing the RMSE).
Figure <a href="regression2.html#fig:08-verticalDistToMin">8.4</a> illustrates these vertical distances as red lines. Finally, to assess the predictive
accuracy of a simple linear regression model,
we use RMSPEthe same measure of predictive performance we used with K-NN regression.
</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-verticalDistToMin"></span>
<img src="_main_files/figure-html/08-verticalDistToMin-1.png" alt="Scatter plot of sale price versus size with red lines denoting the vertical distances between the predicted values and the observed data points." width="432" />
<p class="caption">
Figure 8.4: Scatter plot of sale price versus size with red lines denoting the vertical distances between the predicted values and the observed data points.
</p>
</div>
</div>
<div id="linear-regression-in-r" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Linear regression in R<a href="regression2.html#linear-regression-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can perform simple linear regression in R using <code>tidymodels</code> in a
very similar manner to how we performed K-NN regression.
To do this, instead of creating a <code>nearest_neighbor</code> model specification with
the <code>kknn</code> engine, we use a <code>linear_reg</code> model specification
with the <code>lm</code> engine. Another difference is that we do not need to choose <span class="math inline">\(K\)</span> in the
context of linear regression, and so we do not need to perform cross-validation.
Below we illustrate how we can use the usual <code>tidymodels</code> workflow to predict house sale
price given house size using a simple linear regression approach using the full
Sacramento real estate data set.</p>
<p>As usual, we start by loading packages, setting the seed, loading data, and putting some test data away in a lock box that we
can come back to after we choose our final model. Lets take care of that now.
</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="regression2.html#cb413-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb413-2"><a href="regression2.html#cb413-2" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb413-3"><a href="regression2.html#cb413-3" tabindex="-1"></a></span>
<span id="cb413-4"><a href="regression2.html#cb413-4" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">7</span>)</span>
<span id="cb413-5"><a href="regression2.html#cb413-5" tabindex="-1"></a></span>
<span id="cb413-6"><a href="regression2.html#cb413-6" tabindex="-1"></a>sacramento <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/sacramento.csv&quot;</span>)</span>
<span id="cb413-7"><a href="regression2.html#cb413-7" tabindex="-1"></a></span>
<span id="cb413-8"><a href="regression2.html#cb413-8" tabindex="-1"></a>sacramento_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(sacramento, <span class="at">prop =</span> <span class="fl">0.75</span>, <span class="at">strata =</span> price)</span>
<span id="cb413-9"><a href="regression2.html#cb413-9" tabindex="-1"></a>sacramento_train <span class="ot">&lt;-</span> <span class="fu">training</span>(sacramento_split)</span>
<span id="cb413-10"><a href="regression2.html#cb413-10" tabindex="-1"></a>sacramento_test <span class="ot">&lt;-</span> <span class="fu">testing</span>(sacramento_split)</span></code></pre></div>
<p>Now that we have our training data, we will create the model specification
and recipe, and fit our simple linear regression model:</p>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="regression2.html#cb414-1" tabindex="-1"></a>lm_spec <span class="ot">&lt;-</span> <span class="fu">linear_reg</span>() <span class="sc">|&gt;</span></span>
<span id="cb414-2"><a href="regression2.html#cb414-2" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;lm&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb414-3"><a href="regression2.html#cb414-3" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;regression&quot;</span>)</span>
<span id="cb414-4"><a href="regression2.html#cb414-4" tabindex="-1"></a></span>
<span id="cb414-5"><a href="regression2.html#cb414-5" tabindex="-1"></a>lm_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(price <span class="sc">~</span> sqft, <span class="at">data =</span> sacramento_train)</span>
<span id="cb414-6"><a href="regression2.html#cb414-6" tabindex="-1"></a></span>
<span id="cb414-7"><a href="regression2.html#cb414-7" tabindex="-1"></a>lm_fit <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb414-8"><a href="regression2.html#cb414-8" tabindex="-1"></a>  <span class="fu">add_recipe</span>(lm_recipe) <span class="sc">|&gt;</span></span>
<span id="cb414-9"><a href="regression2.html#cb414-9" tabindex="-1"></a>  <span class="fu">add_model</span>(lm_spec) <span class="sc">|&gt;</span></span>
<span id="cb414-10"><a href="regression2.html#cb414-10" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> sacramento_train)</span>
<span id="cb414-11"><a href="regression2.html#cb414-11" tabindex="-1"></a></span>
<span id="cb414-12"><a href="regression2.html#cb414-12" tabindex="-1"></a>lm_fit</span></code></pre></div>
<pre><code>##  Workflow [trained] 
## Preprocessor: Recipe
## Model: linear_reg()
## 
##  Preprocessor 
## 0 Recipe Steps
## 
##  Model 
## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
## (Intercept)         sqft  
##     18450.3        134.8</code></pre>
<blockquote>
<p><strong>Note:</strong> An additional difference that you will notice here is that we do
not standardize (i.e., scale and center) our
predictors. In K-nearest neighbors models, recall that the model fit changes
depending on whether we standardize first or not. In linear regression,
standardization does not affect the fit (it <em>does</em> affect the coefficients in
the equation, though!). So you can standardize if you wantit wont
hurt anythingbut if you leave the predictors in their original form,
the best fit coefficients are usually easier to interpret afterward.</p>
</blockquote>
<p>Our coefficients are
(intercept) <span class="math inline">\(\beta_0=\)</span> 18450
and (slope) <span class="math inline">\(\beta_1=\)</span> 135.
This means that the equation of the line of best fit is</p>
<p><span class="math display">\[\text{house sale price} = 18450 + 135\cdot (\text{house size}).\]</span></p>
<p>In other words, the model predicts that houses
start at $18,450 for 0 square feet, and that
every extra square foot increases the cost of
the house by $135. Finally,
we predict on the test data set to assess how well our model does:</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="regression2.html#cb416-1" tabindex="-1"></a>lm_test_results <span class="ot">&lt;-</span> lm_fit <span class="sc">|&gt;</span></span>
<span id="cb416-2"><a href="regression2.html#cb416-2" tabindex="-1"></a>  <span class="fu">predict</span>(sacramento_test) <span class="sc">|&gt;</span></span>
<span id="cb416-3"><a href="regression2.html#cb416-3" tabindex="-1"></a>  <span class="fu">bind_cols</span>(sacramento_test) <span class="sc">|&gt;</span></span>
<span id="cb416-4"><a href="regression2.html#cb416-4" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> price, <span class="at">estimate =</span> .pred)</span>
<span id="cb416-5"><a href="regression2.html#cb416-5" tabindex="-1"></a></span>
<span id="cb416-6"><a href="regression2.html#cb416-6" tabindex="-1"></a>lm_test_results</span></code></pre></div>
<pre><code>## # A tibble: 3  3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard   88528.   
## 2 rsq     standard       0.608
## 3 mae     standard   61892.</code></pre>
<p>Our final models test error as assessed by RMSPE
is $88,528.
Remember that this is in units of the response variable, and here that
is US Dollars (USD). Does this mean our model is good at predicting house
sale price based off of the predictor of home size? Again, answering this is
tricky and requires knowledge of how you intend to use the prediction.</p>
<p>To visualize the simple linear regression model, we can plot the predicted house
sale price across all possible house sizes we might encounter.
Since our model is linear,
we only need to compute the predicted price of the minimum and maximum house size,
and then connect them with a straight line.
We superimpose this prediction line on a scatter
plot of the original housing price data,
so that we can qualitatively assess if the model seems to fit the data well.
Figure <a href="regression2.html#fig:08-lm-predict-all">8.5</a> displays the result.</p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="regression2.html#cb418-1" tabindex="-1"></a>sqft_prediction_grid <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb418-2"><a href="regression2.html#cb418-2" tabindex="-1"></a>    <span class="at">sqft =</span> <span class="fu">c</span>(</span>
<span id="cb418-3"><a href="regression2.html#cb418-3" tabindex="-1"></a>        sacramento <span class="sc">|&gt;</span> <span class="fu">select</span>(sqft) <span class="sc">|&gt;</span> <span class="fu">min</span>(),</span>
<span id="cb418-4"><a href="regression2.html#cb418-4" tabindex="-1"></a>        sacramento <span class="sc">|&gt;</span> <span class="fu">select</span>(sqft) <span class="sc">|&gt;</span> <span class="fu">max</span>()</span>
<span id="cb418-5"><a href="regression2.html#cb418-5" tabindex="-1"></a>    )</span>
<span id="cb418-6"><a href="regression2.html#cb418-6" tabindex="-1"></a>)</span>
<span id="cb418-7"><a href="regression2.html#cb418-7" tabindex="-1"></a></span>
<span id="cb418-8"><a href="regression2.html#cb418-8" tabindex="-1"></a>sacr_preds <span class="ot">&lt;-</span> lm_fit <span class="sc">|&gt;</span></span>
<span id="cb418-9"><a href="regression2.html#cb418-9" tabindex="-1"></a>  <span class="fu">predict</span>(sqft_prediction_grid) <span class="sc">|&gt;</span></span>
<span id="cb418-10"><a href="regression2.html#cb418-10" tabindex="-1"></a>  <span class="fu">bind_cols</span>(sqft_prediction_grid)</span>
<span id="cb418-11"><a href="regression2.html#cb418-11" tabindex="-1"></a></span>
<span id="cb418-12"><a href="regression2.html#cb418-12" tabindex="-1"></a>lm_plot_final <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sacramento, <span class="fu">aes</span>(<span class="at">x =</span> sqft, <span class="at">y =</span> price)) <span class="sc">+</span></span>
<span id="cb418-13"><a href="regression2.html#cb418-13" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb418-14"><a href="regression2.html#cb418-14" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> sacr_preds,</span>
<span id="cb418-15"><a href="regression2.html#cb418-15" tabindex="-1"></a>            <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> sqft, <span class="at">y =</span> .pred),</span>
<span id="cb418-16"><a href="regression2.html#cb418-16" tabindex="-1"></a>            <span class="at">color =</span> <span class="st">&quot;steelblue&quot;</span>,</span>
<span id="cb418-17"><a href="regression2.html#cb418-17" tabindex="-1"></a>            <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb418-18"><a href="regression2.html#cb418-18" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;House size (square feet)&quot;</span>) <span class="sc">+</span></span>
<span id="cb418-19"><a href="regression2.html#cb418-19" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Price (USD)&quot;</span>) <span class="sc">+</span></span>
<span id="cb418-20"><a href="regression2.html#cb418-20" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> <span class="fu">dollar_format</span>()) <span class="sc">+</span></span>
<span id="cb418-21"><a href="regression2.html#cb418-21" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">12</span>))</span>
<span id="cb418-22"><a href="regression2.html#cb418-22" tabindex="-1"></a></span>
<span id="cb418-23"><a href="regression2.html#cb418-23" tabindex="-1"></a>lm_plot_final</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-lm-predict-all"></span>
<img src="_main_files/figure-html/08-lm-predict-all-1.png" alt="Scatter plot of sale price versus size with line of best fit for the full Sacramento housing data." width="432"  />
<p class="caption">
Figure 8.5: Scatter plot of sale price versus size with line of best fit for the full Sacramento housing data.
</p>
</div>
<p>We can extract the coefficients from our model by accessing the
fit object that is output by the <code>fit</code> function; we first have to extract
it from the workflow using the <code>extract_fit_parsnip</code> function, and then apply
the <code>tidy</code> function to convert the result into a data frame:</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="regression2.html#cb419-1" tabindex="-1"></a>coeffs <span class="ot">&lt;-</span> lm_fit <span class="sc">|&gt;</span></span>
<span id="cb419-2"><a href="regression2.html#cb419-2" tabindex="-1"></a>             <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span></span>
<span id="cb419-3"><a href="regression2.html#cb419-3" tabindex="-1"></a>             <span class="fu">tidy</span>()</span>
<span id="cb419-4"><a href="regression2.html#cb419-4" tabindex="-1"></a></span>
<span id="cb419-5"><a href="regression2.html#cb419-5" tabindex="-1"></a>coeffs</span></code></pre></div>
<pre><code>## # A tibble: 2  5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)   18450.   7916.        2.33 2.01e-  2
## 2 sqft            135.      4.31     31.2  1.37e-134</code></pre>
</div>
<div id="comparing-simple-linear-and-k-nn-regression" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Comparing simple linear and K-NN regression<a href="regression2.html#comparing-simple-linear-and-k-nn-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we have a general understanding of both simple linear and K-NN
regression, we can start to compare and contrast these methods as well as the
predictions made by them. To start, lets look at the visualization of the
simple linear regression model predictions for the Sacramento real estate data
(predicting price from house size) and the best K-NN regression model
obtained from the same problem, shown in Figure <a href="regression2.html#fig:08-compareRegression">8.6</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-compareRegression"></span>
<img src="_main_files/figure-html/08-compareRegression-1.png" alt="Comparison of simple linear regression and K-NN regression." width="960" />
<p class="caption">
Figure 8.6: Comparison of simple linear regression and K-NN regression.
</p>
</div>
<p>What differences do we observe in Figure <a href="regression2.html#fig:08-compareRegression">8.6</a>? One obvious
difference is the shape of the blue lines. In simple linear regression we are
restricted to a straight line, whereas in K-NN regression our line is much more
flexible and can be quite wiggly. But there is a major interpretability advantage in limiting the
model to a straight line. A
straight line can be defined by two numbers, the
vertical intercept and the slope. The intercept tells us what the prediction is when
all of the predictors are equal to 0; and the slope tells us what unit increase in the response
variable we predict given a unit increase in the predictor
variable. K-NN regression, as simple as it is to implement and understand, has no such
interpretability from its wiggly line.</p>
<p>There can, however, also be a disadvantage to using a simple linear regression
model in some cases, particularly when the relationship between the response and
the predictor is not linear, but instead some other shape (e.g., curved or oscillating). In
these cases the prediction model from a simple linear regression
will underfit, meaning that model/predicted values do not
match the actual observed values very well. Such a model would probably have a
quite high RMSE when assessing model goodness of fit on the training data and
a quite high RMSPE when assessing model prediction quality on a test data
set. On such a data set, K-NN regression may fare better. Additionally, there
are other types of regression you can learn about in future books that may do
even better at predicting with such data.</p>
<p>How do these two models compare on the Sacramento house prices data set? In
Figure <a href="regression2.html#fig:08-compareRegression">8.6</a>, we also printed the RMSPE as calculated from
predicting on the test data set that was not used to train/fit the models. The RMSPE for the simple linear
regression model is slightly lower than the RMSPE for the K-NN regression model.
Considering that the simple linear regression model is also more interpretable,
if we were comparing these in practice we would likely choose to use the simple
linear regression model.</p>
<p>Finally, note that the K-NN regression model becomes flat
at the left and right boundaries of the data, while the linear model
predicts a constant slope. Predicting outside the range of the observed
data is known as <em>extrapolation</em>; K-NN and linear models behave quite differently
when extrapolating. Depending on the application, the flat
or constant slope trend may make more sense. For example, if our housing
data were slightly different, the linear model may have actually predicted
a <em>negative</em> price for a small house (if the intercept <span class="math inline">\(\beta_0\)</span> was negative),
which obviously does not match reality. On the other hand, the trend of increasing
house size corresponding to increasing house price probably continues for large houses,
so the flat extrapolation of K-NN likely does not match reality.</p>
</div>
<div id="multivariable-linear-regression" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> Multivariable linear regression<a href="regression2.html#multivariable-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As in K-NN classification and K-NN regression, we can move beyond the simple
case of only one predictor to the case with multiple predictors,
known as <em>multivariable linear regression</em>.
To do this, we follow a very similar approach to what we did for
K-NN regression: we just add more predictors to the model formula in the
recipe. But recall that we do not need to use cross-validation to choose any parameters,
nor do we need to standardize (i.e., center and scale) the data for linear regression.
Note once again that we have the same concerns regarding multiple predictors
as in the settings of multivariable K-NN regression and classification: having more predictors is <strong>not</strong> always
better. But because the same predictor selection
algorithm from the classification chapter extends to the setting of linear regression,
it will not be covered again in this chapter.</p>
<p>We will demonstrate multivariable linear regression using the Sacramento real estate
data with both house size
(measured in square feet) as well as number of bedrooms as our predictors, and
continue to use house sale price as our response variable. We will start by
changing the formula in the recipe to
include both the <code>sqft</code> and <code>beds</code> variables as predictors:</p>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="regression2.html#cb421-1" tabindex="-1"></a>mlm_recipe <span class="ot">&lt;-</span> <span class="fu">recipe</span>(price <span class="sc">~</span> sqft <span class="sc">+</span> beds, <span class="at">data =</span> sacramento_train)</span></code></pre></div>
<p>Now we can build our workflow and fit the model:</p>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="regression2.html#cb422-1" tabindex="-1"></a>mlm_fit <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">|&gt;</span></span>
<span id="cb422-2"><a href="regression2.html#cb422-2" tabindex="-1"></a>  <span class="fu">add_recipe</span>(mlm_recipe) <span class="sc">|&gt;</span></span>
<span id="cb422-3"><a href="regression2.html#cb422-3" tabindex="-1"></a>  <span class="fu">add_model</span>(lm_spec) <span class="sc">|&gt;</span></span>
<span id="cb422-4"><a href="regression2.html#cb422-4" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> sacramento_train)</span>
<span id="cb422-5"><a href="regression2.html#cb422-5" tabindex="-1"></a></span>
<span id="cb422-6"><a href="regression2.html#cb422-6" tabindex="-1"></a>mlm_fit</span></code></pre></div>
<pre><code>##  Workflow [trained] 
## Preprocessor: Recipe
## Model: linear_reg()
## 
##  Preprocessor 
## 0 Recipe Steps
## 
##  Model 
## 
## Call:
## stats::lm(formula = ..y ~ ., data = data)
## 
## Coefficients:
## (Intercept)         sqft         beds  
##     72547.8        160.6     -29644.3</code></pre>
<p>And finally, we make predictions on the test data set to assess the quality of our model:</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="regression2.html#cb424-1" tabindex="-1"></a>lm_mult_test_results <span class="ot">&lt;-</span> mlm_fit <span class="sc">|&gt;</span></span>
<span id="cb424-2"><a href="regression2.html#cb424-2" tabindex="-1"></a>  <span class="fu">predict</span>(sacramento_test) <span class="sc">|&gt;</span></span>
<span id="cb424-3"><a href="regression2.html#cb424-3" tabindex="-1"></a>  <span class="fu">bind_cols</span>(sacramento_test) <span class="sc">|&gt;</span></span>
<span id="cb424-4"><a href="regression2.html#cb424-4" tabindex="-1"></a>  <span class="fu">metrics</span>(<span class="at">truth =</span> price, <span class="at">estimate =</span> .pred)</span>
<span id="cb424-5"><a href="regression2.html#cb424-5" tabindex="-1"></a></span>
<span id="cb424-6"><a href="regression2.html#cb424-6" tabindex="-1"></a>lm_mult_test_results</span></code></pre></div>
<pre><code>## # A tibble: 3  3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard   88739.   
## 2 rsq     standard       0.603
## 3 mae     standard   61732.</code></pre>
<p>Our models test error as assessed by RMSPE
is $88,739.
In the case of two predictors, we can plot the predictions made by our linear regression creates a <em>plane</em> of best fit, as
shown in Figure <a href="regression2.html#fig:08-3DlinReg">8.7</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-3DlinReg"></span>
<div class="plotly html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-d9a741287887f718de93" style="width:100%;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-d9a741287887f718de93">{"x":{"visdat":{"16c2fe79":["function () ","plotlyVisDat"],"122301ec2":["function () ","data"]},"cur_data":"122301ec2","attrs":{"122301ec2":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","marker":{"size":2,"opacity":0.40000000000000002,"color":"red"},"inherit":true},"122301ec2.1":{"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"z":{},"type":"surface","x":{},"y":{},"colorbar":{"title":"Price (USD)"},"inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"Size (sq ft)"},"zaxis":{"title":"Price (USD)"},"yaxis":{"title":"Bedrooms"}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[836,1167,796,1122,1177,941,1146,909,1289,871,1020,1022,1134,844,795,1118,1329,1240,901,1088,1119,1039,1152,1380,1116,1039,1418,1082,1472,1146,760,1304,1207,795,1099,840,746,1067,1337,924,1516,1220,722,722,1080,1039,1051,967,1050,1110,888,1120,1080,1264,1080,1266,994,1202,1039,722,1448,1183,1320,1117,1364,1310,1006,1104,810,1123,840,623,932,796,834,924,795,1250,1013,1012,795,918,1082,1404,625,888,1120,1331,1014,1448,966,779,836,1100,1207,1995,804,958,1366,696,1080,1390,1354,795,780,1587,1209,1139,1690,1245,1416,1300,1590,1516,1057,1370,1370,1166,1000,838,1080,990,861,906,1089,832,1292,810,911,1320,1410,1115,1169,1164,1341,1127,1253,1120,1118,1890,1260,1400,1264,1132,1466,1092,960,1075,1512,611,1011,1158,1092,1051,682,1161,1004,1229,1249,1161,1010,1005,1462,1269,1570,1093,962,1127,970,1000,1065,1206,1285,1543,1392,924,1056,1043,1587,1580,1955,1656,1477,1188,1590,1463,1406,1943,1172,1851,1130,1603,1479,1420,1280,1586,1362,2162,1266,1820,936,1665,1511,1590,904,1156,1321,1439,1159,1671,1716,1685,1120,1174,1393,1415,2126,1799,1308,1953,723,1376,948,1578,1317,1360,1351,1452,1162,1182,1100,1280,1280,1039,1204,1120,1638,1152,1154,1353,1329,1356,1009,1144,930,1766,1940,1776,1258,1872,1112,1856,1939,998,1758,2142,1428,1358,2475,1410,1711,1140,1410,1240,1712,1580,1029,1103,2161,1650,1320,1200,1170,1157,1410,1593,1093,1328,1273,1578,796,1386,1452,1513,1232,1578,1498,1473,1127,1144,972,2306,1479,1040,1953,984,1351,1284,1376,1300,1566,1115,1032,1419,1670,1488,1373,1381,1265,881,1917,1608,1344,1202,1859,1232,1582,904,1340,1204,1477,1497,960,1194,1428,1039,1529,1887,1294,1638,1677,1073,1231,1416,1358,1609,1968,1089,1296,1189,1371,1740,1450,1416,888,1302,1418,1462,1319,1770,1596,2136,1616,1478,1287,1277,1448,2235,2093,1193,2163,1269,1473,958,2508,1305,1591,1326,1921,1541,1018,1713,1672,1446,1284,3009,3612,2056,1993,1857,1126,1520,2800,1360,1522,1751,1475,1216,1315,2187,1129,1453,1503,1269,1176,1456,1498,2085,2170,1595,1567,2943,1253,1768,2030,1531,2056,2494,1450,2169,1527,1401,1411,2990,2307,1329,1910,1981,1739,1516,988,1555,1212,1871,1302,756,2026,1250,1187,1324,1936,2382,1798,2652,1816,3076,1844,1306,2447,1176,1182,1160,1424,1574,1830,1724,1255,1718,1808,1713,2724,2550,1928,1922,1510,960,1624,2992,1524,1248,1876,2489,1851,1637,1338,1257,2254,1441,1991,2126,1094,1462,2258,2111,1915,2367,1962,1406,1876,1235,2504,1899,1828,1438,1451,1520,2605,1196,1621,1811,1540,2647,2750,1543,2494,1650,2280,1443,1857,1735,2096,1720,2160,1282,1721,1328,1919,1982,1144,1623,2555,1577,2592,1401,1627,960,1456,1450,1358,1329,2280,1477,1685,1362,2309,2367,3516,2536,1914,1690,2725,2354,1842,1801,1961,3134,1915,2734,2110,3599,2054,1830,3440,2846,2359,3433,3615,2724,3508,2462,2900,3705,3527,2325,4878,1829,1665,3072,1449,2575,539,2208,1108,1595,2159,2295,1838,1900,3389,2190,2607,2724,3746,3969,3192,2829,3928,3577,2581,3992,3397,3881,1598,1929,2272,3117,2222,3059,2846,1829,2218,1394,1410,3468,2346,2347,1659,2590,2155,1673,2789,1606,2166,1871,1800,1683,1625,2752,1596,2716,1639,3281,1697,1993,2085,2548,2730,1939,1788,1691,2002,4246,2962,3056,3198,1905,1320,1873,3741,2660,3357,2896,2025,3788,2048,1502,1327,1800,2169,2457,2264,2004,3134,1360,1951,1276,2962,1888,2155,1744,1548,1322,2484,2212,1616,2606,2877,2960,1704,2100,1924,2295,2577,2616,1727,1485,1655,2049,3042,2875,3566,1304,2334,1493,1944,3913,3151,2787,3261,2053,2379,2480,2418,3282,4091,2806,3173,3380,1348,4090,1252,3229,3863,3901,2356,3579,3782,4400],"y":[2,3,2,3,3,2,3,3,3,1,3,2,2,2,2,3,4,4,3,3,3,2,3,3,3,2,3,3,4,4,1,2,3,2,4,2,2,3,3,3,3,2,1,1,3,3,3,2,3,3,3,3,3,3,3,3,2,3,2,2,4,4,3,3,3,4,2,3,2,2,2,2,2,2,2,2,2,3,3,3,2,2,3,4,1,2,4,3,3,4,3,2,2,2,3,4,2,2,3,3,3,4,4,2,2,4,3,2,2,3,3,3,4,5,2,3,3,3,1,2,2,2,2,2,3,2,4,2,2,3,3,3,3,3,4,4,4,3,2,4,3,3,3,2,3,3,3,3,4,1,2,4,3,3,1,3,3,3,3,3,3,2,4,3,4,3,3,3,2,3,1,3,3,3,4,2,3,2,4,4,4,4,3,3,4,3,3,4,3,4,3,4,3,3,3,3,3,4,3,3,3,2,3,4,2,3,2,3,3,3,3,4,4,3,3,3,4,4,3,4,2,2,2,4,3,3,4,3,2,3,3,4,4,3,3,3,4,3,3,3,3,3,3,3,2,4,4,4,3,4,2,4,4,3,3,3,3,4,6,3,3,3,3,3,5,4,3,3,3,3,3,3,3,3,3,3,3,3,3,4,2,3,3,3,3,4,2,3,3,3,3,4,3,2,4,1,3,3,4,3,4,2,2,4,3,3,3,4,3,2,4,4,3,3,4,3,3,2,3,3,4,4,3,1,3,3,3,4,3,3,3,3,3,3,3,4,4,2,3,2,3,4,3,3,3,3,3,3,4,4,4,5,4,3,3,4,4,4,3,3,3,3,3,3,5,3,4,2,4,3,3,4,3,3,2,4,8,4,4,3,2,2,5,3,3,4,4,3,2,3,2,3,3,2,3,4,3,5,3,4,3,4,4,4,4,3,4,4,3,4,3,3,3,4,4,3,4,3,4,3,3,4,3,4,3,2,4,2,3,2,4,5,4,4,4,5,4,3,4,4,4,3,3,4,3,4,2,3,4,3,4,4,4,3,3,2,3,5,4,3,4,5,4,2,3,2,5,3,4,4,3,3,5,4,4,4,3,2,4,3,4,4,3,4,3,3,4,3,3,3,3,4,2,3,5,3,5,3,3,3,4,3,4,3,4,4,3,4,2,2,6,3,5,3,4,3,3,3,3,4,4,3,4,3,4,5,5,4,4,2,3,4,3,4,3,4,4,4,3,5,4,4,4,3,4,5,5,4,5,4,5,4,4,3,6,3,3,5,2,3,2,4,3,4,4,4,3,4,5,4,4,4,5,5,4,3,5,5,4,4,4,5,2,4,4,5,4,4,5,3,4,3,3,5,5,5,4,4,4,3,4,4,4,4,3,3,3,4,2,4,3,5,3,3,4,3,4,4,2,3,4,5,4,4,3,3,3,2,5,4,4,5,3,5,4,3,3,4,4,5,3,4,5,3,4,3,4,4,3,3,3,2,4,3,3,5,5,3,2,3,3,4,4,5,3,3,3,3,4,5,5,2,3,3,3,5,5,5,4,4,4,3,3,4,5,4,3,4,3,4,2,4,5,5,4,5,4,4],"z":[59222,68212,68880,89921,91002,94905,98937,100309,106250,106852,107502,108750,110700,113263,116250,122000,122682,123000,125000,126640,129000,133000,134555,136500,138750,141000,146250,147308,148750,149593,150000,152000,154000,69000,70000,71000,78400,80000,90000,92000,97750,98000,98000,100000,106716,111000,111000,114800,123225,123750,125000,125000,126000,135500,140000,140000,142500,143500,145000,145000,145000,146000,148500,149000,150000,150000,152000,156000,156000,156000,40000,62050,65000,65000,68000,77000,82732,84000,85000,90000,90000,91000,95000,100000,100000,101000,102750,112500,113000,114000,114000,114750,115000,115000,119250,120000,120000,120000,120108,121725,122000,125573,126714,126960,127000,127500,130000,133105,136500,139500,140000,140800,147000,150000,150000,155435,155500,30000,30000,55422,65000,66500,75000,77000,95625,96140,105000,108000,115000,115500,115620,116000,122000,122500,123000,124000,125000,130000,131750,137721,137760,138000,140000,145000,150000,150000,155000,155800,56950,60000,70000,80000,85500,105000,107666,109000,110000,110000,112500,114800,116000,119000,121500,122000,126854,127059,128687,130000,132000,134000,138000,142000,143012,145846,150000,150454,156896,161250,161500,165000,166357,166357,168000,170000,173000,174250,178760,179580,181000,182587,182750,183200,188741,189000,192067,194000,194818,195000,198000,200000,200000,206000,208000,212864,157788,161653,161829,168000,169000,175000,180400,182000,189000,195000,200000,201000,202500,205000,205000,205000,207000,210000,211500,215000,215000,215500,158000,160000,164000,164000,167000,167293,167293,168000,174000,178000,180000,188325,191500,192000,192700,195000,198000,200345,203000,207000,208000,210000,212000,213675,213697,215000,215000,215100,217500,218000,156142,158000,159900,160000,161500,162000,165000,167293,168000,168000,168750,170000,170250,173000,175000,176095,176250,180000,180000,181000,182000,188335,190000,190000,190000,191250,193000,193500,194818,195000,195000,195000,199900,200000,201000,204918,205000,205000,207744,210944,215000,215000,215000,216033,220000,220000,220000,220000,157296,160000,160000,161250,164000,165000,165000,165750,166000,169000,170000,170000,172000,173056,174000,174250,176850,179500,185000,188000,188700,189000,189000,190000,191250,191675,195500,198000,200000,200000,201528,204750,205000,205000,205900,207000,208250,211500,213000,216000,216021,219794,220000,220000,220000,220000,221000,223058,227887,231477,234697,235000,236000,236685,237800,240122,242638,244000,244500,244960,245918,250000,250000,250134,254200,260000,260014,263500,265000,275086,280908,280987,282400,285000,287417,291000,292024,299000,304037,222381,225000,225000,229665,230000,230000,235000,240000,242000,245000,245000,250000,250000,250000,256054,257729,260000,261000,261800,264469,265000,270000,270000,275000,280000,286013,292000,293993,294000,296769,297500,300000,300000,300500,305000,221000,222900,223139,225500,228327,230000,230000,230522,231200,232500,234000,234500,235000,236000,238861,239700,240000,240000,241000,245000,246000,247234,247480,249862,251000,252155,254172,258000,260000,261000,262500,266000,274425,277980,280000,284686,285000,285000,289000,295000,296056,297359,299940,304000,305000,220702,222000,222500,222750,225000,225000,228750,229000,230095,232500,233500,240000,240000,240971,242000,243500,246544,246750,249000,250000,252000,255000,255000,257200,260000,260000,263500,266510,267750,270000,275000,276000,276500,279000,280000,285000,288000,289000,290000,290000,294000,294173,295000,298000,298000,299000,300000,300000,300567,303000,305000,223000,224252,225000,228000,229027,229500,232425,234000,235301,235738,311000,315537,320000,320000,328360,334150,335750,335750,339500,346210,347029,347650,351300,370500,372000,381300,381942,387731,394470,395000,400186,425000,430000,461000,510000,539000,585000,600000,606238,660000,830000,306500,312500,315000,330000,331000,334000,336000,339000,339000,345000,350000,356000,361745,370000,380000,402000,406026,420000,425000,425000,433500,436746,438700,450000,460000,465000,471750,484000,485000,500500,541000,582000,614000,680000,307000,311328,313138,316630,320000,320000,325000,328578,331500,340000,344755,351000,353767,356035,360552,362305,365000,367554,368500,370000,371086,388000,395100,400000,400000,408431,413000,420000,423000,427500,430922,445000,452000,471000,475000,487500,500000,506688,512000,579093,636000,668365,676200,677048,691659,306000,310000,310000,310000,311518,312000,313000,315000,315000,315000,315000,320000,322000,325000,325500,326951,328370,330000,331200,334000,335000,346375,349000,350000,350000,350000,356200,360000,367463,375000,380000,380578,386222,395500,396000,397000,400000,413500,415000,425000,425000,433500,438000,441000,446000,450000,455000,460000,490000,493000,508000,511000,525000,533000,545000,560000,575000,575000,598695,600000,600000,610000,879000,884790],"type":"scatter3d","mode":"markers","marker":{"color":"red","size":2,"opacity":0.40000000000000002,"line":{"color":"rgba(31,119,180,1)"}},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"Price (USD)","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(68,1,84,1)"],["0.0416666666666667","rgba(70,19,97,1)"],["0.0833333333333333","rgba(72,32,111,1)"],["0.125","rgba(71,45,122,1)"],["0.166666666666667","rgba(68,58,128,1)"],["0.208333333333333","rgba(64,70,135,1)"],["0.25","rgba(60,82,138,1)"],["0.291666666666667","rgba(56,93,140,1)"],["0.333333333333333","rgba(49,104,142,1)"],["0.375","rgba(46,114,142,1)"],["0.416666666666667","rgba(42,123,142,1)"],["0.458333333333333","rgba(38,133,141,1)"],["0.5","rgba(37,144,140,1)"],["0.541666666666667","rgba(33,154,138,1)"],["0.583333333333333","rgba(39,164,133,1)"],["0.625","rgba(47,174,127,1)"],["0.666666666666667","rgba(53,183,121,1)"],["0.708333333333333","rgba(79,191,110,1)"],["0.75","rgba(98,199,98,1)"],["0.791666666666667","rgba(119,207,85,1)"],["0.833333333333333","rgba(147,214,70,1)"],["0.875","rgba(172,220,52,1)"],["0.916666666666667","rgba(199,225,42,1)"],["0.958333333333333","rgba(226,228,40,1)"],["1","rgba(253,231,37,1)"]],"showscale":true,"z":[[129493.02032786921,143718.61088939646,157944.20145092372,172169.79201245101,186395.38257397825,200620.97313550551,214846.56369703281,229072.15425856004,243297.7448200873,257523.3353816146,271748.92594314192,285974.5165046691,300200.10706619639,314425.69762772368,328651.28818925092,342876.87875077815,357102.46931230545,371328.05987383274,385553.65043535997,399779.24099688727,414004.83155841456,428230.42211994174,442456.01268146903,456681.60324299632,470907.19380452362,485132.78436605085,499358.37492757803,513583.96548910532,527809.55605063261,542035.14661215991,556260.7371736872,570486.32773521449,584711.91829674179,598937.50885826908,613163.09941979637,627388.68998132343,641614.28054285073,655839.87110437802,670065.46166590531,684291.05222743261,698516.6427889599,712742.23335048719,726967.82391201425,741193.41447354155,755419.00503506884,769644.59559659613,783870.18615812343,798095.77671965072,812321.36728117801,826546.95784270507],[125258.114213623,139483.70477515028,153709.29533667752,167934.88589820481,182160.47645973205,196386.06702125934,210611.65758278663,224837.24814431387,239062.8387058411,253288.4292673684,267514.01982889569,281739.61039042287,295965.20095195016,310190.79151347745,324416.38207500469,338641.97263653192,352867.56319805922,367093.15375958651,381318.74432111374,395544.33488264104,409769.92544416833,423995.51600569551,438221.1065672228,452446.69712875009,466672.28769027739,480897.87825180462,495123.4688133318,509349.05937485909,523574.64993638638,537800.24049791368,552025.83105944097,566251.42162096826,580477.01218249556,594702.60274402285,608928.19330555014,623153.7838670772,637379.3744286045,651604.96499013179,665830.55555165908,680056.14611318638,694281.73667471367,708507.32723624096,722732.91779776802,736958.50835929532,751184.09892082261,765409.6894823499,779635.2800438772,793860.87060540449,808086.46116693178,822312.05172845884],[121023.2080993768,135248.79866090405,149474.38922243135,163699.97978395864,177925.57034548587,192151.16090701311,206376.7514685404,220602.34203006764,234827.93259159493,249053.52315312222,263279.11371464952,277504.70427617669,291730.29483770399,305955.88539923128,320181.47596075851,334407.06652228575,348632.65708381304,362858.24764534034,377083.83820686757,391309.42876839486,405535.01932992216,419760.60989144933,433986.20045297663,448211.79101450392,462437.38157603121,476662.97213755845,490888.56269908563,505114.15326061292,519339.74382214021,533565.33438366745,547790.92494519474,562016.51550672203,576242.10606824933,590467.69662977662,604693.28719130391,618918.87775283097,633144.46831435827,647370.05887588556,661595.64943741285,675821.23999894015,690046.83056046744,704272.42112199473,718498.01168352179,732723.60224504909,746949.19280657638,761174.78336810367,775400.37392963096,789625.96449115826,803851.55505268555,818077.14561421261],[116788.3019851306,131013.89254665787,145239.48310818512,159465.07366971241,173690.66423123964,187916.25479276694,202141.84535429423,216367.43591582146,230593.0264773487,244818.61703887599,259044.20760040329,273269.79816193046,287495.38872345776,301720.97928498505,315946.56984651228,330172.16040803952,344397.75096956681,358623.34153109411,372848.93209262134,387074.52265414863,401300.11321567593,415525.7037772031,429751.2943387304,443976.88490025769,458202.47546178498,472428.06602331222,486653.65658483939,500879.24714636669,515104.83770789398,529330.42826942133,543556.01883094863,557781.60939247592,572007.19995400321,586232.79051553051,600458.3810770578,614683.97163858486,628909.56220011215,643135.15276163945,657360.74332316674,671586.33388469403,685811.92444622132,700037.51500774862,714263.10556927568,728488.69613080297,742714.28669233026,756939.87725385756,771165.46781538485,785391.05837691214,799616.64893843944,813842.2394999665],[112553.3958708844,126778.98643241166,141004.57699393894,155230.16755546624,169455.75811699347,183681.34867852071,197906.939240048,212132.52980157523,226358.12036310253,240583.71092462982,254809.30148615711,269034.89204768429,283260.48260921158,297486.07317073888,311711.66373226611,325937.25429379335,340162.84485532064,354388.43541684793,368614.02597837517,382839.61653990246,397065.20710142975,411290.79766295693,425516.38822448422,439741.97878601152,453967.56934753881,468193.15990906605,482418.75047059322,496644.34103212052,510869.93159364781,525095.5221551751,539321.1127167024,553546.70327822969,567772.29383975698,581997.88440128427,596223.47496281157,610449.06552433863,624674.65608586592,638900.24664739321,653125.83720892051,667351.4277704478,681577.01833197509,695802.60889350239,710028.19945502945,724253.79001655674,738479.38057808403,752704.97113961133,766930.56170113862,781156.15226266591,795381.74282419321,809607.33338572027],[108318.48975663821,122544.08031816548,136769.67087969274,150995.26144122003,165220.85200274727,179446.44256427453,193672.03312580183,207897.62368732906,222123.21424885633,236348.80481038362,250574.39537191091,264799.98593343806,279025.57649496535,293251.16705649265,307476.75761801988,321702.34817954712,335927.93874107441,350153.5293026017,364379.11986412894,378604.71042565623,392830.30098718352,407055.8915487107,421281.48211023799,435507.07267176529,449732.66323329258,463958.25379481982,478183.84435634699,492409.43491787429,506635.02547940158,520860.61604092887,535086.20660245616,549311.79716398346,563537.38772551075,577762.97828703804,591988.56884856534,606214.1594100924,620439.74997161969,634665.34053314698,648890.93109467428,663116.52165620157,677342.11221772886,691567.70277925616,705793.29334078322,720018.88390231051,734244.4744638378,748470.0650253651,762695.65558689239,776921.24614841968,791146.83670994698,805372.42727147404],[104083.58364239201,118309.17420391928,132534.76476544654,146760.35532697383,160985.94588850107,175211.53645002833,189437.12701155563,203662.71757308286,217888.30813461012,232113.89869613742,246339.48925766471,260565.07981919189,274790.67038071918,289016.26094224647,303241.85150377371,317467.44206530094,331693.03262682824,345918.62318835553,360144.21374988277,374369.80431141006,388595.39487293735,402820.98543446453,417046.57599599182,431272.16655751911,445497.75711904641,459723.34768057364,473948.93824210082,488174.52880362811,502400.11936515541,516625.7099266827,530851.30048820993,545076.89104973723,559302.48161126452,573528.07217279181,587753.66273431911,601979.25329584617,616204.84385737346,630430.43441890075,644656.02498042805,658881.61554195534,673107.20610348263,687332.79666500993,701558.38722653699,715783.97778806428,730009.56834959157,744235.15891111887,758460.74947264616,772686.34003417345,786911.93059570075,801137.52115722781],[99848.67752814581,114074.26808967307,128299.85865120034,142525.44921272763,156751.03977425487,170976.63033578213,185202.22089730942,199427.81145883666,213653.40202036392,227878.99258189122,242104.58314341851,256330.17370494569,270555.76426647295,284781.35482800024,299006.94538952748,313232.53595105471,327458.12651258201,341683.7170741093,355909.30763563653,370134.89819716383,384360.48875869112,398586.0793202183,412811.66988174559,427037.26044327288,441262.85100480018,455488.44156632741,469714.03212785459,483939.62268938188,498165.21325090918,512390.80381243647,526616.39437396382,540841.98493549111,555067.57549701841,569293.1660585457,583518.75662007299,597744.34718160005,611969.93774312735,626195.52830465464,640421.11886618193,654646.70942770923,668872.29998923652,683097.89055076381,697323.48111229087,711549.07167381817,725774.66223534546,740000.25279687275,754225.84335840004,768451.43391992734,782677.02448145463,796902.61504298169],[95613.771413899609,109839.36197542687,124064.95253695414,138290.54309848143,152516.13366000867,166741.72422153593,180967.31478306322,195192.90534459046,209418.49590611772,223644.08646764501,237869.67702917231,252095.26759069948,266320.85815222678,280546.44871375407,294772.03927528131,308997.62983680854,323223.22039833583,337448.81095986313,351674.40152139036,365899.99208291766,380125.58264444495,394351.17320597213,408576.76376749942,422802.35432902671,437027.944890554,451253.53545208124,465479.12601360842,479704.71657513571,493930.307136663,508155.8976981903,522381.48825971759,536607.07882124488,550832.66938277218,565058.25994429947,579283.85050582676,593509.44106735382,607735.03162888112,621960.62219040841,636186.2127519357,650411.80331346299,664637.39387499029,678862.98443651758,693088.57499804464,707314.16555957193,721539.75612109923,735765.34668262652,749990.93724415381,764216.52780568111,778442.1183672084,792667.70892873546],[91378.865299653407,105604.45586118067,119830.04642270794,134055.63698423523,148281.22754576246,162506.81810728973,176732.40866881702,190957.99923034426,205183.58979187152,219409.18035339881,233634.77091492611,247860.36147645328,262085.95203798058,276311.54259950784,290537.13316103513,304762.72372256231,318988.3142840896,333213.9048456169,347439.49540714419,361665.08596867148,375890.67653019878,390116.26709172595,404341.85765325325,418567.44821478054,432793.03877630783,447018.62933783501,461244.21989936219,475469.81046088948,489695.40102241677,503920.99158394407,518146.58214547136,532372.17270699865,546597.76326852595,560823.35383005324,575048.94439158053,589274.53495310759,603500.12551463488,617725.71607616218,631951.30663768947,646176.89719921676,660402.48776074406,674628.07832227135,688853.66888379841,703079.2594453257,717304.850006853,731530.44056838029,745756.03112990758,759981.62169143488,774207.21225296217,788432.80281448923],[87143.959185407206,101369.54974693447,115595.14030846173,129820.73086998903,144046.32143151626,158271.91199304353,172497.50255457082,186723.09311609805,200948.68367762532,215174.27423915261,229399.8648006799,243625.45536220708,257851.04592373437,272076.63648526167,286302.2270467889,300527.81760831614,314753.40816984343,328978.99873137072,343204.58929289796,357430.17985442525,371655.77041595255,385881.36097747972,400106.95153900702,414332.54210053431,428558.1326620616,442783.72322358884,457009.31378511601,471234.90434664331,485460.4949081706,499686.08546969789,513911.67603122519,528137.26659275242,542362.85715427971,556588.44771580701,570814.0382773343,585039.62883886136,599265.21940038865,613490.80996191595,627716.40052344324,641941.99108497053,656167.58164649783,670393.17220802512,684618.76276955218,698844.35333107947,713069.94389260677,727295.53445413406,741521.12501566135,755746.71557718865,769972.30613871594,784197.896700243],[82909.053071161004,97134.643632688269,111360.23419421553,125585.82475574283,139811.41531727006,154037.00587879732,168262.59644032462,182488.18700185185,196713.77756337912,210939.36812490641,225164.9586864337,239390.54924796088,253616.13980948817,267841.7303710155,282067.32093254267,296292.91149406997,310518.50205559726,324744.09261712455,338969.68317865173,353195.27374017902,367420.86430170632,381646.45486323349,395872.04542476078,410097.63598628808,424323.22654781537,438548.81710934266,452774.40767086984,466999.99823239713,481225.58879392443,495451.17935545172,509676.76991697901,523902.36047850631,538127.9510400336,552353.54160156089,566579.13216308819,580804.72272461525,595030.31328614254,609255.90384766983,623481.49440919713,637707.08497072442,651932.67553225171,666158.26609377901,680383.85665530607,694609.44721683336,708835.03777836065,723060.62833988795,737286.21890141524,751511.80946294253,765737.40002446983,779962.99058599689],[78674.146956914803,92899.737518442067,107125.32807996933,121350.91864149662,135576.50920302386,149802.09976455112,164027.69032607842,178253.28088760565,192478.87144913292,206704.46201066021,220930.0525721875,235155.64313371468,249381.23369524197,263606.82425676927,277832.4148182965,292058.00537982373,306283.59594135103,320509.18650287832,334734.77706440556,348960.36762593285,363185.95818746014,377411.54874898732,391637.13931051461,405862.72987204191,420088.3204335692,434313.91099509643,448539.50155662361,462765.0921181509,476990.6826796782,491216.27324120549,505441.86380273278,519667.45436426008,533893.04492578737,548118.63548731466,562344.22604884196,576569.81661036902,590795.40717189631,605020.9977334236,619246.5882949509,633472.17885647819,647697.76941800548,661923.35997953278,676148.95054105984,690374.54110258713,704600.13166411442,718825.72222564172,733051.31278716901,747276.9033486963,761502.49391022359,775728.08447175066],[74439.240842668616,88664.83140419588,102890.42196572314,117116.01252725044,131341.60308877769,145567.19365030492,159792.78421183222,174018.37477335945,188243.96533488674,202469.55589641404,216695.14645794133,230920.73701946851,245146.3275809958,259371.91814252309,273597.50870405033,287823.09926557756,302048.68982710486,316274.28038863215,330499.87095015938,344725.46151168668,358951.05207321397,373176.64263474115,387402.23319626844,401627.82375779573,415853.41431932303,430079.00488085026,444304.59544237744,458530.18600390473,472755.77656543202,486981.36712695932,501206.95768848661,515432.5482500139,529658.13881154114,543883.72937306843,558109.31993459573,572334.91049612279,586560.50105765008,600786.09161917737,615011.68218070467,629237.27274223196,643462.86330375925,657688.45386528654,671914.04442681361,686139.6349883409,700365.22554986819,714590.81611139548,728816.40667292278,743041.99723445007,757267.58779597736,771493.17835750442],[70204.3347284224,84429.925289949664,98655.515851476928,112881.10641300422,127106.69697453146,141332.28753605872,155557.87809758601,169783.46865911325,184009.05922064051,198234.64978216781,212460.2403436951,226685.83090522228,240911.42146674957,255137.01202827686,269362.6025898041,283588.19315133133,297813.78371285863,312039.37427438592,326264.96483591315,340490.55539744045,354716.14595896774,368941.73652049492,383167.32708202221,397392.9176435495,411618.5082050768,425844.09876660403,440069.68932813121,454295.2798896585,468520.87045118579,482746.46101271309,496972.05157424038,511197.64213576767,525423.23269729502,539648.82325882232,553874.41382034961,568100.00438187667,582325.59494340396,596551.18550493126,610776.77606645855,625002.36662798584,639227.95718951314,653453.54775104043,667679.13831256749,681904.72887409478,696130.31943562208,710355.90999714937,724581.50055867666,738807.09112020396,753032.68168173125,767258.27224325831],[65969.428614176199,80195.019175703463,94420.609737230727,108646.20029875802,122871.79086028525,137097.38142181252,151322.97198333981,165548.56254486705,179774.15310639431,193999.7436679216,208225.3342294489,222450.92479097607,236676.51535250337,250902.10591403066,265127.69647555787,279353.28703708516,293578.87759861245,307804.46816013975,322030.05872166692,336255.64928319422,350481.23984472151,364706.83040624869,378932.42096777598,393158.01152930327,407383.60209083057,421609.19265235786,435834.78321388504,450060.37377541233,464285.96433693962,478511.55489846691,492737.14545999421,506962.7360215215,521188.32658304879,535413.91714457609,549639.50770610338,563865.09826763044,578090.68882915773,592316.27939068503,606541.86995221232,620767.46051373961,634993.05107526691,649218.6416367942,663444.23219832126,677669.82275984855,691895.41332137585,706121.00388290314,720346.59444443043,734572.18500595773,748797.77556748502,763023.36612901208],[61734.522499930012,75960.113061457276,90185.70362298454,104411.29418451183,118636.88474603907,132862.47530756635,147088.06586909364,161313.65643062087,175539.24699214811,189764.8375536754,203990.4281152027,218216.01867672987,232441.60923825717,246667.19979978446,260892.79036131169,275118.38092283893,289343.97148436622,303569.56204589352,317795.15260742075,332020.74316894804,346246.33373047534,360471.92429200251,374697.51485352981,388923.1054150571,403148.69597658439,417374.28653811163,431599.8770996388,445825.4676611661,460051.05822269339,474276.64878422068,488502.23934574798,502727.82990727527,516953.42046880256,531179.01103032986,545404.60159185715,559630.19215338421,573855.7827149115,588081.3732764388,602306.96383796609,616532.55439949338,630758.14496102068,644983.73552254797,659209.32608407503,673434.91664560232,687660.50720712962,701886.09776865691,716111.6883301842,730337.2788917115,744562.86945323879,758788.46001476585],[57499.61638568381,71725.206947211074,85950.797508738338,100176.38807026563,114401.97863179287,128627.56919332013,142853.15975484741,157078.75031637464,171304.34087790194,185529.93143942923,199755.52200095652,213981.1125624837,228206.70312401099,242432.29368553829,256657.88424706552,270883.47480859276,285109.06537012005,299334.65593164734,313560.24649317458,327785.83705470187,342011.42761622916,356237.01817775634,370462.60873928363,384688.19930081093,398913.78986233822,413139.38042386546,427364.97098539263,441590.56154691993,455816.15210844722,470041.74266997451,484267.33323150181,498492.9237930291,512718.51435455639,526944.10491608363,541169.69547761092,555395.28603913798,569620.87660066527,583846.46716219257,598072.05772371986,612297.64828524715,626523.23884677445,640748.82940830174,654974.4199698288,669200.01053135609,683425.60109288339,697651.19165441068,711876.78221593797,726102.37277746527,740327.96333899256,754553.55390051962],[53264.710271437609,67490.300832964873,81715.891394492137,95941.48195601943,110167.07251754667,124392.66307907393,138618.25364060124,152843.84420212847,167069.43476365571,181295.025325183,195520.61588671029,209746.20644823747,223971.79700976476,238197.38757129206,252422.97813281929,266648.56869434653,280874.15925587382,295099.74981740111,309325.34037892835,323550.93094045564,337776.52150198293,352002.11206351011,366227.7026250374,380453.2931865647,394678.88374809199,408904.47430961923,423130.0648711464,437355.6554326737,451581.24599420099,465806.83655572828,480032.42711725557,494258.01767878287,508483.60824031016,522709.19880183745,536934.78936336481,551160.37992489187,565385.97048641916,579611.56104794645,593837.15160947375,608062.74217100104,622288.33273252833,636513.92329405562,650739.51385558269,664965.10441710998,679190.69497863727,693416.28554016456,707641.87610169186,721867.46666321915,736093.05722474644,750318.6477862735],[49029.804157191407,63255.394718718671,77480.985280245935,91706.575841773229,105932.16640330046,120157.75696482773,134383.34752635501,148608.93808788224,162834.52864940953,177060.11921093683,191285.70977246412,205511.3003339913,219736.89089551859,233962.48145704588,248188.07201857312,262413.66258010035,276639.25314162765,290864.84370315494,305090.43426468218,319316.02482620947,333541.61538773676,347767.20594926394,361992.79651079123,376218.38707231852,390443.97763384582,404669.56819537305,418895.15875690023,433120.74931842752,447346.33987995482,461571.93044148211,475797.5210030094,490023.1115645367,504248.70212606399,518474.29268759128,532699.88324911857,546925.47381064564,561151.06437217293,575376.65493370022,589602.24549522751,603827.83605675481,618053.4266182821,632279.01717980939,646504.60774133645,660730.19830286375,674955.78886439104,689181.37942591833,703406.96998744563,717632.56054897292,731858.15111050021,746083.74167202727],[44794.89804294522,59020.488604472484,73246.079165999749,87471.669727527042,101697.26028905428,115922.85085058154,130148.44141210883,144374.03197363607,158599.62253516333,172825.21309669063,187050.80365821792,201276.3942197451,215501.98478127239,229727.57534279968,243953.16590432692,258178.75646585415,272404.34702738142,286629.93758890871,300855.528150436,315081.1187119633,329306.70927349059,343532.29983501777,357757.89039654506,371983.48095807235,386209.07151959965,400434.66208112682,414660.252642654,428885.84320418129,443111.43376570859,457337.02432723588,471562.61488876317,485788.20545029046,500013.79601181776,514239.38657334505,528464.97713487234,542690.5676963994,556916.1582579267,571141.74881945399,585367.33938098128,599592.92994250858,613818.52050403587,628044.11106556316,642269.70162709022,656495.29218861752,670720.88275014481,684946.4733116721,699172.0638731994,713397.65443472669,727623.24499625398,741848.83555778104],[40559.991928699004,54785.582490226268,69011.173051753532,83236.763613280826,97462.354174808061,111687.94473633532,125913.53529786262,140139.12585938984,154364.71642091713,168590.30698244442,182815.89754397172,197041.48810549889,211267.07866702619,225492.66922855348,239718.25979008072,253943.85035160795,268169.44091313524,282395.03147466254,296620.62203618977,310846.21259771707,325071.80315924436,339297.39372077154,353522.98428229883,367748.57484382612,381974.16540535341,396199.75596688065,410425.34652840783,424650.93708993512,438876.52765146241,453102.11821298971,467327.708774517,481553.29933604429,495778.88989757159,510004.48045909888,524230.07102062617,538455.66158215317,552681.25214368047,566906.84270520776,581132.43326673505,595358.02382826235,609583.61438978964,623809.20495131693,638034.79551284399,652260.38607437129,666485.97663589858,680711.56719742587,694937.15775895317,709162.74832048046,723388.33888200775,737613.92944353481],[36325.085814452817,50550.676375980082,64776.266937507346,79001.857499034639,93227.448060561874,107453.03862208914,121678.62918361643,135904.21974514367,150129.81030667093,164355.40086819822,178580.99142972552,192806.58199125269,207032.17255277999,221257.76311430728,235483.35367583451,249708.94423736175,263934.53479888907,278160.12536041636,292385.71592194354,306611.30648347083,320836.89704499813,335062.4876065253,349288.0781680526,363513.66872957989,377739.25929110718,391964.84985263448,406190.44041416165,420416.03097568895,434641.62153721624,448867.21209874353,463092.80266027083,477318.39322179812,491543.98378332541,505769.57434485271,519995.16490638,534220.75546790706,548446.34602943435,562671.93659096165,576897.52715248894,591123.11771401623,605348.70827554353,619574.29883707082,633799.88939859788,648025.47996012517,662251.07052165247,676476.66108317976,690702.25164470705,704927.84220623435,719153.43276776164,733379.0233292887],[32090.179700206601,46315.770261733865,60541.36082326113,74766.951384788423,88992.541946315658,103218.13250784292,117443.72306937021,131669.31363089744,145894.90419242473,160120.49475395202,174346.08531547931,188571.67587700649,202797.26643853378,217022.85700006108,231248.44756158831,245474.03812311555,259699.62868464284,273925.21924617013,288150.80980769737,302376.40036922466,316601.99093075196,330827.58149227913,345053.17205380643,359278.76261533372,373504.35317686101,387729.94373838825,401955.53429991542,416181.12486144272,430406.71542297001,444632.3059844973,458857.8965460246,473083.48710755189,487309.07766907918,501534.66823060648,515760.25879213377,529985.84935366083,544211.43991518812,558437.03047671542,572662.62103824271,586888.21159977,601113.8021612973,615339.39272282459,629564.98328435165,643790.57384587894,658016.16440740624,672241.75496893353,686467.34553046082,700692.93609198811,714918.52665351541,729144.11721504247],[27855.273585960385,42080.864147487649,56306.454709014914,70532.045270542207,84757.635832069442,98983.226393596706,113208.816955124,127434.40751665123,141659.9980781785,155885.58863970579,170111.17920123308,184336.76976276026,198562.36032428755,212787.95088581485,227013.54144734208,241239.13200886932,255464.72257039661,269690.3131319239,283915.90369345114,298141.49425497843,312367.08481650573,326592.6753780329,340818.26593956019,355043.85650108749,369269.44706261478,383495.03762414202,397720.62818566919,411946.21874719649,426171.80930872378,440397.39987025107,454622.99043177837,468848.58099330566,483074.17155483295,497299.76211636025,511525.35267788754,525750.9432394146,539976.53380094189,554202.12436246919,568427.71492399648,582653.30548552377,596878.89604705106,611104.48660857836,625330.07717010542,639555.66773163271,653781.25829316,668006.8488546873,682232.43941621459,696458.02997774188,710683.62053926918,724909.21110079624],[23620.367471714213,37845.958033241477,52071.548594768741,66297.139156296034,80522.729717823269,94748.320279350533,108973.91084087783,123199.50140240506,137425.09196393233,151650.68252545962,165876.27308698691,180101.86364851409,194327.45421004138,208553.04477156868,222778.63533309591,237004.22589462314,251229.81645615044,265455.40701767773,279680.99757920497,293906.58814073226,308132.17870225955,322357.76926378673,336583.35982531402,350808.95038684132,365034.54094836861,379260.13150989584,393485.72207142302,407711.31263295031,421936.90319447761,436162.4937560049,450388.08431753219,464613.67487905949,478839.26544058678,493064.85600211407,507290.44656364137,521516.03712516843,535741.62768669566,549967.21824822295,564192.80880975025,578418.39937127754,592643.98993280483,606869.58049433213,621095.17105585919,635320.76161738648,649546.35217891377,663771.94274044107,677997.53330196836,692223.12386349565,706448.71442502295,720674.30498655001],[19385.461357468041,33611.051918995305,47836.642480522569,62062.233042049862,76287.823603577097,90513.414165104361,104739.00472663165,118964.59528815889,133190.18584968615,147415.77641121345,161641.36697274074,175866.95753426792,190092.54809579521,204318.1386573225,218543.72921884974,232769.31978037697,246994.91034190427,261220.50090343156,275446.09146495879,289671.68202648609,303897.27258801338,318122.86314954056,332348.45371106785,346574.04427259514,360799.63483412244,375025.22539564967,389250.81595717685,403476.40651870414,417701.99708023143,431927.58764175873,446153.17820328602,460378.76876481331,474604.35932634061,488829.9498878679,503055.54044939519,517281.13101092225,531506.72157244955,545732.31213397684,559957.90269550413,574183.49325703143,588409.08381855872,602634.67438008601,616860.26494161307,631085.85550314037,645311.44606466766,659537.03662619495,673762.62718772225,687988.21774924954,702213.80831077683,716439.39887230389],[15150.55524322181,29376.145804749074,43601.736366276338,57827.326927803631,72052.917489330866,86278.50805085813,100504.09861238542,114729.68917391266,128955.27973543992,143180.87029696722,157406.46085849451,171632.05142002169,185857.64198154898,200083.23254307627,214308.82310460351,228534.41366613074,242760.00422765804,256985.59478918533,271211.18535071256,285436.77591223986,299662.36647376715,313887.95703529433,328113.54759682162,342339.13815834891,356564.72871987621,370790.31928140344,385015.90984293062,399241.50040445791,413467.0909659852,427692.6815275125,441918.27208903979,456143.86265056708,470369.45321209438,484595.04377362167,498820.63433514896,513046.22489667602,527271.81545820332,541497.40601973061,555722.9965812579,569948.5871427852,584174.17770431249,598399.76826583978,612625.35882736684,626850.94938889414,641076.53995042143,655302.13051194872,669527.72107347602,683753.31163500331,697978.9021965306,712204.49275805766],[10915.649128975609,25141.239690502873,39366.830252030137,53592.42081355743,67818.011375084665,82043.601936611929,96269.192498139222,110494.78305966646,124720.37362119372,138945.96418272101,153171.55474424831,167397.14530577548,181622.73586730278,195848.32642883007,210073.91699035731,224299.50755188454,238525.09811341183,252750.68867493913,266976.27923646639,281201.86979799368,295427.46035952098,309653.05092104815,323878.64148257545,338104.23204410274,352329.82260563003,366555.41316715721,380781.00372868439,395006.59429021168,409232.18485173897,423457.77541326627,437683.36597479356,451908.95653632085,466134.54709784815,480360.13765937544,494585.72822090273,508811.31878242979,523036.90934395709,537262.49990548438,551488.09046701167,565713.68102853897,579939.27159006626,594164.86215159355,608390.45271312061,622616.04327464791,636841.6338361752,651067.22439770249,665292.81495922979,679518.40552075708,693743.99608228437,707969.58664381143],[6680.7430147294072,20906.333576256671,35131.924137783935,49357.514699311228,63583.105260838463,77808.695822365728,92034.286383893021,106259.87694542026,120485.46750694752,134711.05806847481,148936.64863000211,163162.23919152928,177387.82975305658,191613.42031458387,205839.0108761111,220064.60143763834,234290.19199916563,248515.78256069293,262741.37312222016,276966.96368374745,291192.55424527475,305418.14480680192,319643.73536832922,333869.32592985651,348094.9164913838,362320.50705291104,376546.09761443821,390771.68817596551,404997.2787374928,419222.86929902009,433448.45986054739,447674.05042207468,461899.64098360197,476125.23154512927,490350.82210665656,504576.41266818362,518802.00322971091,533027.59379123827,547253.18435276556,561478.77491429285,575704.36547582014,589929.95603734744,604155.5465988745,618381.13716040179,632606.72772192908,646832.31828345638,661057.90884498367,675283.49940651096,689509.08996803826,703734.68052956532],[2445.8369004832057,16671.42746201047,30897.018023537734,45122.608585065027,59348.199146592262,73573.789708119526,87799.380269646819,102024.97083117405,116250.56139270132,130476.15195422861,144701.7425157559,158927.33307728308,173152.92363881037,187378.51420033767,201604.1047618649,215829.69532339214,230055.28588491943,244280.87644644672,258506.46700797396,272732.05756950122,286957.64813102852,301183.23869255569,315408.82925408299,329634.41981561028,343860.01037713757,358085.60093866487,372311.19150019204,386536.78206171934,400762.37262324663,414987.96318477392,429213.55374630122,443439.14430782851,457664.7348693558,471890.32543088309,486115.91599241039,500341.50655393745,514567.09711546474,528792.68767699203,543018.27823851933,557243.86880004662,571469.45936157391,585695.04992310121,599920.64048462827,614146.23104615556,628371.82160768285,642597.41216921015,656823.00273073744,671048.59329226473,685274.18385379203,699499.77441531909],[-1789.0692137629667,12436.521347764297,26662.111909291561,40887.702470818855,55113.29303234609,69338.883593873354,83564.474155400647,97790.064716927882,112015.65527845515,126241.24583998244,140466.83640150973,154692.42696303691,168918.0175245642,183143.6080860915,197369.19864761873,211594.78920914597,225820.37977067326,240045.97033220055,254271.56089372779,268497.15145525511,282722.7420167824,296948.33257830958,311173.92313983687,325399.51370136417,339625.10426289146,353850.69482441864,368076.28538594581,382301.87594747311,396527.4665090004,410753.05707052769,424978.64763205498,439204.23819358228,453429.82875510957,467655.41931663686,481881.00987816416,496106.60043969122,510332.19100121851,524557.7815627458,538783.3721242731,553008.96268580039,567234.55324732768,581460.14380885498,595685.73437038204,609911.32493190933,624136.91549343662,638362.50605496392,652588.09661649121,666813.6871780185,681039.2777395458,695264.86830107286],[-6023.9753280091973,8201.6152335180668,22427.205795045331,36652.796356572624,50878.386918099859,65103.977479627123,79329.568041154416,93555.158602681651,107780.74916420892,122006.33972573621,136231.9302872635,150457.52084879068,164683.11141031797,178908.70197184526,193134.2925333725,207359.88309489973,221585.47365642703,235811.06421795432,250036.65477948156,264262.24534100888,278487.83590253617,292713.42646406335,306939.01702559064,321164.60758711793,335390.19814864523,349615.7887101724,363841.37927169958,378066.96983322687,392292.56039475417,406518.15095628146,420743.74151780875,434969.33207933605,449194.92264086334,463420.51320239063,477646.10376391793,491871.69432544499,506097.28488697228,520322.87544849957,534548.46601002687,548774.05657155416,562999.64713308145,577225.23769460875,591450.82825613581,605676.4188176631,619902.00937919039,634127.59994071769,648353.19050224498,662578.78106377227,676804.37162529957,691029.96218682663],[-10258.881442255399,3966.7091192718653,18192.299680799129,32417.890242326423,46643.480803853658,60869.071365380922,75094.661926908215,89320.25248843545,103545.84304996271,117771.43361149001,131997.0241730173,146222.61473454448,160448.20529607177,174673.79585759906,188899.3864191263,203124.97698065353,217350.56754218083,231576.15810370812,245801.74866523535,260027.33922676265,274252.92978828994,288478.52034981712,302704.11091134441,316929.7014728717,331155.292034399,345380.88259592623,359606.47315745341,373832.0637189807,388057.654280508,402283.24484203529,416508.83540356258,430734.42596508987,444960.01652661717,459185.60708814446,473411.19764967175,487636.78821119881,501862.37877272611,516087.9693342534,530313.55989578064,544539.15045730793,558764.74101883522,572990.33158036252,587215.92214188958,601441.51270341687,615667.10326494416,629892.69382647146,644118.28438799875,658343.87494952604,672569.46551105333,686795.0560725804],[-14493.787556501571,-268.19699497430702,13957.393566552957,28182.98412808025,42408.574689607485,56634.165251134749,70859.755812662042,85085.346374189277,99310.936935716541,113536.52749724383,127762.11805877113,141987.7086202983,156213.2991818256,170438.88974335289,184664.48030488013,198890.07086640736,213115.66142793465,227341.25198946195,241566.84255098918,255792.43311251648,270018.02367404377,284243.61423557095,298469.20479709824,312694.79535862553,326920.38592015282,341145.97648168006,355371.56704320724,369597.15760473453,383822.74816626182,398048.33872778912,412273.92928931641,426499.5198508437,440725.110412371,454950.70097389829,469176.29153542558,483401.88209695264,497627.47265847994,511853.06322000723,526078.65378153452,540304.24434306182,554529.83490458911,568755.4254661164,582981.01602764346,597206.60658917075,611432.19715069805,625657.78771222534,639883.37827375263,654108.96883527993,668334.55939680722,682560.14995833428],[-18728.693670747802,-4503.1031092205376,9722.4874523067265,23948.07801383402,38173.668575361255,52399.259136888519,66624.849698415812,80850.440259943047,95076.030821470311,109301.6213829976,123527.2119445249,137752.80250605207,151978.39306757937,166203.98362910666,180429.5741906339,194655.16475216113,208880.75531368842,223106.34587521572,237331.93643674295,251557.52699827024,265783.11755979754,280008.70812132471,294234.29868285201,308459.8892443793,322685.47980590659,336911.07036743383,351136.66092896101,365362.2514904883,379587.84205201559,393813.43261354289,408039.02317507018,422264.61373659747,436490.20429812477,450715.79485965206,464941.38542117935,479166.97598270641,493392.5665442337,507618.157105761,521843.74766728829,536069.33822881558,550294.92879034288,564520.51935187017,578746.10991339723,592971.70047492452,607197.29103645182,621422.88159797911,635648.4721595064,649874.0627210337,664099.65328256099,678325.24384408805],[-22963.599784993974,-8738.00922346671,5487.5813380605541,19713.171899587847,33938.762461115082,48164.353022642346,62389.94358416964,76615.534145696874,90841.124707224139,105066.71526875143,119292.30583027872,133517.8963918059,147743.48695333319,161969.07751486049,176194.66807638772,190420.25863791496,204645.84919944225,218871.43976096954,233097.03032249678,247322.62088402407,261548.21144555137,275773.80200707854,289999.39256860584,304224.98313013313,318450.57369166042,332676.16425318766,346901.75481471483,361127.34537624213,375352.93593776942,389578.52649929671,403804.11706082401,418029.7076223513,432255.29818387859,446480.88874540589,460706.47930693318,474932.06986846024,489157.66042998753,503383.25099151483,517608.84155304212,531834.43211456947,546060.02267609676,560285.61323762406,574511.20379915112,588736.79436067841,602962.3849222057,617187.975483733,631413.56604526029,645639.15660678758,659864.74716831488,674090.33772984194],[-27198.505899240205,-12972.915337712941,1252.6752238143235,15478.265785341617,29703.856346868852,43929.446908396116,58155.037469923409,72380.628031450644,86606.218592977908,100831.8091545052,115057.39971603249,129282.99027755967,143508.58083908696,157734.17140061426,171959.76196214149,186185.35252366873,200410.94308519602,214636.53364672331,228862.12420825055,243087.71476977784,257313.30533130514,271538.89589283231,285764.4864543596,299990.0770158869,314215.66757741419,328441.25813894143,342666.8487004686,356892.4392619959,371118.02982352319,385343.62038505048,399569.21094657778,413794.80150810507,428020.39206963236,442245.98263115966,456471.57319268695,470697.16375421401,484922.7543157413,499148.3448772686,513373.93543879589,527599.52600032324,541825.11656185053,556050.70712337783,570276.29768490489,584501.88824643218,598727.47880795947,612953.06936948677,627178.65993101406,641404.25049254135,655629.84105406865,669855.43161559571],[-31433.412013486377,-17207.821451959113,-2982.2308904318488,11243.359671095444,25468.950232622679,39694.540794149943,53920.131355677237,68145.721917204472,82371.312478731736,96596.903040259029,110822.49360178632,125048.0841633135,139273.67472484079,153499.26528636809,167724.85584789532,181950.44640942256,196176.03697094985,210401.62753247714,224627.21809400438,238852.80865553167,253078.39921705896,267303.98977858614,281529.58034011343,295755.17090164073,309980.76146316802,324206.35202469525,338431.94258622243,352657.53314774972,366883.12370927702,381108.71427080431,395334.3048323316,409559.8953938589,423785.48595538619,438011.07651691348,452236.66707844078,466462.25763996784,480687.84820149513,494913.43876302242,509139.02932454972,523364.61988607701,537590.2104476043,551815.8010091316,566041.39157065866,580266.98213218595,594492.57269371324,608718.16325524054,622943.75381676783,637169.34437829512,651394.93493982241,665620.52550134948],[-35668.318127732578,-21442.727566205314,-7217.1370046780503,7008.4535568492429,21234.044118376478,35459.634679903742,49685.225241431035,63910.81580295827,78136.406364485534,92361.996926012827,106587.58748754012,120813.1780490673,135038.76861059459,149264.35917212188,163489.94973364912,177715.54029517635,191941.13085670365,206166.72141823094,220392.31197975817,234617.90254128547,248843.49310281276,263069.08366433997,277294.67422586726,291520.26478739455,305745.85534892185,319971.44591044902,334197.0364719762,348422.62703350349,362648.21759503079,376873.80815655808,391099.39871808537,405324.98927961267,419550.57984113996,433776.17040266725,448001.76096419455,462227.35152572161,476452.9420872489,490678.53264877619,504904.12321030349,519129.71377183078,533355.30433335807,547580.89489488536,561806.48545641243,576032.07601793972,590257.66657946701,604483.2571409943,618708.8477025216,632934.43826404889,647160.02882557618,661385.61938710324],[-39903.22424197878,-25677.633680451516,-11452.043118924252,2773.5474426030414,16999.138004130276,31224.72856565754,45450.319127184834,59675.909688712069,73901.500250239333,88127.090811766626,102352.68137329392,116578.2719348211,130803.86249634839,145029.45305787568,159255.04361940292,173480.63418093015,187706.22474245745,201931.81530398474,216157.40586551197,230382.99642703927,244608.58698856656,258834.17755009374,273059.76811162103,287285.35867314832,301510.94923467562,315736.53979620285,329962.13035773003,344187.72091925732,358413.31148078461,372638.90204231191,386864.4926038392,401090.08316536649,415315.67372689379,429541.26428842108,443766.85484994837,457992.44541147543,472218.03597300273,486443.62653453002,500669.21709605731,514894.80765758461,529120.39821911184,543345.98878063913,557571.57934216619,571797.16990369349,586022.76046522078,600248.35102674807,614473.94158827537,628699.53214980266,642925.12271132995,657150.71327285701],[-44138.130356224981,-29912.539794697717,-15686.949233170453,-1461.3586716431601,12764.231889884075,26989.822451411339,41215.413012938632,55441.003574465867,69666.594135993131,83892.184697520424,98117.775259047718,112343.36582057489,126568.95638210219,140794.54694362948,155020.13750515672,169245.72806668395,183471.31862821124,197696.90918973854,211922.49975126577,226148.09031279307,240373.68087432036,254599.27143584754,268824.8619973748,283050.45255890209,297276.04312042939,311501.63368195668,325727.22424348386,339952.81480501115,354178.40536653844,368403.99592806573,382629.58648959303,396855.17705112032,411080.76761264761,425306.35817417491,439531.9487357022,453757.53929722926,467983.12985875655,482208.72042028385,496434.31098181114,510659.90154333843,524885.49210486573,539111.08266639302,553336.67322792008,567562.26378944737,581787.85435097467,596013.44491250196,610239.03547402925,624464.62603555655,638690.21659708384,652915.8071586109],[-48373.036470471183,-34147.445908943919,-19921.855347416655,-5696.2647858893615,8529.3257756378734,22754.916337165138,36980.506898692431,51206.097460219666,65431.68802174693,79657.278583274223,93882.869144801516,108108.45970632869,122334.05026785599,136559.64082938328,150785.23139091051,165010.82195243775,179236.41251396504,193462.00307549234,207687.59363701957,221913.18419854686,236138.77476007416,250364.36532160133,264589.95588312863,278815.54644465592,293041.13700618321,307266.72756771045,321492.31812923762,335717.90869076492,349943.49925229221,364169.0898138195,378394.6803753468,392620.27093687409,406845.86149840138,421071.45205992868,435297.04262145597,449522.63318298303,463748.22374451032,477973.81430603762,492199.40486756491,506424.9954290922,520650.5859906195,534876.17655214679,549101.76711367385,563327.35767520114,577552.94823672844,591778.53879825573,606004.12935978302,620229.71992131032,634455.31048283761,648680.90104436467],[-52607.942584717384,-38382.35202319012,-24156.761461662856,-9931.170900135563,4294.419661391672,18520.010222918936,32745.600784446229,46971.191345973464,61196.781907500728,75422.372469028021,89647.963030555315,103873.55359208249,118099.14415360978,132324.73471513708,146550.32527666431,160775.91583819155,175001.50639971884,189227.09696124613,203452.68752277337,217678.27808430066,231903.86864582796,246129.45920735513,260355.04976888243,274580.64033040975,288806.23089193704,303031.82145346422,317257.41201499139,331483.00257651869,345708.59313804598,359934.18369957327,374159.77426110057,388385.36482262786,402610.95538415515,416836.54594568245,431062.13650720974,445287.7270687368,459513.31763026409,473738.90819179139,487964.49875331868,502190.08931484597,516415.67987637327,530641.27043790056,544866.86099942762,559092.45156095491,573318.04212248221,587543.6326840095,601769.22324553679,615994.81380706409,630220.40436859138,644445.99493011844],[-56842.848698963586,-42617.258137436322,-28391.667575909058,-14166.077014381764,59.513547145470511,14285.104108672735,28510.694670200028,42736.285231727263,56961.875793254527,71187.46635478182,85413.056916309113,99638.64747783629,113864.23803936358,128089.82860089088,142315.41916241811,156541.00972394535,170766.60028547264,184992.19084699993,199217.78140852717,213443.37197005446,227668.96253158175,241894.55309310893,256120.14365463622,270345.73421616352,284571.32477769081,298796.91533921805,313022.50590074522,327248.09646227252,341473.68702379981,355699.2775853271,369924.86814685439,384150.45870838169,398376.04926990898,412601.63983143627,426827.23039296357,441052.82095449063,455278.41151601792,469504.00207754521,483729.59263907251,497955.1832005998,512180.77376212709,526406.36432365444,540631.95488518151,554857.5454467088,569083.13600823609,583308.72656976338,597534.31713129068,611759.90769281797,625985.49825434526,640211.08881587232],[-61077.754813209787,-46852.164251682523,-32626.573690155259,-18400.983128627966,-4175.392567100731,10050.197994426533,24275.788555953826,38501.379117481061,52726.969679008325,66952.560240535619,81178.150802062912,95403.741363590088,109629.33192511738,123854.92248664467,138080.51304817191,152306.10360969914,166531.69417122644,180757.28473275373,194982.87529428097,209208.46585580826,223434.05641733555,237659.64697886273,251885.23754039002,266110.82810191729,280336.41866344458,294562.00922497187,308787.59978649905,323013.19034802634,337238.78090955364,351464.37147108093,365689.96203260822,379915.55259413552,394141.14315566281,408366.7337171901,422592.32427871739,436817.91484024446,451043.50540177175,465269.09596329904,479494.68652482633,493720.27708635363,507945.86764788092,522171.45820940821,536397.04877093527,550622.63933246257,564848.22989398986,579073.82045551715,593299.41101704445,607525.00157857174,621750.59214009903,635976.18270162609],[-65312.660927455989,-51087.070365928725,-36861.479804401461,-22635.889242874167,-8410.2986813469324,5815.2918801803316,20040.882441707625,34266.47300323486,48492.063564762124,62717.654126289417,76943.24468781671,91168.835249343887,105394.42581087118,119620.01637239847,133845.60693392571,148071.19749545294,162296.78805698024,176522.37861850753,190747.96918003476,204973.55974156206,219199.15030308935,233424.74086461653,247650.33142614382,261875.92198767111,276101.51254919841,290327.10311072564,304552.69367225282,318778.28423378011,333003.87479530741,347229.4653568347,361455.05591836199,375680.64647988928,389906.23704141658,404131.82760294387,418357.41816447116,432583.00872599822,446808.59928752552,461034.18984905281,475259.7804105801,489485.3709721074,503710.96153363469,517936.55209516198,532162.14265668904,546387.73321821634,560613.32377974363,574838.91434127092,589064.50490279822,603290.09546432551,617515.6860258528,631741.27658737986],[-69547.567041702161,-55321.976480174897,-41096.385918647633,-26870.79535712034,-12645.204795593105,1580.3857659341593,15805.976327461452,30031.566888988687,44257.157450515951,58482.748012043245,72708.338573570538,86933.929135097715,101159.51969662501,115385.1102581523,129610.70081967954,143836.29138120677,158061.88194273406,172287.47250426136,186513.06306578859,200738.65362731589,214964.24418884318,229189.83475037036,243415.42531189765,257641.01587342494,271866.60643495223,286092.19699647947,300317.78755800665,314543.37811953394,328768.96868106123,342994.55924258853,357220.14980411582,371445.74036564311,385671.33092717041,399896.9214886977,414122.51205022499,428348.10261175205,442573.69317327935,456799.28373480664,471024.87429633393,485250.46485786123,499476.05541938852,513701.64598091581,527927.23654244281,542152.82710397011,556378.4176654974,570604.00822702469,584829.59878855199,599055.18935007928,613280.77991160657,627506.37047313363],[-73782.473155948392,-59556.882594421128,-45331.292032893864,-31105.70147136657,-16880.110909839335,-2654.5203483120713,11571.070213215222,25796.660774742457,40022.251336269721,54247.841897797014,68473.432459324307,82699.023020851484,96924.613582378777,111150.20414390607,125375.79470543331,139601.38526696054,153826.97582848783,168052.56639001513,182278.15695154236,196503.74751306965,210729.33807459695,224954.92863612412,239180.51919765142,253406.10975917871,267631.700320706,281857.29088223324,296082.88144376042,310308.47200528771,324534.062566815,338759.6531283423,352985.24368986959,367210.83425139688,381436.42481292418,395662.01537445147,409887.60593597876,424113.19649750582,438338.78705903311,452564.37762056041,466789.9681820877,481015.55874361499,495241.14930514229,509466.73986666958,523692.33042819664,537917.92098972388,552143.51155125117,566369.10211277846,580594.69267430576,594820.28323583305,609045.87379736034,623271.4643588874],[-78017.379270194593,-63791.788708667329,-49566.198147140065,-35340.607585612772,-21115.017024085537,-6889.4264625582728,7336.1640989690204,21561.754660496255,35787.345222023519,50012.935783550813,64238.526345078106,78464.116906605283,92689.707468132576,106915.29802965987,121140.8885911871,135366.47915271434,149592.06971424163,163817.66027576893,178043.25083729616,192268.84139882345,206494.43196035075,220720.02252187792,234945.61308340522,249171.20364493251,263396.79420645977,277622.38476798707,291847.97532951424,306073.56589104154,320299.15645256883,334524.74701409612,348750.33757562342,362975.92813715071,377201.518698678,391427.1092602053,405652.69982173259,419878.29038325965,434103.88094478694,448329.47150631424,462555.06206784153,476780.65262936882,491006.24319089612,505231.83375242341,519457.42431395047,533683.01487547776,547908.60543700506,562134.19599853235,576359.78656005964,590585.37712158693,604810.96768311423,619036.55824464129]],"type":"surface","x":[539,627.55102040816325,716.10204081632651,804.65306122448987,893.20408163265301,981.75510204081638,1070.3061224489797,1158.8571428571429,1247.408163265306,1335.9591836734694,1424.5102040816328,1513.0612244897959,1601.6122448979593,1690.1632653061224,1778.7142857142858,1867.2653061224489,1955.8163265306123,2044.3673469387757,2132.9183673469388,2221.4693877551022,2310.0204081632655,2398.5714285714284,2487.1224489795918,2575.6734693877552,2664.2244897959185,2752.7755102040819,2841.3265306122448,2929.8775510204082,3018.4285714285716,3106.9795918367349,3195.5306122448978,3284.0816326530612,3372.6326530612246,3461.1836734693879,3549.7346938775513,3638.2857142857142,3726.8367346938776,3815.387755102041,3903.9387755102043,3992.4897959183672,4081.0408163265306,4169.591836734694,4258.1428571428569,4346.6938775510207,4435.2448979591836,4523.7959183673465,4612.3469387755104,4700.8979591836733,4789.4489795918371,4878],"y":[1,1.1428571428571428,1.2857142857142856,1.4285714285714286,1.5714285714285714,1.7142857142857142,1.8571428571428572,2,2.1428571428571428,2.2857142857142856,2.4285714285714284,2.5714285714285712,2.7142857142857144,2.8571428571428568,3,3.1428571428571428,3.2857142857142856,3.4285714285714284,3.5714285714285712,3.714285714285714,3.8571428571428568,4,4.1428571428571423,4.2857142857142856,4.4285714285714288,4.5714285714285712,4.7142857142857135,4.8571428571428568,5,5.1428571428571423,5.2857142857142856,5.4285714285714279,5.5714285714285712,5.7142857142857144,5.8571428571428568,6,6.1428571428571423,6.2857142857142856,6.4285714285714279,6.5714285714285712,6.7142857142857135,6.8571428571428568,7,7.1428571428571423,7.2857142857142856,7.4285714285714279,7.5714285714285712,7.7142857142857135,7.8571428571428568,8],"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p class="caption">
Figure 8.7: Linear regression plane of best fit overlaid on top of the data (using price, house size, and number of bedrooms as predictors). Note that in general we recommend against using 3D visualizations; here we use a 3D visualization only to illustrate what the regression plane looks like for learning purposes.
</p>
</div>
<p>We see that the predictions from linear regression with two predictors form a
flat plane. This is the hallmark of linear regression, and differs from the
wiggly, flexible surface we get from other methods such as K-NN regression.
As discussed, this can be advantageous in one aspect, which is that for each
predictor, we can get slopes/intercept from linear regression, and thus describe the
plane mathematically. We can extract those slope values from our model object
as shown below:</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="regression2.html#cb426-1" tabindex="-1"></a>mcoeffs <span class="ot">&lt;-</span> mlm_fit <span class="sc">|&gt;</span></span>
<span id="cb426-2"><a href="regression2.html#cb426-2" tabindex="-1"></a>             <span class="fu">extract_fit_parsnip</span>() <span class="sc">|&gt;</span></span>
<span id="cb426-3"><a href="regression2.html#cb426-3" tabindex="-1"></a>             <span class="fu">tidy</span>()</span>
<span id="cb426-4"><a href="regression2.html#cb426-4" tabindex="-1"></a></span>
<span id="cb426-5"><a href="regression2.html#cb426-5" tabindex="-1"></a>mcoeffs</span></code></pre></div>
<pre><code>## # A tibble: 3  5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)   72548.  11670.        6.22 8.76e- 10
## 2 sqft            161.      5.93     27.1  8.34e-111
## 3 beds         -29644.   4799.       -6.18 1.11e-  9</code></pre>
<p>And then use those slopes to write a mathematical equation to describe the prediction plane: </p>
<p><span class="math display">\[\text{house sale price} = \beta_0 + \beta_1\cdot(\text{house size}) + \beta_2\cdot(\text{number of bedrooms}),\]</span>
where:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span> is the <em>vertical intercept</em> of the hyperplane (the price when both house size and number of bedrooms are 0)</li>
<li><span class="math inline">\(\beta_1\)</span> is the <em>slope</em> for the first predictor (how quickly the price changes as you increase house size, holding number of bedrooms constant)</li>
<li><span class="math inline">\(\beta_2\)</span> is the <em>slope</em> for the second predictor (how quickly the price changes as you increase the number of bedrooms, holding house size constant)</li>
</ul>
<p>Finally, we can fill in the values for <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> from the model output above
to create the equation of the plane of best fit to the data:</p>
<p><span class="math display">\[\text{house sale price} = 72548 + 161\cdot (\text{house size})  -29644 \cdot (\text{number of bedrooms})\]</span></p>
<p>This model is more interpretable than the multivariable K-NN
regression model; we can write a mathematical equation that explains how
each predictor is affecting the predictions. But as always, we should
question how well multivariable linear regression is doing compared to
the other tools we have, such as simple linear regression
and multivariable K-NN regression. If this comparison is part of
the model tuning processfor example, if we are trying
out many different sets of predictors for multivariable linear
and K-NN regressionwe must perform this comparison using
cross-validation on only our training data. But if we have already
decided on a small number (e.g., 2 or 3) of tuned candidate models and
we want to make a final comparison, we can do so by comparing the prediction
error of the methods on the test data.</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="regression2.html#cb428-1" tabindex="-1"></a>lm_mult_test_results</span></code></pre></div>
<pre><code>## # A tibble: 3  3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard   88739.   
## 2 rsq     standard       0.603
## 3 mae     standard   61732.</code></pre>
<p>We obtain an RMSPE for the multivariable linear regression model
of $88,739.45. This prediction error
is less than the prediction error for the multivariable K-NN regression model,
indicating that we should likely choose linear regression for predictions of
house sale price on this data set. Revisiting the simple linear regression model
with only a single predictor from earlier in this chapter, we see that the RMSPE for that model was
$88,527.75,
which is almost the same as that of our more complex model.
As mentioned earlier, this is not always the case: often including more
predictors will either positively or negatively impact the prediction performance on unseen
test data.</p>
</div>
<div id="multicollinearity-and-outliers" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> Multicollinearity and outliers<a href="regression2.html#multicollinearity-and-outliers" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>What can go wrong when performing (possibly multivariable) linear regression?
This section will introduce two common issues<em>outliers</em> and <em>collinear predictors</em>and
illustrate their impact on predictions.</p>
<div id="outliers" class="section level3 hasAnchor" number="8.7.1">
<h3><span class="header-section-number">8.7.1</span> Outliers<a href="regression2.html#outliers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Outliers are data points that do not follow the usual pattern of the rest of the data.
In the setting of linear regression, these are points that
have a vertical distance to the line of best fit that is either much higher or much lower
than you might expect based on the rest of the data. The problem with outliers is that
they can have <em>too much influence</em> on the line of best fit. In general, it is very difficult
to judge accurately which data are outliers without advanced techniques that are beyond
the scope of this book.</p>
<p>But to illustrate what can happen when you have outliers, Figure <a href="regression2.html#fig:08-lm-outlier">8.8</a>
shows a small subset of the Sacramento housing data again, except we have added a <em>single</em> data point (highlighted
in red). This house is 5,000 square feet in size, and sold for only $50,000. Unbeknownst to the
data analyst, this house was sold by a parent to their child for an absurdly low price. Of course,
this is not representative of the real housing market values that the other data points follow;
the data point is an <em>outlier</em>. In blue we plot the original line of best fit, and in red
we plot the new line of best fit including the outlier. You can see how different the red line
is from the blue line, which is entirely caused by that one extra outlier data point.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-lm-outlier"></span>
<img src="_main_files/figure-html/08-lm-outlier-1.png" alt="Scatter plot of a subset of the data, with outlier highlighted in red." width="432" />
<p class="caption">
Figure 8.8: Scatter plot of a subset of the data, with outlier highlighted in red.
</p>
</div>
<p>Fortunately, if you have enough data, the inclusion of one or two
outliersas long as their values are not <em>too</em> wildwill
typically not have a large effect on the line of best fit. Figure
<a href="regression2.html#fig:08-lm-outlier-2">8.9</a> shows how that same outlier data point from earlier
influences the line of best fit when we are working with the entire original
Sacramento training data. You can see that with this larger data set, the line
changes much less when adding the outlier.
Nevertheless, it is still important when working with linear regression to critically
think about how much any individual data point is influencing the model.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-lm-outlier-2"></span>
<img src="_main_files/figure-html/08-lm-outlier-2-1.png" alt="Scatter plot of the full data, with outlier highlighted in red." width="432" />
<p class="caption">
Figure 8.9: Scatter plot of the full data, with outlier highlighted in red.
</p>
</div>
</div>
<div id="multicollinearity" class="section level3 hasAnchor" number="8.7.2">
<h3><span class="header-section-number">8.7.2</span> Multicollinearity<a href="regression2.html#multicollinearity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The second, and much more subtle, issue can occur when performing multivariable
linear regression. In particular, if you include multiple predictors that are
strongly linearly related to one another, the coefficients that describe the
plane of best fit can be very unreliablesmall changes to the data can
result in large changes in the coefficients. Consider an extreme example using
the Sacramento housing data where the house was measured twice by two people.
Since the two people are each slightly inaccurate, the two measurements might
not agree exactly, but they are very strongly linearly related to each other,
as shown in Figure <a href="regression2.html#fig:08-lm-multicol">8.10</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-lm-multicol"></span>
<img src="_main_files/figure-html/08-lm-multicol-1.png" alt="Scatter plot of house size (in square feet) measured by person 1 versus house size (in square feet) measured by person 2." width="432" />
<p class="caption">
Figure 8.10: Scatter plot of house size (in square feet) measured by person 1 versus house size (in square feet) measured by person 2.
</p>
</div>
<p>If we again fit the multivariable linear regression model on this data, then the plane of best fit
has regression coefficients that are very sensitive to the exact values in the data. For example,
if we change the data ever so slightlye.g., by running cross-validation, which splits
up the data randomly into different chunksthe coefficients vary by large amounts:</p>
<p>Best Fit 1: <span class="math inline">\(\text{house sale price} = 22535 + (220)\cdot (\text{house size 1 (ft$^2$)}) + (-86) \cdot (\text{house size 2 (ft$^2$)}).\)</span></p>
<p>Best Fit 2: <span class="math inline">\(\text{house sale price} = 15966 + (86)\cdot (\text{house size 1 (ft$^2$)}) + (49) \cdot (\text{house size 2 (ft$^2$)}).\)</span></p>
<p>Best Fit 3: <span class="math inline">\(\text{house sale price} = 17178 + (107)\cdot (\text{house size 1 (ft$^2$)}) + (27) \cdot (\text{house size 2 (ft$^2$)}).\)</span></p>
<p>Therefore, when performing multivariable linear regression, it is important to avoid including very
linearly related predictors. However, techniques for doing so are beyond the scope of this
book; see the list of additional resources at the end of this chapter to find out where you can learn more.</p>
</div>
</div>
<div id="designing-new-predictors" class="section level2 hasAnchor" number="8.8">
<h2><span class="header-section-number">8.8</span> Designing new predictors<a href="regression2.html#designing-new-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We were quite fortunate in our initial exploration to find a predictor variable (house size)
that seems to have a meaningful and nearly linear relationship with our response variable (sale price).
But what should we do if we cannot immediately find such a nice variable?
Well, sometimes it is just a fact that the variables in the data do not have enough of
a relationship with the response variable to provide useful predictions. For example,
if the only available predictor was the current house owners favorite ice cream flavor,
we likely would have little hope of using that variable to predict the houses sale price
(barring any future remarkable scientific discoveries about the relationship between
the housing market and homeowner ice cream preferences). In cases like these,
the only option is to obtain measurements of more useful variables.</p>
<p>There are, however, a wide variety of cases where the predictor variables do have a
meaningful relationship with the response variable, but that relationship does not fit
the assumptions of the regression method you have chosen. For example, a data frame <code>df</code>
with two variables<code>x</code> and <code>y</code>with a nonlinear relationship between the two variables
will not be fully captured by simple linear regression, as shown in Figure <a href="regression2.html#fig:08-predictor-design">8.11</a>.</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="regression2.html#cb430-1" tabindex="-1"></a>df</span></code></pre></div>
<pre><code>## # A tibble: 100  2
##        x      y
##    &lt;dbl&gt;  &lt;dbl&gt;
##  1 0.102 0.0720
##  2 0.800 0.532 
##  3 0.478 0.148 
##  4 0.972 1.01  
##  5 0.846 0.677 
##  6 0.405 0.157 
##  7 0.879 0.768 
##  8 0.130 0.0402
##  9 0.852 0.576 
## 10 0.180 0.0847
## #  90 more rows</code></pre>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-predictor-design"></span>
<img src="_main_files/figure-html/08-predictor-design-1.png" alt="Example of a data set with a nonlinear relationship between the predictor and the response." width="432" />
<p class="caption">
Figure 8.11: Example of a data set with a nonlinear relationship between the predictor and the response.
</p>
</div>
<p>Instead of trying to predict the response <code>y</code> using a linear regression on <code>x</code>,
we might have some scientific background about our problem to suggest that <code>y</code>
should be a cubic function of <code>x</code>. So before performing regression,
we might <em>create a new predictor variable</em> <code>z</code> using the <code>mutate</code> function: </p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="regression2.html#cb432-1" tabindex="-1"></a>df <span class="ot">&lt;-</span> df <span class="sc">|&gt;</span></span>
<span id="cb432-2"><a href="regression2.html#cb432-2" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">z =</span> x<span class="sc">^</span><span class="dv">3</span>)</span></code></pre></div>
<p>Then we can perform linear regression for <code>y</code> using the predictor variable <code>z</code>,
as shown in Figure <a href="regression2.html#fig:08-predictor-design-2">8.12</a>.
Here you can see that the transformed predictor <code>z</code> helps the
linear regression model make more accurate predictions.
Note that none of the <code>y</code> response values have changed between Figures <a href="regression2.html#fig:08-predictor-design">8.11</a>
and <a href="regression2.html#fig:08-predictor-design-2">8.12</a>; the only change is that the <code>x</code> values
have been replaced by <code>z</code> values.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:08-predictor-design-2"></span>
<img src="_main_files/figure-html/08-predictor-design-2-1.png" alt="Relationship between the transformed predictor and the response." width="432" />
<p class="caption">
Figure 8.12: Relationship between the transformed predictor and the response.
</p>
</div>
<p>The process of
transforming predictors (and potentially combining multiple predictors in the process)
is known as <em>feature engineering</em>. In real data analysis
problems, you will need to rely on
a deep understanding of the problemas well as the wrangling tools
from previous chaptersto engineer useful new features that improve
predictive performance.</p>
<blockquote>
<p><strong>Note:</strong> Feature engineering
is <em>part of tuning your model</em>, and as such you must not use your test data
to evaluate the quality of the features you produce. You are free to use
cross-validation, though!</p>
</blockquote>
</div>
<div id="the-other-sides-of-regression" class="section level2 hasAnchor" number="8.9">
<h2><span class="header-section-number">8.9</span> The other sides of regression<a href="regression2.html#the-other-sides-of-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>So far in this textbook we have used regression only in the context of
prediction. However, regression can also be seen as a method to understand and
quantify the effects of individual predictor variables on a response variable of interest.
In the housing example from this chapter, beyond just using past data
to predict future sale prices,
we might also be interested in describing the
individual relationships of house size and the number of bedrooms with house price,
quantifying how strong each of these relationships are, and assessing how accurately we
can estimate their magnitudes. And even beyond that, we may be interested in
understanding whether the predictors <em>cause</em> changes in the price.
These sides of regression are well beyond the scope of this book; but
the material you have learned here should give you a foundation of knowledge
that will serve you well when moving to more advanced books on the topic.</p>
</div>
<div id="exercises-7" class="section level2 hasAnchor" number="8.10">
<h2><span class="header-section-number">8.10</span> Exercises<a href="regression2.html#exercises-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Practice exercises for the material covered in this chapter
can be found in the accompanying
<a href="https://worksheets.datasciencebook.ca">worksheets repository</a>
in the Regression II: linear regression row.
You can launch an interactive version of the worksheet in your browser by clicking the launch binder button.
You can also preview a non-interactive version of the worksheet by clicking view worksheet.
If you instead decide to download the worksheet and run it on your own machine,
make sure to follow the instructions for computer setup
found in Chapter <a href="setup.html#setup">13</a>. This will ensure that the automated feedback
and guidance that the worksheets provide will function as intended.</p>
</div>
<div id="additional-resources-4" class="section level2 hasAnchor" number="8.11">
<h2><span class="header-section-number">8.11</span> Additional resources<a href="regression2.html#additional-resources-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>The <a href="https://tidymodels.org/packages"><code>tidymodels</code> website</a> is an excellent
reference for more details on, and advanced usage of, the functions and
packages in the past two chapters. Aside from that, it also has a <a href="https://www.tidymodels.org/start/">nice
beginners tutorial</a> and <a href="https://www.tidymodels.org/learn/">an extensive list
of more advanced examples</a> that you can use
to continue learning beyond the scope of this book.</li>
<li><em>Modern Dive</em> <span class="citation">(<a href="#ref-moderndive">Ismay and Kim 2020</a>)</span> is another textbook that uses the
<code>tidyverse</code> / <code>tidymodels</code> framework. Chapter 6 complements the material in
the current chapter well; it covers some slightly more advanced concepts than
we do without getting mathematical. Give this chapter a read before moving on
to the next reference. It is also worth noting that this book takes a more
explanatory / inferential approach to regression in general (in Chapters 5,
6, and 10), which provides a nice complement to the predictive tack we take in
the present book.</li>
<li><em>An Introduction to Statistical Learning</em> <span class="citation">(<a href="#ref-james2013introduction">James et al. 2013</a>)</span> provides
a great next stop in the process of
learning about regression. Chapter 3 covers linear regression at a slightly
more mathematical level than we do here, but it is not too large a leap and so
should provide a good stepping stone. Chapter 6 discusses how to pick a subset
of informative predictors when you have a data set with many predictors, and
you expect only a few of them to be relevant. Chapter 7 covers regression
models that are more flexible than linear regression models but still enjoy the
computational efficiency of linear regression. In contrast, the K-NN methods we
covered earlier are indeed more flexible but become very slow when given lots
of data.</li>
</ul>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-moderndive" class="csl-entry">
Ismay, Chester, and Albert Kim. 2020. <em>Statistical Inference via Data Science: A <span>M</span>odern<span>D</span>ive into <span>R</span> and the <span>T</span>idyverse</em>. Chapman; Hall/CRC Press. <a href="https://moderndive.com/">https://moderndive.com/</a>.
</div>
<div id="ref-james2013introduction" class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. 1st ed. Springer. <a href="https://www.statlearning.com/">https://www.statlearning.com/</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="clustering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
